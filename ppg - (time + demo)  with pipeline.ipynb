{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b410711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa28b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_features = pd.read_csv(r\"filepath\")\n",
    "dbp_features = pd.read_csv(r\"filepath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4638db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>sum75</th>\n",
       "      <th>div10</th>\n",
       "      <th>div25</th>\n",
       "      <th>div33</th>\n",
       "      <th>div50</th>\n",
       "      <th>div66</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>1.678947</td>\n",
       "      <td>1.520231</td>\n",
       "      <td>1.472727</td>\n",
       "      <td>1.091503</td>\n",
       "      <td>0.609929</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>1.433333</td>\n",
       "      <td>1.622642</td>\n",
       "      <td>1.708609</td>\n",
       "      <td>1.856115</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>1.102740</td>\n",
       "      <td>1.238462</td>\n",
       "      <td>1.308943</td>\n",
       "      <td>1.450450</td>\n",
       "      <td>1.216495</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>3.709677</td>\n",
       "      <td>3.454545</td>\n",
       "      <td>3.223301</td>\n",
       "      <td>2.615385</td>\n",
       "      <td>2.341772</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>2.657343</td>\n",
       "      <td>1.695312</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.372549</td>\n",
       "      <td>1.341463</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>2.167702</td>\n",
       "      <td>1.875862</td>\n",
       "      <td>1.669065</td>\n",
       "      <td>1.290323</td>\n",
       "      <td>1.063636</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>595.050006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>234</td>\n",
       "      <td>1.976303</td>\n",
       "      <td>1.725389</td>\n",
       "      <td>1.605405</td>\n",
       "      <td>1.239521</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>680.005470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>162</td>\n",
       "      <td>3.992308</td>\n",
       "      <td>3.146552</td>\n",
       "      <td>2.898148</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>844.648904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>3.194245</td>\n",
       "      <td>2.772358</td>\n",
       "      <td>2.517241</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.534091</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>611.871232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>3.217105</td>\n",
       "      <td>2.518248</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>1.576271</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>599.832037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "202         214  775  185  567          96    349    272    232    160    117   \n",
       "203         215  948  244  646          97    417    333    297    207    123   \n",
       "204         216  719  163  549          98    519    365    313    171    120   \n",
       "205         217  751  255  551          99    444    341    292    187    135   \n",
       "206         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...  sum75     div10     div25     div33     div50     div66     div75  \\\n",
       "0    ...    199  1.678947  1.520231  1.472727  1.091503  0.609929  0.507576   \n",
       "1    ...    232  1.433333  1.622642  1.708609  1.856115  1.555556  1.128440   \n",
       "2    ...    190  1.102740  1.238462  1.308943  1.450450  1.216495  1.134831   \n",
       "3    ...    235  3.709677  3.454545  3.223301  2.615385  2.341772  2.263889   \n",
       "4    ...    158  2.657343  1.695312  1.500000  1.372549  1.341463  1.289855   \n",
       "..   ...    ...       ...       ...       ...       ...       ...       ...   \n",
       "202  ...    203  2.167702  1.875862  1.669065  1.290323  1.063636  1.009901   \n",
       "203  ...    234  1.976303  1.725389  1.605405  1.239521  0.820000  0.683453   \n",
       "204  ...    162  3.992308  3.146552  2.898148  1.900000  1.621622  1.531250   \n",
       "205  ...    191  3.194245  2.772358  2.517241  1.833333  1.534091  1.480519   \n",
       "206  ...    165  3.217105  2.518248  2.312500  1.576271  1.052632  1.171053   \n",
       "\n",
       "     sbp  dbp  area_under_curve  \n",
       "0    140   82        673.754706  \n",
       "1    120   60        671.104643  \n",
       "2    135   75        571.545583  \n",
       "3    130   66        821.935730  \n",
       "4    133   77        649.000588  \n",
       "..   ...  ...               ...  \n",
       "202  136   71        595.050006  \n",
       "203  143   65        680.005470  \n",
       "204  116   65        844.648904  \n",
       "205  133   71        611.871232  \n",
       "206  123   73        599.832037  \n",
       "\n",
       "[207 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fcd0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cardiovascular Dataset Information File</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Hospital Electronic Medical Record</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Num.</td>\n",
       "      <td>subject_ID</td>\n",
       "      <td>Sex(M/F)</td>\n",
       "      <td>Age(year)</td>\n",
       "      <td>Height(cm)</td>\n",
       "      <td>Weight(kg)</td>\n",
       "      <td>Systolic Blood Pressure(mmHg)</td>\n",
       "      <td>Diastolic Blood Pressure(mmHg)</td>\n",
       "      <td>Heart Rate(b/m)</td>\n",
       "      <td>BMI(kg/m^2)</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>cerebral infarction</td>\n",
       "      <td>cerebrovascular disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>152</td>\n",
       "      <td>63</td>\n",
       "      <td>161</td>\n",
       "      <td>89</td>\n",
       "      <td>97</td>\n",
       "      <td>27.268006</td>\n",
       "      <td>Stage 2 hypertension</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>157</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>20.284799</td>\n",
       "      <td>Stage 2 hypertension</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>150</td>\n",
       "      <td>47</td>\n",
       "      <td>101</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>20.888889</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>172</td>\n",
       "      <td>65</td>\n",
       "      <td>136</td>\n",
       "      <td>93</td>\n",
       "      <td>87</td>\n",
       "      <td>21.971336</td>\n",
       "      <td>Prehypertension</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>415</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>21.604938</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>416</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>156</td>\n",
       "      <td>47</td>\n",
       "      <td>93</td>\n",
       "      <td>57</td>\n",
       "      <td>79</td>\n",
       "      <td>19.312952</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>417</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>55</td>\n",
       "      <td>120</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>17.755682</td>\n",
       "      <td>Prehypertension</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>418</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>173</td>\n",
       "      <td>63</td>\n",
       "      <td>106</td>\n",
       "      <td>69</td>\n",
       "      <td>67</td>\n",
       "      <td>21.049818</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>419</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>175</td>\n",
       "      <td>58</td>\n",
       "      <td>108</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>18.938776</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cardiovascular Dataset Information File  Unnamed: 1 Unnamed: 2 Unnamed: 3  \\\n",
       "0                                      Num.  subject_ID   Sex(M/F)  Age(year)   \n",
       "1                                         1           2     Female         45   \n",
       "2                                         2           3     Female         50   \n",
       "3                                         3           6     Female         47   \n",
       "4                                         4           8       Male         45   \n",
       "..                                      ...         ...        ...        ...   \n",
       "215                                     215         415       Male         24   \n",
       "216                                     216         416     Female         25   \n",
       "217                                     217         417       Male         25   \n",
       "218                                     218         418       Male         25   \n",
       "219                                     219         419       Male         24   \n",
       "\n",
       "     Unnamed: 4  Unnamed: 5                     Unnamed: 6  \\\n",
       "0    Height(cm)  Weight(kg)  Systolic Blood Pressure(mmHg)   \n",
       "1           152          63                            161   \n",
       "2           157          50                            160   \n",
       "3           150          47                            101   \n",
       "4           172          65                            136   \n",
       "..          ...         ...                            ...   \n",
       "215         180          70                            111   \n",
       "216         156          47                             93   \n",
       "217         176          55                            120   \n",
       "218         173          63                            106   \n",
       "219         175          58                            108   \n",
       "\n",
       "                         Unnamed: 7       Unnamed: 8   Unnamed: 9  \\\n",
       "0    Diastolic Blood Pressure(mmHg)  Heart Rate(b/m)  BMI(kg/m^2)   \n",
       "1                                89               97    27.268006   \n",
       "2                                93               76    20.284799   \n",
       "3                                71               79    20.888889   \n",
       "4                                93               87    21.971336   \n",
       "..                              ...              ...          ...   \n",
       "215                              70               77    21.604938   \n",
       "216                              57               79    19.312952   \n",
       "217                              69               72    17.755682   \n",
       "218                              69               67    21.049818   \n",
       "219                              68               65    18.938776   \n",
       "\n",
       "    Hospital Electronic Medical Record Unnamed: 11          Unnamed: 12  \\\n",
       "0                         Hypertension    Diabetes  cerebral infarction   \n",
       "1                 Stage 2 hypertension         NaN                  NaN   \n",
       "2                 Stage 2 hypertension         NaN                  NaN   \n",
       "3                               Normal         NaN                  NaN   \n",
       "4                      Prehypertension         NaN                  NaN   \n",
       "..                                 ...         ...                  ...   \n",
       "215                             Normal         NaN                  NaN   \n",
       "216                             Normal         NaN                  NaN   \n",
       "217                    Prehypertension         NaN                  NaN   \n",
       "218                             Normal         NaN                  NaN   \n",
       "219                             Normal         NaN                  NaN   \n",
       "\n",
       "                 Unnamed: 13  \n",
       "0    cerebrovascular disease  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "..                       ...  \n",
       "215                      NaN  \n",
       "216                      NaN  \n",
       "217                      NaN  \n",
       "218                      NaN  \n",
       "219                      NaN  \n",
       "\n",
       "[220 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel(r\"file_path\")\n",
    "# df=df.rename(columns=df.iloc[0])\n",
    "# df=df.drop(index=0)\n",
    "# df=df.reset_index()\n",
    "# df=df.drop(['Num.','Hypertension','Diabetes','cerebral infarction','cerebrovascular disease','index'],axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f377c23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type 2 Diabetes    37\n",
       "Diabetes            2\n",
       "Name: Unnamed: 11, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Unnamed: 11\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754f40ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prehypertension         85\n",
       "Normal                  80\n",
       "Stage 1 hypertension    34\n",
       "Stage 2 hypertension    20\n",
       "Hypertension             1\n",
       "Name: Hospital Electronic Medical Record, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Hospital Electronic Medical Record\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3010a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cerebral infarction    21\n",
       "Name: Unnamed: 12, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Unnamed: 12\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3b3856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insufficiency of cerebral blood supply    15\n",
       "cerebrovascular disease                   11\n",
       "Name: Unnamed: 13, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Unnamed: 13\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f4f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex=[]\n",
    "Age=[]\n",
    "Height=[]\n",
    "Weight=[]\n",
    "Systolic_Blood_Pressure=[]\n",
    "Diastolic_Blood_Pressure=[]\n",
    "Heart_Rate=[]\n",
    "BMI=[]\n",
    "Ht =[]\n",
    "Diabetics =[]\n",
    "cerebral =[]\n",
    "cerebro =[]\n",
    "\n",
    "\n",
    "for i in sbp_features['subject_id']:\n",
    "    index = df1[df1['Unnamed: 1'] == i].index[0]\n",
    "    sex_value = df1['Unnamed: 2'][index]       \n",
    "    Sex.append(sex_value)  \n",
    "    age_value = df1['Unnamed: 3'][index]       \n",
    "    Age.append(age_value) \n",
    "    height_value = df1['Unnamed: 4'][index]       \n",
    "    Height.append(height_value)\n",
    "    weight_value = df1['Unnamed: 5'][index]       \n",
    "    Weight.append(weight_value)\n",
    "    Systolic_Blood_Pressure_value = df1['Unnamed: 6'][index]       \n",
    "    Systolic_Blood_Pressure.append(Systolic_Blood_Pressure_value)\n",
    "    Diastolic_Blood_Pressure_value = df1['Unnamed: 7'][index]       \n",
    "    Diastolic_Blood_Pressure.append(Diastolic_Blood_Pressure_value)\n",
    "    Heart_Rate_value = df1['Unnamed: 8'][index]       \n",
    "    Heart_Rate.append(Heart_Rate_value)\n",
    "    BMI_value = df1['Unnamed: 9'][index]       \n",
    "    BMI.append(BMI_value)\n",
    "    ht_value = df1['Hospital Electronic Medical Record'][index]       \n",
    "    Ht.append(ht_value)\n",
    "    Diabetics_value = df1['Unnamed: 11'][index]       \n",
    "    Diabetics.append(Diabetics_value)\n",
    "    cerebral_value = df1['Unnamed: 12'][index]       \n",
    "    cerebral.append(cerebral_value)\n",
    "    cerebro_value = df1['Unnamed: 13'][index]       \n",
    "    cerebro.append(cerebro_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e360875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_features['Sex'] = Sex\n",
    "sbp_features['Age'] = Age\n",
    "sbp_features['Height'] = Height\n",
    "sbp_features['Weight'] = Weight\n",
    "# sbp_features['Systolic_Blood_Pressure'] = Systolic_Blood_Pressure\n",
    "# sbp_features['Diastolic_Blood_Pressure'] = Diastolic_Blood_Pressure\n",
    "sbp_features['Heart_Rate'] = Heart_Rate\n",
    "sbp_features['BMI'] = BMI\n",
    "# sbp_features['Hypertension'] = Ht\n",
    "# sbp_features['Diabetics'] = Diabetics\n",
    "# sbp_features['cerebral infarction'] = cerebral\n",
    "# sbp_features['cerebrovascular disease'] = cerebro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3248d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>Female</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>Female</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>Female</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>Female</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>595.050006</td>\n",
       "      <td>Female</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>680.005470</td>\n",
       "      <td>Male</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>844.648904</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>611.871232</td>\n",
       "      <td>Male</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>599.832037</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "202         214  775  185  567          96    349    272    232    160    117   \n",
       "203         215  948  244  646          97    417    333    297    207    123   \n",
       "204         216  719  163  549          98    519    365    313    171    120   \n",
       "205         217  751  255  551          99    444    341    292    187    135   \n",
       "206         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...     div75  sbp  dbp  area_under_curve     Sex  Age  Height  Weight  \\\n",
       "0    ...  0.507576  140   82        673.754706  Female   68     150      63   \n",
       "1    ...  1.128440  120   60        671.104643  Female   63     153      45   \n",
       "2    ...  1.134831  135   75        571.545583  Female   67     155      55   \n",
       "3    ...  2.263889  130   66        821.935730  Female   86     161      70   \n",
       "4    ...  1.289855  133   77        649.000588    Male   59     171      80   \n",
       "..   ...       ...  ...  ...               ...     ...  ...     ...     ...   \n",
       "202  ...  1.009901  136   71        595.050006  Female   76     158      62   \n",
       "203  ...  0.683453  143   65        680.005470    Male   76     168      75   \n",
       "204  ...  1.531250  116   65        844.648904    Male   68     170      69   \n",
       "205  ...  1.480519  133   71        611.871232    Male   78     170      60   \n",
       "206  ...  1.171053  123   73        599.832037  Female   46     155      65   \n",
       "\n",
       "     Heart_Rate        BMI  \n",
       "0            73  28.000000  \n",
       "1            76  19.223376  \n",
       "2            72  22.892820  \n",
       "3            69  27.005131  \n",
       "4            66  27.358845  \n",
       "..          ...        ...  \n",
       "202          72  24.835763  \n",
       "203          66  26.573129  \n",
       "204          70  23.875433  \n",
       "205          80  20.761246  \n",
       "206          73  27.055151  \n",
       "\n",
       "[207 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97a98dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_features[\"Sex\"]= sbp_features['Sex'].map({'Male': 0, 'Female': 1})\n",
    "# sbp_features[\"Hypertension\"]= sbp_features['Hypertension'].map({'Normal': 0, 'Prehypertension': 1, \"Stage 1 hypertension\": 2,'Stage 2 hypertension':3})\n",
    "# sbp_features[\"Diabetics\"]= sbp_features['Diabetics'].map({'NaN': 0, 'Type 2 Diabetes': 1,'Diabetes':2})\n",
    "# sbp_features[\"cerebral infarction\"]= sbp_features['cerebral infarction'].map({'NaN': 0, 'cerebral infarction': 1})\n",
    "# sbp_features[\"cerebrovascular disease\"]= sbp_features['cerebrovascular disease'].map({'NaN': 0, 'insufficiency of cerebral blood supply': 1,'insufficiency of cerebral blood supply':2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bbfd14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>595.050006</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>680.005470</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>844.648904</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>611.871232</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>599.832037</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "202         214  775  185  567          96    349    272    232    160    117   \n",
       "203         215  948  244  646          97    417    333    297    207    123   \n",
       "204         216  719  163  549          98    519    365    313    171    120   \n",
       "205         217  751  255  551          99    444    341    292    187    135   \n",
       "206         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...     div75  sbp  dbp  area_under_curve  Sex  Age  Height  Weight  \\\n",
       "0    ...  0.507576  140   82        673.754706    1   68     150      63   \n",
       "1    ...  1.128440  120   60        671.104643    1   63     153      45   \n",
       "2    ...  1.134831  135   75        571.545583    1   67     155      55   \n",
       "3    ...  2.263889  130   66        821.935730    1   86     161      70   \n",
       "4    ...  1.289855  133   77        649.000588    0   59     171      80   \n",
       "..   ...       ...  ...  ...               ...  ...  ...     ...     ...   \n",
       "202  ...  1.009901  136   71        595.050006    1   76     158      62   \n",
       "203  ...  0.683453  143   65        680.005470    0   76     168      75   \n",
       "204  ...  1.531250  116   65        844.648904    0   68     170      69   \n",
       "205  ...  1.480519  133   71        611.871232    0   78     170      60   \n",
       "206  ...  1.171053  123   73        599.832037    1   46     155      65   \n",
       "\n",
       "     Heart_Rate        BMI  \n",
       "0            73  28.000000  \n",
       "1            76  19.223376  \n",
       "2            72  22.892820  \n",
       "3            69  27.005131  \n",
       "4            66  27.358845  \n",
       "..          ...        ...  \n",
       "202          72  24.835763  \n",
       "203          66  26.573129  \n",
       "204          70  23.875433  \n",
       "205          80  20.761246  \n",
       "206          73  27.055151  \n",
       "\n",
       "[207 rows x 38 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e1c7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>595.050006</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>680.005470</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>844.648904</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>611.871232</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>599.832037</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "202         214  775  185  567          96    349    272    232    160    117   \n",
       "203         215  948  244  646          97    417    333    297    207    123   \n",
       "204         216  719  163  549          98    519    365    313    171    120   \n",
       "205         217  751  255  551          99    444    341    292    187    135   \n",
       "206         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...     div75  sbp  dbp  area_under_curve  Sex  Age  Height  Weight  \\\n",
       "0    ...  0.507576  140   82        673.754706    1   68     150      63   \n",
       "1    ...  1.128440  120   60        671.104643    1   63     153      45   \n",
       "2    ...  1.134831  135   75        571.545583    1   67     155      55   \n",
       "3    ...  2.263889  130   66        821.935730    1   86     161      70   \n",
       "4    ...  1.289855  133   77        649.000588    0   59     171      80   \n",
       "..   ...       ...  ...  ...               ...  ...  ...     ...     ...   \n",
       "202  ...  1.009901  136   71        595.050006    1   76     158      62   \n",
       "203  ...  0.683453  143   65        680.005470    0   76     168      75   \n",
       "204  ...  1.531250  116   65        844.648904    0   68     170      69   \n",
       "205  ...  1.480519  133   71        611.871232    0   78     170      60   \n",
       "206  ...  1.171053  123   73        599.832037    1   46     155      65   \n",
       "\n",
       "     Heart_Rate        BMI  \n",
       "0            73  28.000000  \n",
       "1            76  19.223376  \n",
       "2            72  22.892820  \n",
       "3            69  27.005131  \n",
       "4            66  27.358845  \n",
       "..          ...        ...  \n",
       "202          72  24.835763  \n",
       "203          66  26.573129  \n",
       "204          70  23.875433  \n",
       "205          80  20.761246  \n",
       "206          73  27.055151  \n",
       "\n",
       "[207 rows x 38 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_features = sbp_features.fillna(0)\n",
    "sbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2130e831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>595.050006</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>680.005470</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>844.648904</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>611.871232</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>599.832037</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "202         214  775  185  567          96    349    272    232    160    117   \n",
       "203         215  948  244  646          97    417    333    297    207    123   \n",
       "204         216  719  163  549          98    519    365    313    171    120   \n",
       "205         217  751  255  551          99    444    341    292    187    135   \n",
       "206         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...     div75  sbp  dbp  area_under_curve  Sex  Age  Height  Weight  \\\n",
       "0    ...  0.507576  140   82        673.754706    1   68     150      63   \n",
       "1    ...  1.128440  120   60        671.104643    1   63     153      45   \n",
       "2    ...  1.134831  135   75        571.545583    1   67     155      55   \n",
       "3    ...  2.263889  130   66        821.935730    1   86     161      70   \n",
       "4    ...  1.289855  133   77        649.000588    0   59     171      80   \n",
       "..   ...       ...  ...  ...               ...  ...  ...     ...     ...   \n",
       "202  ...  1.009901  136   71        595.050006    1   76     158      62   \n",
       "203  ...  0.683453  143   65        680.005470    0   76     168      75   \n",
       "204  ...  1.531250  116   65        844.648904    0   68     170      69   \n",
       "205  ...  1.480519  133   71        611.871232    0   78     170      60   \n",
       "206  ...  1.171053  123   73        599.832037    1   46     155      65   \n",
       "\n",
       "     Heart_Rate        BMI  \n",
       "0            73  28.000000  \n",
       "1            76  19.223376  \n",
       "2            72  22.892820  \n",
       "3            69  27.005131  \n",
       "4            66  27.358845  \n",
       "..          ...        ...  \n",
       "202          72  24.835763  \n",
       "203          66  26.573129  \n",
       "204          70  23.875433  \n",
       "205          80  20.761246  \n",
       "206          73  27.055151  \n",
       "\n",
       "[207 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b116c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # For scikit-learn <= 0.24\n",
    "# If you're using scikit-learn 0.24 or later, you can use:\n",
    "# from joblib import dump\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_model_size(model):\n",
    "    # Serialize the model and get the size in kilobytes\n",
    "    model_filename = \"temp_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    size_kb = os.path.getsize(model_filename) / 1024\n",
    "    os.remove(model_filename)\n",
    "    return size_kb\n",
    "\n",
    "def evaluate_models(data):\n",
    "    X = data.drop(['sbp', 'dbp',\"subject_id\",\"Unnamed: 0\"], axis=1)\n",
    "    y = data['sbp']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    results_dict = {'Model': [], 'Mean Absolute Error': [], 'Root Mean Square': [], 'Model Size (KB)': []}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "#         print(\"-------------------------------\")\n",
    "#         print(y_pred)\n",
    "#         print(\"--------------------------------\")\n",
    "#         print(y_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "        size_kb = get_model_size(model)\n",
    "\n",
    "        results_dict['Model'].append(model_name)\n",
    "        results_dict['Mean Absolute Error'].append(mae)\n",
    "        results_dict['Root Mean Square'].append(rmse)\n",
    "        results_dict['Model Size (KB)'].append(size_kb)\n",
    "\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "models = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'SVR': SVR(),\n",
    "}\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models.update({\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "    'MLPRegressor': MLPRegressor(),\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e15e6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+02, tolerance: 4.711e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Model Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>10.016190</td>\n",
       "      <td>13.463357</td>\n",
       "      <td>1046.969727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>11.164336</td>\n",
       "      <td>14.061347</td>\n",
       "      <td>1.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>12.034921</td>\n",
       "      <td>15.991883</td>\n",
       "      <td>40.737305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>12.764576</td>\n",
       "      <td>16.166566</td>\n",
       "      <td>43.038086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>15.904762</td>\n",
       "      <td>20.636691</td>\n",
       "      <td>18.157227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>10.704909</td>\n",
       "      <td>13.619490</td>\n",
       "      <td>1.502930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>10.761906</td>\n",
       "      <td>14.119519</td>\n",
       "      <td>1.584961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>10.864272</td>\n",
       "      <td>14.177299</td>\n",
       "      <td>1.600586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>11.231763</td>\n",
       "      <td>14.656691</td>\n",
       "      <td>159.464844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>10.479704</td>\n",
       "      <td>14.032686</td>\n",
       "      <td>62.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>11.336335</td>\n",
       "      <td>14.285775</td>\n",
       "      <td>93.233398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>11.279605</td>\n",
       "      <td>15.230250</td>\n",
       "      <td>189.262695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Root Mean Square  \\\n",
       "0       RandomForestRegressor            10.016190         13.463357   \n",
       "1            LinearRegression            11.164336         14.061347   \n",
       "2         KNeighborsRegressor            12.034921         15.991883   \n",
       "3                         SVR            12.764576         16.166566   \n",
       "4       DecisionTreeRegressor            15.904762         20.636691   \n",
       "5                       Ridge            10.704909         13.619490   \n",
       "6                       Lasso            10.761906         14.119519   \n",
       "7                  ElasticNet            10.864272         14.177299   \n",
       "8   GradientBoostingRegressor            11.231763         14.656691   \n",
       "9           AdaBoostRegressor            10.479704         14.032686   \n",
       "10               MLPRegressor            11.336335         14.285775   \n",
       "11               XGBRegressor            11.279605         15.230250   \n",
       "\n",
       "    Model Size (KB)  \n",
       "0       1046.969727  \n",
       "1          1.835938  \n",
       "2         40.737305  \n",
       "3         43.038086  \n",
       "4         18.157227  \n",
       "5          1.502930  \n",
       "6          1.584961  \n",
       "7          1.600586  \n",
       "8        159.464844  \n",
       "9         62.734375  \n",
       "10        93.233398  \n",
       "11       189.262695  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_results=evaluate_models(sbp_features)\n",
    "sbp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e518ef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.030144\n",
      "0:\tlearn: 17.9691399\ttotal: 169ms\tremaining: 2m 48s\n",
      "1:\tlearn: 17.8279399\ttotal: 171ms\tremaining: 1m 25s\n",
      "2:\tlearn: 17.6896155\ttotal: 174ms\tremaining: 57.8s\n",
      "3:\tlearn: 17.5791349\ttotal: 177ms\tremaining: 44s\n",
      "4:\tlearn: 17.4668712\ttotal: 179ms\tremaining: 35.7s\n",
      "5:\tlearn: 17.3503697\ttotal: 181ms\tremaining: 30s\n",
      "6:\tlearn: 17.2284746\ttotal: 184ms\tremaining: 26.1s\n",
      "7:\tlearn: 17.1274062\ttotal: 186ms\tremaining: 23s\n",
      "8:\tlearn: 17.0336845\ttotal: 188ms\tremaining: 20.7s\n",
      "9:\tlearn: 16.9099572\ttotal: 190ms\tremaining: 18.8s\n",
      "10:\tlearn: 16.8163830\ttotal: 192ms\tremaining: 17.3s\n",
      "11:\tlearn: 16.7114838\ttotal: 194ms\tremaining: 16s\n",
      "12:\tlearn: 16.5946254\ttotal: 197ms\tremaining: 14.9s\n",
      "13:\tlearn: 16.5137018\ttotal: 199ms\tremaining: 14s\n",
      "14:\tlearn: 16.3679869\ttotal: 202ms\tremaining: 13.3s\n",
      "15:\tlearn: 16.2658306\ttotal: 205ms\tremaining: 12.6s\n",
      "16:\tlearn: 16.1486221\ttotal: 208ms\tremaining: 12s\n",
      "17:\tlearn: 16.0392155\ttotal: 210ms\tremaining: 11.5s\n",
      "18:\tlearn: 15.9347963\ttotal: 213ms\tremaining: 11s\n",
      "19:\tlearn: 15.8274248\ttotal: 216ms\tremaining: 10.6s\n",
      "20:\tlearn: 15.7340114\ttotal: 218ms\tremaining: 10.2s\n",
      "21:\tlearn: 15.6470397\ttotal: 221ms\tremaining: 9.82s\n",
      "22:\tlearn: 15.5433631\ttotal: 224ms\tremaining: 9.49s\n",
      "23:\tlearn: 15.4475743\ttotal: 226ms\tremaining: 9.2s\n",
      "24:\tlearn: 15.3659378\ttotal: 229ms\tremaining: 8.95s\n",
      "25:\tlearn: 15.2649051\ttotal: 232ms\tremaining: 8.68s\n",
      "26:\tlearn: 15.1755582\ttotal: 234ms\tremaining: 8.42s\n",
      "27:\tlearn: 15.0801020\ttotal: 236ms\tremaining: 8.18s\n",
      "28:\tlearn: 15.0083424\ttotal: 238ms\tremaining: 7.96s\n",
      "29:\tlearn: 14.9327541\ttotal: 240ms\tremaining: 7.75s\n",
      "30:\tlearn: 14.8485749\ttotal: 242ms\tremaining: 7.56s\n",
      "31:\tlearn: 14.7507194\ttotal: 244ms\tremaining: 7.38s\n",
      "32:\tlearn: 14.6623639\ttotal: 247ms\tremaining: 7.23s\n",
      "33:\tlearn: 14.5859946\ttotal: 249ms\tremaining: 7.07s\n",
      "34:\tlearn: 14.4866042\ttotal: 251ms\tremaining: 6.91s\n",
      "35:\tlearn: 14.4198803\ttotal: 253ms\tremaining: 6.77s\n",
      "36:\tlearn: 14.3542544\ttotal: 255ms\tremaining: 6.63s\n",
      "37:\tlearn: 14.2755055\ttotal: 257ms\tremaining: 6.5s\n",
      "38:\tlearn: 14.1712827\ttotal: 259ms\tremaining: 6.37s\n",
      "39:\tlearn: 14.1195370\ttotal: 261ms\tremaining: 6.26s\n",
      "40:\tlearn: 14.0394360\ttotal: 263ms\tremaining: 6.14s\n",
      "41:\tlearn: 13.9773399\ttotal: 265ms\tremaining: 6.03s\n",
      "42:\tlearn: 13.9099803\ttotal: 266ms\tremaining: 5.93s\n",
      "43:\tlearn: 13.8339324\ttotal: 269ms\tremaining: 5.84s\n",
      "44:\tlearn: 13.7534345\ttotal: 271ms\tremaining: 5.74s\n",
      "45:\tlearn: 13.6705488\ttotal: 272ms\tremaining: 5.65s\n",
      "46:\tlearn: 13.6033302\ttotal: 274ms\tremaining: 5.57s\n",
      "47:\tlearn: 13.5330933\ttotal: 277ms\tremaining: 5.49s\n",
      "48:\tlearn: 13.4748919\ttotal: 279ms\tremaining: 5.42s\n",
      "49:\tlearn: 13.4093853\ttotal: 281ms\tremaining: 5.34s\n",
      "50:\tlearn: 13.3690499\ttotal: 283ms\tremaining: 5.26s\n",
      "51:\tlearn: 13.2817547\ttotal: 285ms\tremaining: 5.19s\n",
      "52:\tlearn: 13.2091889\ttotal: 287ms\tremaining: 5.12s\n",
      "53:\tlearn: 13.1586448\ttotal: 289ms\tremaining: 5.05s\n",
      "54:\tlearn: 13.0821491\ttotal: 291ms\tremaining: 4.99s\n",
      "55:\tlearn: 13.0067391\ttotal: 293ms\tremaining: 4.93s\n",
      "56:\tlearn: 12.9466205\ttotal: 294ms\tremaining: 4.87s\n",
      "57:\tlearn: 12.9046225\ttotal: 296ms\tremaining: 4.81s\n",
      "58:\tlearn: 12.8214792\ttotal: 299ms\tremaining: 4.78s\n",
      "59:\tlearn: 12.7331928\ttotal: 302ms\tremaining: 4.72s\n",
      "60:\tlearn: 12.6755122\ttotal: 304ms\tremaining: 4.67s\n",
      "61:\tlearn: 12.6244687\ttotal: 305ms\tremaining: 4.62s\n",
      "62:\tlearn: 12.5562289\ttotal: 308ms\tremaining: 4.58s\n",
      "63:\tlearn: 12.4862158\ttotal: 310ms\tremaining: 4.53s\n",
      "64:\tlearn: 12.4144363\ttotal: 312ms\tremaining: 4.49s\n",
      "65:\tlearn: 12.3661254\ttotal: 314ms\tremaining: 4.44s\n",
      "66:\tlearn: 12.3069416\ttotal: 316ms\tremaining: 4.4s\n",
      "67:\tlearn: 12.2583323\ttotal: 318ms\tremaining: 4.36s\n",
      "68:\tlearn: 12.1930961\ttotal: 320ms\tremaining: 4.31s\n",
      "69:\tlearn: 12.1417921\ttotal: 321ms\tremaining: 4.27s\n",
      "70:\tlearn: 12.1006063\ttotal: 324ms\tremaining: 4.23s\n",
      "71:\tlearn: 12.0281189\ttotal: 326ms\tremaining: 4.2s\n",
      "72:\tlearn: 11.9747498\ttotal: 327ms\tremaining: 4.16s\n",
      "73:\tlearn: 11.9184864\ttotal: 329ms\tremaining: 4.12s\n",
      "74:\tlearn: 11.8588898\ttotal: 331ms\tremaining: 4.09s\n",
      "75:\tlearn: 11.8125508\ttotal: 333ms\tremaining: 4.05s\n",
      "76:\tlearn: 11.7540754\ttotal: 335ms\tremaining: 4.02s\n",
      "77:\tlearn: 11.7047328\ttotal: 337ms\tremaining: 3.98s\n",
      "78:\tlearn: 11.6464817\ttotal: 339ms\tremaining: 3.96s\n",
      "79:\tlearn: 11.5815956\ttotal: 341ms\tremaining: 3.92s\n",
      "80:\tlearn: 11.5272892\ttotal: 343ms\tremaining: 3.9s\n",
      "81:\tlearn: 11.4892645\ttotal: 345ms\tremaining: 3.87s\n",
      "82:\tlearn: 11.4594708\ttotal: 347ms\tremaining: 3.83s\n",
      "83:\tlearn: 11.4168476\ttotal: 349ms\tremaining: 3.81s\n",
      "84:\tlearn: 11.3705071\ttotal: 351ms\tremaining: 3.78s\n",
      "85:\tlearn: 11.3375180\ttotal: 353ms\tremaining: 3.75s\n",
      "86:\tlearn: 11.2842327\ttotal: 356ms\tremaining: 3.73s\n",
      "87:\tlearn: 11.2133963\ttotal: 357ms\tremaining: 3.7s\n",
      "88:\tlearn: 11.1622708\ttotal: 359ms\tremaining: 3.68s\n",
      "89:\tlearn: 11.1125153\ttotal: 361ms\tremaining: 3.65s\n",
      "90:\tlearn: 11.0733518\ttotal: 363ms\tremaining: 3.63s\n",
      "91:\tlearn: 11.0190889\ttotal: 365ms\tremaining: 3.6s\n",
      "92:\tlearn: 10.9804425\ttotal: 367ms\tremaining: 3.58s\n",
      "93:\tlearn: 10.9274532\ttotal: 369ms\tremaining: 3.55s\n",
      "94:\tlearn: 10.8908569\ttotal: 371ms\tremaining: 3.54s\n",
      "95:\tlearn: 10.8315191\ttotal: 374ms\tremaining: 3.52s\n",
      "96:\tlearn: 10.7758487\ttotal: 377ms\tremaining: 3.5s\n",
      "97:\tlearn: 10.7353753\ttotal: 379ms\tremaining: 3.49s\n",
      "98:\tlearn: 10.7113920\ttotal: 381ms\tremaining: 3.47s\n",
      "99:\tlearn: 10.6660711\ttotal: 383ms\tremaining: 3.45s\n",
      "100:\tlearn: 10.6413389\ttotal: 386ms\tremaining: 3.43s\n",
      "101:\tlearn: 10.6146120\ttotal: 388ms\tremaining: 3.42s\n",
      "102:\tlearn: 10.5760232\ttotal: 392ms\tremaining: 3.41s\n",
      "103:\tlearn: 10.5282975\ttotal: 394ms\tremaining: 3.4s\n",
      "104:\tlearn: 10.4738698\ttotal: 397ms\tremaining: 3.38s\n",
      "105:\tlearn: 10.4316880\ttotal: 399ms\tremaining: 3.36s\n",
      "106:\tlearn: 10.4002314\ttotal: 403ms\tremaining: 3.36s\n",
      "107:\tlearn: 10.3604165\ttotal: 406ms\tremaining: 3.35s\n",
      "108:\tlearn: 10.3244145\ttotal: 409ms\tremaining: 3.34s\n",
      "109:\tlearn: 10.2874778\ttotal: 412ms\tremaining: 3.33s\n",
      "110:\tlearn: 10.2360502\ttotal: 414ms\tremaining: 3.32s\n",
      "111:\tlearn: 10.1886277\ttotal: 416ms\tremaining: 3.3s\n",
      "112:\tlearn: 10.1443946\ttotal: 419ms\tremaining: 3.29s\n",
      "113:\tlearn: 10.1095007\ttotal: 421ms\tremaining: 3.27s\n",
      "114:\tlearn: 10.0823765\ttotal: 424ms\tremaining: 3.26s\n",
      "115:\tlearn: 10.0598217\ttotal: 426ms\tremaining: 3.25s\n",
      "116:\tlearn: 10.0036366\ttotal: 428ms\tremaining: 3.23s\n",
      "117:\tlearn: 9.9555816\ttotal: 430ms\tremaining: 3.21s\n",
      "118:\tlearn: 9.9210116\ttotal: 433ms\tremaining: 3.21s\n",
      "119:\tlearn: 9.8730488\ttotal: 435ms\tremaining: 3.19s\n",
      "120:\tlearn: 9.8337090\ttotal: 437ms\tremaining: 3.18s\n",
      "121:\tlearn: 9.7958620\ttotal: 440ms\tremaining: 3.17s\n",
      "122:\tlearn: 9.7489035\ttotal: 443ms\tremaining: 3.16s\n",
      "123:\tlearn: 9.7039840\ttotal: 447ms\tremaining: 3.15s\n",
      "124:\tlearn: 9.6755455\ttotal: 451ms\tremaining: 3.15s\n",
      "125:\tlearn: 9.6195340\ttotal: 454ms\tremaining: 3.15s\n",
      "126:\tlearn: 9.5587560\ttotal: 457ms\tremaining: 3.14s\n",
      "127:\tlearn: 9.4924120\ttotal: 459ms\tremaining: 3.13s\n",
      "128:\tlearn: 9.4512925\ttotal: 461ms\tremaining: 3.11s\n",
      "129:\tlearn: 9.4246967\ttotal: 463ms\tremaining: 3.1s\n",
      "130:\tlearn: 9.3857637\ttotal: 468ms\tremaining: 3.1s\n",
      "131:\tlearn: 9.3660117\ttotal: 469ms\tremaining: 3.08s\n",
      "132:\tlearn: 9.3301850\ttotal: 472ms\tremaining: 3.07s\n",
      "133:\tlearn: 9.2953664\ttotal: 473ms\tremaining: 3.06s\n",
      "134:\tlearn: 9.2427390\ttotal: 475ms\tremaining: 3.04s\n",
      "135:\tlearn: 9.1849075\ttotal: 477ms\tremaining: 3.03s\n",
      "136:\tlearn: 9.1714103\ttotal: 480ms\tremaining: 3.02s\n",
      "137:\tlearn: 9.1209608\ttotal: 483ms\tremaining: 3.02s\n",
      "138:\tlearn: 9.0674905\ttotal: 487ms\tremaining: 3.02s\n",
      "139:\tlearn: 9.0009761\ttotal: 489ms\tremaining: 3s\n",
      "140:\tlearn: 8.9653518\ttotal: 491ms\tremaining: 2.99s\n",
      "141:\tlearn: 8.9245734\ttotal: 493ms\tremaining: 2.98s\n",
      "142:\tlearn: 8.8649829\ttotal: 496ms\tremaining: 2.97s\n",
      "143:\tlearn: 8.8416044\ttotal: 499ms\tremaining: 2.97s\n",
      "144:\tlearn: 8.8047256\ttotal: 502ms\tremaining: 2.96s\n",
      "145:\tlearn: 8.7702257\ttotal: 505ms\tremaining: 2.95s\n",
      "146:\tlearn: 8.7158053\ttotal: 506ms\tremaining: 2.94s\n",
      "147:\tlearn: 8.6780718\ttotal: 508ms\tremaining: 2.93s\n",
      "148:\tlearn: 8.6428614\ttotal: 512ms\tremaining: 2.92s\n",
      "149:\tlearn: 8.6002860\ttotal: 515ms\tremaining: 2.92s\n",
      "150:\tlearn: 8.5668766\ttotal: 518ms\tremaining: 2.91s\n",
      "151:\tlearn: 8.5360994\ttotal: 520ms\tremaining: 2.9s\n",
      "152:\tlearn: 8.5210800\ttotal: 522ms\tremaining: 2.89s\n",
      "153:\tlearn: 8.4887452\ttotal: 524ms\tremaining: 2.88s\n",
      "154:\tlearn: 8.4439852\ttotal: 527ms\tremaining: 2.87s\n",
      "155:\tlearn: 8.3964969\ttotal: 531ms\tremaining: 2.87s\n",
      "156:\tlearn: 8.3692686\ttotal: 533ms\tremaining: 2.86s\n",
      "157:\tlearn: 8.3234371\ttotal: 535ms\tremaining: 2.85s\n",
      "158:\tlearn: 8.3073377\ttotal: 537ms\tremaining: 2.84s\n",
      "159:\tlearn: 8.2687039\ttotal: 539ms\tremaining: 2.83s\n",
      "160:\tlearn: 8.2504791\ttotal: 542ms\tremaining: 2.83s\n",
      "161:\tlearn: 8.2282561\ttotal: 546ms\tremaining: 2.82s\n",
      "162:\tlearn: 8.1927619\ttotal: 549ms\tremaining: 2.82s\n",
      "163:\tlearn: 8.1731253\ttotal: 550ms\tremaining: 2.81s\n",
      "164:\tlearn: 8.1561831\ttotal: 552ms\tremaining: 2.79s\n",
      "165:\tlearn: 8.1418959\ttotal: 554ms\tremaining: 2.78s\n",
      "166:\tlearn: 8.1193159\ttotal: 556ms\tremaining: 2.77s\n",
      "167:\tlearn: 8.1049461\ttotal: 559ms\tremaining: 2.77s\n",
      "168:\tlearn: 8.0888713\ttotal: 562ms\tremaining: 2.76s\n",
      "169:\tlearn: 8.0548285\ttotal: 564ms\tremaining: 2.75s\n",
      "170:\tlearn: 8.0234319\ttotal: 566ms\tremaining: 2.74s\n",
      "171:\tlearn: 7.9710620\ttotal: 568ms\tremaining: 2.73s\n",
      "172:\tlearn: 7.9464588\ttotal: 569ms\tremaining: 2.72s\n",
      "173:\tlearn: 7.9220111\ttotal: 571ms\tremaining: 2.71s\n",
      "174:\tlearn: 7.8804864\ttotal: 574ms\tremaining: 2.71s\n",
      "175:\tlearn: 7.8403281\ttotal: 578ms\tremaining: 2.71s\n",
      "176:\tlearn: 7.8064350\ttotal: 581ms\tremaining: 2.7s\n",
      "177:\tlearn: 7.7988560\ttotal: 583ms\tremaining: 2.69s\n",
      "178:\tlearn: 7.7684611\ttotal: 585ms\tremaining: 2.68s\n",
      "179:\tlearn: 7.7135214\ttotal: 588ms\tremaining: 2.68s\n",
      "180:\tlearn: 7.6910080\ttotal: 590ms\tremaining: 2.67s\n",
      "181:\tlearn: 7.6492129\ttotal: 593ms\tremaining: 2.67s\n",
      "182:\tlearn: 7.6280292\ttotal: 596ms\tremaining: 2.66s\n",
      "183:\tlearn: 7.5952360\ttotal: 599ms\tremaining: 2.66s\n",
      "184:\tlearn: 7.5714010\ttotal: 601ms\tremaining: 2.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185:\tlearn: 7.5460201\ttotal: 604ms\tremaining: 2.64s\n",
      "186:\tlearn: 7.4931735\ttotal: 608ms\tremaining: 2.64s\n",
      "187:\tlearn: 7.4530310\ttotal: 611ms\tremaining: 2.64s\n",
      "188:\tlearn: 7.4289524\ttotal: 613ms\tremaining: 2.63s\n",
      "189:\tlearn: 7.3889398\ttotal: 615ms\tremaining: 2.62s\n",
      "190:\tlearn: 7.3755251\ttotal: 617ms\tremaining: 2.61s\n",
      "191:\tlearn: 7.3430305\ttotal: 620ms\tremaining: 2.61s\n",
      "192:\tlearn: 7.3337935\ttotal: 622ms\tremaining: 2.6s\n",
      "193:\tlearn: 7.3154632\ttotal: 624ms\tremaining: 2.59s\n",
      "194:\tlearn: 7.2978887\ttotal: 627ms\tremaining: 2.59s\n",
      "195:\tlearn: 7.2587311\ttotal: 629ms\tremaining: 2.58s\n",
      "196:\tlearn: 7.2260645\ttotal: 631ms\tremaining: 2.57s\n",
      "197:\tlearn: 7.2188281\ttotal: 635ms\tremaining: 2.57s\n",
      "198:\tlearn: 7.1677533\ttotal: 638ms\tremaining: 2.57s\n",
      "199:\tlearn: 7.1340878\ttotal: 641ms\tremaining: 2.56s\n",
      "200:\tlearn: 7.0961700\ttotal: 643ms\tremaining: 2.56s\n",
      "201:\tlearn: 7.0916131\ttotal: 645ms\tremaining: 2.55s\n",
      "202:\tlearn: 7.0764239\ttotal: 647ms\tremaining: 2.54s\n",
      "203:\tlearn: 7.0706749\ttotal: 649ms\tremaining: 2.53s\n",
      "204:\tlearn: 7.0315679\ttotal: 653ms\tremaining: 2.53s\n",
      "205:\tlearn: 7.0230834\ttotal: 657ms\tremaining: 2.53s\n",
      "206:\tlearn: 6.9951925\ttotal: 659ms\tremaining: 2.52s\n",
      "207:\tlearn: 6.9615740\ttotal: 661ms\tremaining: 2.52s\n",
      "208:\tlearn: 6.9185438\ttotal: 663ms\tremaining: 2.51s\n",
      "209:\tlearn: 6.8678152\ttotal: 665ms\tremaining: 2.5s\n",
      "210:\tlearn: 6.8600042\ttotal: 669ms\tremaining: 2.5s\n",
      "211:\tlearn: 6.8393199\ttotal: 672ms\tremaining: 2.5s\n",
      "212:\tlearn: 6.8310200\ttotal: 674ms\tremaining: 2.49s\n",
      "213:\tlearn: 6.8212319\ttotal: 676ms\tremaining: 2.48s\n",
      "214:\tlearn: 6.8027486\ttotal: 678ms\tremaining: 2.47s\n",
      "215:\tlearn: 6.7673291\ttotal: 680ms\tremaining: 2.47s\n",
      "216:\tlearn: 6.7597255\ttotal: 684ms\tremaining: 2.47s\n",
      "217:\tlearn: 6.7134354\ttotal: 687ms\tremaining: 2.46s\n",
      "218:\tlearn: 6.7041440\ttotal: 689ms\tremaining: 2.46s\n",
      "219:\tlearn: 6.7002512\ttotal: 690ms\tremaining: 2.45s\n",
      "220:\tlearn: 6.6922166\ttotal: 692ms\tremaining: 2.44s\n",
      "221:\tlearn: 6.6607471\ttotal: 694ms\tremaining: 2.43s\n",
      "222:\tlearn: 6.6312581\ttotal: 696ms\tremaining: 2.43s\n",
      "223:\tlearn: 6.6062538\ttotal: 699ms\tremaining: 2.42s\n",
      "224:\tlearn: 6.5764617\ttotal: 702ms\tremaining: 2.42s\n",
      "225:\tlearn: 6.5718082\ttotal: 705ms\tremaining: 2.41s\n",
      "226:\tlearn: 6.5598709\ttotal: 707ms\tremaining: 2.41s\n",
      "227:\tlearn: 6.5262408\ttotal: 709ms\tremaining: 2.4s\n",
      "228:\tlearn: 6.4968920\ttotal: 711ms\tremaining: 2.39s\n",
      "229:\tlearn: 6.4634403\ttotal: 716ms\tremaining: 2.4s\n",
      "230:\tlearn: 6.4534399\ttotal: 720ms\tremaining: 2.4s\n",
      "231:\tlearn: 6.4372585\ttotal: 722ms\tremaining: 2.39s\n",
      "232:\tlearn: 6.4311752\ttotal: 724ms\tremaining: 2.38s\n",
      "233:\tlearn: 6.3941117\ttotal: 726ms\tremaining: 2.38s\n",
      "234:\tlearn: 6.3552598\ttotal: 729ms\tremaining: 2.37s\n",
      "235:\tlearn: 6.3272351\ttotal: 733ms\tremaining: 2.37s\n",
      "236:\tlearn: 6.3003972\ttotal: 735ms\tremaining: 2.37s\n",
      "237:\tlearn: 6.2687241\ttotal: 737ms\tremaining: 2.36s\n",
      "238:\tlearn: 6.2256696\ttotal: 739ms\tremaining: 2.35s\n",
      "239:\tlearn: 6.1917971\ttotal: 741ms\tremaining: 2.35s\n",
      "240:\tlearn: 6.1504994\ttotal: 745ms\tremaining: 2.35s\n",
      "241:\tlearn: 6.1188281\ttotal: 748ms\tremaining: 2.34s\n",
      "242:\tlearn: 6.0795386\ttotal: 751ms\tremaining: 2.34s\n",
      "243:\tlearn: 6.0422896\ttotal: 753ms\tremaining: 2.33s\n",
      "244:\tlearn: 6.0115804\ttotal: 755ms\tremaining: 2.33s\n",
      "245:\tlearn: 5.9718134\ttotal: 757ms\tremaining: 2.32s\n",
      "246:\tlearn: 5.9643467\ttotal: 759ms\tremaining: 2.31s\n",
      "247:\tlearn: 5.9387273\ttotal: 763ms\tremaining: 2.31s\n",
      "248:\tlearn: 5.9327060\ttotal: 766ms\tremaining: 2.31s\n",
      "249:\tlearn: 5.8985408\ttotal: 768ms\tremaining: 2.3s\n",
      "250:\tlearn: 5.8923254\ttotal: 770ms\tremaining: 2.3s\n",
      "251:\tlearn: 5.8597855\ttotal: 772ms\tremaining: 2.29s\n",
      "252:\tlearn: 5.8263338\ttotal: 774ms\tremaining: 2.28s\n",
      "253:\tlearn: 5.7875816\ttotal: 779ms\tremaining: 2.29s\n",
      "254:\tlearn: 5.7599979\ttotal: 782ms\tremaining: 2.29s\n",
      "255:\tlearn: 5.7265423\ttotal: 784ms\tremaining: 2.28s\n",
      "256:\tlearn: 5.7210604\ttotal: 786ms\tremaining: 2.27s\n",
      "257:\tlearn: 5.6914809\ttotal: 788ms\tremaining: 2.27s\n",
      "258:\tlearn: 5.6761032\ttotal: 790ms\tremaining: 2.26s\n",
      "259:\tlearn: 5.6697001\ttotal: 794ms\tremaining: 2.26s\n",
      "260:\tlearn: 5.6301245\ttotal: 798ms\tremaining: 2.26s\n",
      "261:\tlearn: 5.6226561\ttotal: 801ms\tremaining: 2.26s\n",
      "262:\tlearn: 5.5920512\ttotal: 803ms\tremaining: 2.25s\n",
      "263:\tlearn: 5.5593522\ttotal: 805ms\tremaining: 2.25s\n",
      "264:\tlearn: 5.5368072\ttotal: 810ms\tremaining: 2.25s\n",
      "265:\tlearn: 5.5054193\ttotal: 813ms\tremaining: 2.24s\n",
      "266:\tlearn: 5.4800806\ttotal: 816ms\tremaining: 2.24s\n",
      "267:\tlearn: 5.4459621\ttotal: 818ms\tremaining: 2.23s\n",
      "268:\tlearn: 5.4412193\ttotal: 820ms\tremaining: 2.23s\n",
      "269:\tlearn: 5.4134043\ttotal: 824ms\tremaining: 2.23s\n",
      "270:\tlearn: 5.3725885\ttotal: 827ms\tremaining: 2.22s\n",
      "271:\tlearn: 5.3382251\ttotal: 830ms\tremaining: 2.22s\n",
      "272:\tlearn: 5.3038279\ttotal: 832ms\tremaining: 2.21s\n",
      "273:\tlearn: 5.2655992\ttotal: 834ms\tremaining: 2.21s\n",
      "274:\tlearn: 5.2290365\ttotal: 836ms\tremaining: 2.2s\n",
      "275:\tlearn: 5.2248927\ttotal: 839ms\tremaining: 2.2s\n",
      "276:\tlearn: 5.1886478\ttotal: 842ms\tremaining: 2.2s\n",
      "277:\tlearn: 5.1602429\ttotal: 846ms\tremaining: 2.2s\n",
      "278:\tlearn: 5.1506214\ttotal: 848ms\tremaining: 2.19s\n",
      "279:\tlearn: 5.1299291\ttotal: 850ms\tremaining: 2.18s\n",
      "280:\tlearn: 5.1258323\ttotal: 852ms\tremaining: 2.18s\n",
      "281:\tlearn: 5.0993957\ttotal: 855ms\tremaining: 2.18s\n",
      "282:\tlearn: 5.0894370\ttotal: 862ms\tremaining: 2.18s\n",
      "283:\tlearn: 5.0605047\ttotal: 864ms\tremaining: 2.18s\n",
      "284:\tlearn: 5.0264987\ttotal: 866ms\tremaining: 2.17s\n",
      "285:\tlearn: 5.0018787\ttotal: 869ms\tremaining: 2.17s\n",
      "286:\tlearn: 4.9717932\ttotal: 874ms\tremaining: 2.17s\n",
      "287:\tlearn: 4.9465141\ttotal: 877ms\tremaining: 2.17s\n",
      "288:\tlearn: 4.9189585\ttotal: 879ms\tremaining: 2.16s\n",
      "289:\tlearn: 4.8831657\ttotal: 881ms\tremaining: 2.16s\n",
      "290:\tlearn: 4.8565387\ttotal: 884ms\tremaining: 2.15s\n",
      "291:\tlearn: 4.8179611\ttotal: 890ms\tremaining: 2.16s\n",
      "292:\tlearn: 4.7897435\ttotal: 893ms\tremaining: 2.15s\n",
      "293:\tlearn: 4.7609322\ttotal: 895ms\tremaining: 2.15s\n",
      "294:\tlearn: 4.7575444\ttotal: 897ms\tremaining: 2.14s\n",
      "295:\tlearn: 4.7284288\ttotal: 900ms\tremaining: 2.14s\n",
      "296:\tlearn: 4.6957257\ttotal: 906ms\tremaining: 2.14s\n",
      "297:\tlearn: 4.6625842\ttotal: 909ms\tremaining: 2.14s\n",
      "298:\tlearn: 4.6395246\ttotal: 912ms\tremaining: 2.14s\n",
      "299:\tlearn: 4.6057783\ttotal: 914ms\tremaining: 2.13s\n",
      "300:\tlearn: 4.5818886\ttotal: 920ms\tremaining: 2.14s\n",
      "301:\tlearn: 4.5526810\ttotal: 923ms\tremaining: 2.13s\n",
      "302:\tlearn: 4.5196936\ttotal: 925ms\tremaining: 2.13s\n",
      "303:\tlearn: 4.4965065\ttotal: 928ms\tremaining: 2.12s\n",
      "304:\tlearn: 4.4631926\ttotal: 931ms\tremaining: 2.12s\n",
      "305:\tlearn: 4.4519241\ttotal: 935ms\tremaining: 2.12s\n",
      "306:\tlearn: 4.4359849\ttotal: 938ms\tremaining: 2.12s\n",
      "307:\tlearn: 4.4254749\ttotal: 940ms\tremaining: 2.11s\n",
      "308:\tlearn: 4.4044932\ttotal: 942ms\tremaining: 2.11s\n",
      "309:\tlearn: 4.3765096\ttotal: 944ms\tremaining: 2.1s\n",
      "310:\tlearn: 4.3614489\ttotal: 949ms\tremaining: 2.1s\n",
      "311:\tlearn: 4.3317492\ttotal: 953ms\tremaining: 2.1s\n",
      "312:\tlearn: 4.3133971\ttotal: 955ms\tremaining: 2.1s\n",
      "313:\tlearn: 4.2904131\ttotal: 957ms\tremaining: 2.09s\n",
      "314:\tlearn: 4.2657743\ttotal: 959ms\tremaining: 2.09s\n",
      "315:\tlearn: 4.2367777\ttotal: 963ms\tremaining: 2.08s\n",
      "316:\tlearn: 4.2237609\ttotal: 967ms\tremaining: 2.08s\n",
      "317:\tlearn: 4.2181650\ttotal: 969ms\tremaining: 2.08s\n",
      "318:\tlearn: 4.2048007\ttotal: 971ms\tremaining: 2.07s\n",
      "319:\tlearn: 4.1718341\ttotal: 973ms\tremaining: 2.07s\n",
      "320:\tlearn: 4.1691646\ttotal: 975ms\tremaining: 2.06s\n",
      "321:\tlearn: 4.1406349\ttotal: 978ms\tremaining: 2.06s\n",
      "322:\tlearn: 4.1191573\ttotal: 980ms\tremaining: 2.05s\n",
      "323:\tlearn: 4.1156219\ttotal: 983ms\tremaining: 2.05s\n",
      "324:\tlearn: 4.1061258\ttotal: 984ms\tremaining: 2.04s\n",
      "325:\tlearn: 4.0854217\ttotal: 987ms\tremaining: 2.04s\n",
      "326:\tlearn: 4.0735275\ttotal: 989ms\tremaining: 2.04s\n",
      "327:\tlearn: 4.0489304\ttotal: 991ms\tremaining: 2.03s\n",
      "328:\tlearn: 4.0230628\ttotal: 995ms\tremaining: 2.03s\n",
      "329:\tlearn: 4.0006688\ttotal: 997ms\tremaining: 2.02s\n",
      "330:\tlearn: 3.9909861\ttotal: 1s\tremaining: 2.02s\n",
      "331:\tlearn: 3.9736321\ttotal: 1s\tremaining: 2.02s\n",
      "332:\tlearn: 3.9486992\ttotal: 1s\tremaining: 2.01s\n",
      "333:\tlearn: 3.9234640\ttotal: 1.01s\tremaining: 2.01s\n",
      "334:\tlearn: 3.9002677\ttotal: 1.01s\tremaining: 2.01s\n",
      "335:\tlearn: 3.8887345\ttotal: 1.01s\tremaining: 2s\n",
      "336:\tlearn: 3.8703491\ttotal: 1.02s\tremaining: 2s\n",
      "337:\tlearn: 3.8677207\ttotal: 1.02s\tremaining: 2s\n",
      "338:\tlearn: 3.8399485\ttotal: 1.02s\tremaining: 1.99s\n",
      "339:\tlearn: 3.8299758\ttotal: 1.02s\tremaining: 1.99s\n",
      "340:\tlearn: 3.7990976\ttotal: 1.03s\tremaining: 1.98s\n",
      "341:\tlearn: 3.7853072\ttotal: 1.03s\tremaining: 1.98s\n",
      "342:\tlearn: 3.7741512\ttotal: 1.03s\tremaining: 1.97s\n",
      "343:\tlearn: 3.7535605\ttotal: 1.03s\tremaining: 1.97s\n",
      "344:\tlearn: 3.7473294\ttotal: 1.03s\tremaining: 1.96s\n",
      "345:\tlearn: 3.7290478\ttotal: 1.03s\tremaining: 1.96s\n",
      "346:\tlearn: 3.7143980\ttotal: 1.04s\tremaining: 1.95s\n",
      "347:\tlearn: 3.6882534\ttotal: 1.04s\tremaining: 1.95s\n",
      "348:\tlearn: 3.6765436\ttotal: 1.04s\tremaining: 1.94s\n",
      "349:\tlearn: 3.6513685\ttotal: 1.04s\tremaining: 1.94s\n",
      "350:\tlearn: 3.6293025\ttotal: 1.05s\tremaining: 1.94s\n",
      "351:\tlearn: 3.6102290\ttotal: 1.05s\tremaining: 1.93s\n",
      "352:\tlearn: 3.6050461\ttotal: 1.05s\tremaining: 1.93s\n",
      "353:\tlearn: 3.5838714\ttotal: 1.05s\tremaining: 1.92s\n",
      "354:\tlearn: 3.5658575\ttotal: 1.06s\tremaining: 1.92s\n",
      "355:\tlearn: 3.5393698\ttotal: 1.06s\tremaining: 1.91s\n",
      "356:\tlearn: 3.5370636\ttotal: 1.06s\tremaining: 1.91s\n",
      "357:\tlearn: 3.5315679\ttotal: 1.06s\tremaining: 1.9s\n",
      "358:\tlearn: 3.5194740\ttotal: 1.06s\tremaining: 1.9s\n",
      "359:\tlearn: 3.5048028\ttotal: 1.06s\tremaining: 1.89s\n",
      "360:\tlearn: 3.4906337\ttotal: 1.07s\tremaining: 1.89s\n",
      "361:\tlearn: 3.4718591\ttotal: 1.07s\tremaining: 1.88s\n",
      "362:\tlearn: 3.4647283\ttotal: 1.07s\tremaining: 1.88s\n",
      "363:\tlearn: 3.4405764\ttotal: 1.07s\tremaining: 1.88s\n",
      "364:\tlearn: 3.4231331\ttotal: 1.07s\tremaining: 1.87s\n",
      "365:\tlearn: 3.4052821\ttotal: 1.08s\tremaining: 1.86s\n",
      "366:\tlearn: 3.3875160\ttotal: 1.08s\tremaining: 1.86s\n",
      "367:\tlearn: 3.3774456\ttotal: 1.08s\tremaining: 1.86s\n",
      "368:\tlearn: 3.3594975\ttotal: 1.08s\tremaining: 1.85s\n",
      "369:\tlearn: 3.3395299\ttotal: 1.08s\tremaining: 1.85s\n",
      "370:\tlearn: 3.3187980\ttotal: 1.09s\tremaining: 1.84s\n",
      "371:\tlearn: 3.3022514\ttotal: 1.09s\tremaining: 1.84s\n",
      "372:\tlearn: 3.2884299\ttotal: 1.11s\tremaining: 1.86s\n",
      "373:\tlearn: 3.2747200\ttotal: 1.11s\tremaining: 1.86s\n",
      "374:\tlearn: 3.2559638\ttotal: 1.11s\tremaining: 1.85s\n",
      "375:\tlearn: 3.2371642\ttotal: 1.11s\tremaining: 1.85s\n",
      "376:\tlearn: 3.2219014\ttotal: 1.11s\tremaining: 1.84s\n",
      "377:\tlearn: 3.2059905\ttotal: 1.12s\tremaining: 1.84s\n",
      "378:\tlearn: 3.1891422\ttotal: 1.12s\tremaining: 1.83s\n",
      "379:\tlearn: 3.1670464\ttotal: 1.12s\tremaining: 1.83s\n",
      "380:\tlearn: 3.1575257\ttotal: 1.12s\tremaining: 1.82s\n",
      "381:\tlearn: 3.1549857\ttotal: 1.13s\tremaining: 1.82s\n",
      "382:\tlearn: 3.1489809\ttotal: 1.13s\tremaining: 1.82s\n",
      "383:\tlearn: 3.1318010\ttotal: 1.13s\tremaining: 1.81s\n",
      "384:\tlearn: 3.1155261\ttotal: 1.13s\tremaining: 1.81s\n",
      "385:\tlearn: 3.1095022\ttotal: 1.13s\tremaining: 1.8s\n",
      "386:\tlearn: 3.0946769\ttotal: 1.14s\tremaining: 1.8s\n",
      "387:\tlearn: 3.0821193\ttotal: 1.14s\tremaining: 1.79s\n",
      "388:\tlearn: 3.0702169\ttotal: 1.14s\tremaining: 1.79s\n",
      "389:\tlearn: 3.0496293\ttotal: 1.14s\tremaining: 1.79s\n",
      "390:\tlearn: 3.0424703\ttotal: 1.15s\tremaining: 1.78s\n",
      "391:\tlearn: 3.0386211\ttotal: 1.15s\tremaining: 1.78s\n",
      "392:\tlearn: 3.0192093\ttotal: 1.15s\tremaining: 1.78s\n",
      "393:\tlearn: 3.0167228\ttotal: 1.15s\tremaining: 1.77s\n",
      "394:\tlearn: 3.0020128\ttotal: 1.15s\tremaining: 1.77s\n",
      "395:\tlearn: 2.9957705\ttotal: 1.16s\tremaining: 1.76s\n",
      "396:\tlearn: 2.9935105\ttotal: 1.16s\tremaining: 1.76s\n",
      "397:\tlearn: 2.9817851\ttotal: 1.16s\tremaining: 1.75s\n",
      "398:\tlearn: 2.9671889\ttotal: 1.16s\tremaining: 1.75s\n",
      "399:\tlearn: 2.9646826\ttotal: 1.16s\tremaining: 1.75s\n",
      "400:\tlearn: 2.9479113\ttotal: 1.17s\tremaining: 1.74s\n",
      "401:\tlearn: 2.9319396\ttotal: 1.17s\tremaining: 1.74s\n",
      "402:\tlearn: 2.9161094\ttotal: 1.17s\tremaining: 1.73s\n",
      "403:\tlearn: 2.9048679\ttotal: 1.17s\tremaining: 1.73s\n",
      "404:\tlearn: 2.8914054\ttotal: 1.17s\tremaining: 1.73s\n",
      "405:\tlearn: 2.8789156\ttotal: 1.18s\tremaining: 1.72s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406:\tlearn: 2.8645654\ttotal: 1.18s\tremaining: 1.72s\n",
      "407:\tlearn: 2.8541505\ttotal: 1.18s\tremaining: 1.72s\n",
      "408:\tlearn: 2.8470737\ttotal: 1.19s\tremaining: 1.71s\n",
      "409:\tlearn: 2.8311844\ttotal: 1.19s\tremaining: 1.71s\n",
      "410:\tlearn: 2.8194236\ttotal: 1.19s\tremaining: 1.71s\n",
      "411:\tlearn: 2.8022094\ttotal: 1.19s\tremaining: 1.7s\n",
      "412:\tlearn: 2.7824607\ttotal: 1.2s\tremaining: 1.7s\n",
      "413:\tlearn: 2.7803652\ttotal: 1.2s\tremaining: 1.7s\n",
      "414:\tlearn: 2.7650138\ttotal: 1.2s\tremaining: 1.7s\n",
      "415:\tlearn: 2.7487648\ttotal: 1.2s\tremaining: 1.69s\n",
      "416:\tlearn: 2.7345650\ttotal: 1.21s\tremaining: 1.69s\n",
      "417:\tlearn: 2.7237384\ttotal: 1.21s\tremaining: 1.68s\n",
      "418:\tlearn: 2.7092532\ttotal: 1.21s\tremaining: 1.68s\n",
      "419:\tlearn: 2.6986326\ttotal: 1.21s\tremaining: 1.68s\n",
      "420:\tlearn: 2.6869564\ttotal: 1.22s\tremaining: 1.67s\n",
      "421:\tlearn: 2.6794549\ttotal: 1.22s\tremaining: 1.67s\n",
      "422:\tlearn: 2.6659804\ttotal: 1.22s\tremaining: 1.66s\n",
      "423:\tlearn: 2.6523859\ttotal: 1.22s\tremaining: 1.66s\n",
      "424:\tlearn: 2.6392623\ttotal: 1.22s\tremaining: 1.65s\n",
      "425:\tlearn: 2.6273101\ttotal: 1.23s\tremaining: 1.65s\n",
      "426:\tlearn: 2.6156892\ttotal: 1.23s\tremaining: 1.65s\n",
      "427:\tlearn: 2.6021356\ttotal: 1.23s\tremaining: 1.64s\n",
      "428:\tlearn: 2.5962632\ttotal: 1.23s\tremaining: 1.64s\n",
      "429:\tlearn: 2.5813736\ttotal: 1.23s\tremaining: 1.63s\n",
      "430:\tlearn: 2.5781274\ttotal: 1.24s\tremaining: 1.63s\n",
      "431:\tlearn: 2.5613413\ttotal: 1.24s\tremaining: 1.63s\n",
      "432:\tlearn: 2.5484972\ttotal: 1.24s\tremaining: 1.62s\n",
      "433:\tlearn: 2.5428179\ttotal: 1.24s\tremaining: 1.62s\n",
      "434:\tlearn: 2.5351242\ttotal: 1.24s\tremaining: 1.61s\n",
      "435:\tlearn: 2.5216192\ttotal: 1.24s\tremaining: 1.61s\n",
      "436:\tlearn: 2.5106568\ttotal: 1.25s\tremaining: 1.61s\n",
      "437:\tlearn: 2.4983325\ttotal: 1.25s\tremaining: 1.6s\n",
      "438:\tlearn: 2.4865432\ttotal: 1.25s\tremaining: 1.6s\n",
      "439:\tlearn: 2.4841421\ttotal: 1.25s\tremaining: 1.59s\n",
      "440:\tlearn: 2.4814647\ttotal: 1.25s\tremaining: 1.59s\n",
      "441:\tlearn: 2.4626931\ttotal: 1.26s\tremaining: 1.59s\n",
      "442:\tlearn: 2.4570200\ttotal: 1.26s\tremaining: 1.58s\n",
      "443:\tlearn: 2.4502086\ttotal: 1.26s\tremaining: 1.58s\n",
      "444:\tlearn: 2.4451086\ttotal: 1.26s\tremaining: 1.57s\n",
      "445:\tlearn: 2.4395935\ttotal: 1.26s\tremaining: 1.57s\n",
      "446:\tlearn: 2.4347782\ttotal: 1.27s\tremaining: 1.57s\n",
      "447:\tlearn: 2.4211881\ttotal: 1.27s\tremaining: 1.56s\n",
      "448:\tlearn: 2.4054965\ttotal: 1.27s\tremaining: 1.56s\n",
      "449:\tlearn: 2.3967708\ttotal: 1.27s\tremaining: 1.55s\n",
      "450:\tlearn: 2.3880077\ttotal: 1.27s\tremaining: 1.55s\n",
      "451:\tlearn: 2.3809803\ttotal: 1.28s\tremaining: 1.55s\n",
      "452:\tlearn: 2.3724456\ttotal: 1.28s\tremaining: 1.54s\n",
      "453:\tlearn: 2.3573253\ttotal: 1.28s\tremaining: 1.54s\n",
      "454:\tlearn: 2.3459637\ttotal: 1.28s\tremaining: 1.53s\n",
      "455:\tlearn: 2.3429465\ttotal: 1.28s\tremaining: 1.53s\n",
      "456:\tlearn: 2.3313348\ttotal: 1.28s\tremaining: 1.53s\n",
      "457:\tlearn: 2.3182356\ttotal: 1.29s\tremaining: 1.52s\n",
      "458:\tlearn: 2.3078972\ttotal: 1.29s\tremaining: 1.52s\n",
      "459:\tlearn: 2.3031869\ttotal: 1.29s\tremaining: 1.52s\n",
      "460:\tlearn: 2.2926078\ttotal: 1.29s\tremaining: 1.51s\n",
      "461:\tlearn: 2.2864466\ttotal: 1.3s\tremaining: 1.51s\n",
      "462:\tlearn: 2.2696774\ttotal: 1.3s\tremaining: 1.5s\n",
      "463:\tlearn: 2.2636327\ttotal: 1.3s\tremaining: 1.5s\n",
      "464:\tlearn: 2.2614472\ttotal: 1.3s\tremaining: 1.5s\n",
      "465:\tlearn: 2.2505764\ttotal: 1.3s\tremaining: 1.49s\n",
      "466:\tlearn: 2.2385640\ttotal: 1.3s\tremaining: 1.49s\n",
      "467:\tlearn: 2.2370039\ttotal: 1.31s\tremaining: 1.49s\n",
      "468:\tlearn: 2.2244760\ttotal: 1.31s\tremaining: 1.48s\n",
      "469:\tlearn: 2.2120379\ttotal: 1.31s\tremaining: 1.48s\n",
      "470:\tlearn: 2.1998097\ttotal: 1.31s\tremaining: 1.48s\n",
      "471:\tlearn: 2.1875661\ttotal: 1.31s\tremaining: 1.47s\n",
      "472:\tlearn: 2.1853693\ttotal: 1.32s\tremaining: 1.47s\n",
      "473:\tlearn: 2.1755699\ttotal: 1.32s\tremaining: 1.46s\n",
      "474:\tlearn: 2.1724937\ttotal: 1.32s\tremaining: 1.46s\n",
      "475:\tlearn: 2.1686385\ttotal: 1.32s\tremaining: 1.46s\n",
      "476:\tlearn: 2.1585012\ttotal: 1.32s\tremaining: 1.45s\n",
      "477:\tlearn: 2.1465316\ttotal: 1.33s\tremaining: 1.45s\n",
      "478:\tlearn: 2.1341729\ttotal: 1.33s\tremaining: 1.45s\n",
      "479:\tlearn: 2.1255733\ttotal: 1.33s\tremaining: 1.44s\n",
      "480:\tlearn: 2.1229286\ttotal: 1.33s\tremaining: 1.44s\n",
      "481:\tlearn: 2.1134246\ttotal: 1.33s\tremaining: 1.43s\n",
      "482:\tlearn: 2.1003627\ttotal: 1.34s\tremaining: 1.43s\n",
      "483:\tlearn: 2.0959950\ttotal: 1.34s\tremaining: 1.43s\n",
      "484:\tlearn: 2.0923707\ttotal: 1.34s\tremaining: 1.42s\n",
      "485:\tlearn: 2.0897193\ttotal: 1.34s\tremaining: 1.42s\n",
      "486:\tlearn: 2.0812614\ttotal: 1.34s\tremaining: 1.42s\n",
      "487:\tlearn: 2.0790448\ttotal: 1.35s\tremaining: 1.41s\n",
      "488:\tlearn: 2.0680409\ttotal: 1.35s\tremaining: 1.41s\n",
      "489:\tlearn: 2.0622549\ttotal: 1.35s\tremaining: 1.41s\n",
      "490:\tlearn: 2.0549555\ttotal: 1.35s\tremaining: 1.4s\n",
      "491:\tlearn: 2.0439444\ttotal: 1.35s\tremaining: 1.4s\n",
      "492:\tlearn: 2.0288098\ttotal: 1.36s\tremaining: 1.39s\n",
      "493:\tlearn: 2.0261744\ttotal: 1.36s\tremaining: 1.39s\n",
      "494:\tlearn: 2.0167633\ttotal: 1.36s\tremaining: 1.39s\n",
      "495:\tlearn: 2.0129414\ttotal: 1.36s\tremaining: 1.38s\n",
      "496:\tlearn: 2.0032816\ttotal: 1.36s\tremaining: 1.38s\n",
      "497:\tlearn: 1.9933318\ttotal: 1.36s\tremaining: 1.38s\n",
      "498:\tlearn: 1.9840317\ttotal: 1.37s\tremaining: 1.37s\n",
      "499:\tlearn: 1.9802712\ttotal: 1.37s\tremaining: 1.37s\n",
      "500:\tlearn: 1.9745183\ttotal: 1.37s\tremaining: 1.36s\n",
      "501:\tlearn: 1.9649780\ttotal: 1.37s\tremaining: 1.36s\n",
      "502:\tlearn: 1.9553614\ttotal: 1.38s\tremaining: 1.36s\n",
      "503:\tlearn: 1.9415205\ttotal: 1.38s\tremaining: 1.36s\n",
      "504:\tlearn: 1.9350975\ttotal: 1.38s\tremaining: 1.35s\n",
      "505:\tlearn: 1.9252642\ttotal: 1.38s\tremaining: 1.35s\n",
      "506:\tlearn: 1.9113028\ttotal: 1.38s\tremaining: 1.35s\n",
      "507:\tlearn: 1.9041720\ttotal: 1.39s\tremaining: 1.34s\n",
      "508:\tlearn: 1.8996572\ttotal: 1.39s\tremaining: 1.34s\n",
      "509:\tlearn: 1.8980625\ttotal: 1.39s\tremaining: 1.34s\n",
      "510:\tlearn: 1.8856459\ttotal: 1.39s\tremaining: 1.33s\n",
      "511:\tlearn: 1.8843637\ttotal: 1.4s\tremaining: 1.33s\n",
      "512:\tlearn: 1.8739790\ttotal: 1.4s\tremaining: 1.33s\n",
      "513:\tlearn: 1.8657073\ttotal: 1.4s\tremaining: 1.32s\n",
      "514:\tlearn: 1.8540264\ttotal: 1.4s\tremaining: 1.32s\n",
      "515:\tlearn: 1.8525072\ttotal: 1.4s\tremaining: 1.32s\n",
      "516:\tlearn: 1.8436070\ttotal: 1.41s\tremaining: 1.31s\n",
      "517:\tlearn: 1.8337136\ttotal: 1.41s\tremaining: 1.31s\n",
      "518:\tlearn: 1.8241066\ttotal: 1.41s\tremaining: 1.31s\n",
      "519:\tlearn: 1.8125316\ttotal: 1.41s\tremaining: 1.3s\n",
      "520:\tlearn: 1.8052880\ttotal: 1.41s\tremaining: 1.3s\n",
      "521:\tlearn: 1.7934118\ttotal: 1.42s\tremaining: 1.3s\n",
      "522:\tlearn: 1.7866614\ttotal: 1.42s\tremaining: 1.29s\n",
      "523:\tlearn: 1.7782616\ttotal: 1.42s\tremaining: 1.29s\n",
      "524:\tlearn: 1.7690599\ttotal: 1.42s\tremaining: 1.29s\n",
      "525:\tlearn: 1.7606620\ttotal: 1.42s\tremaining: 1.28s\n",
      "526:\tlearn: 1.7513214\ttotal: 1.43s\tremaining: 1.28s\n",
      "527:\tlearn: 1.7407441\ttotal: 1.43s\tremaining: 1.28s\n",
      "528:\tlearn: 1.7323341\ttotal: 1.43s\tremaining: 1.27s\n",
      "529:\tlearn: 1.7279138\ttotal: 1.43s\tremaining: 1.27s\n",
      "530:\tlearn: 1.7198971\ttotal: 1.44s\tremaining: 1.27s\n",
      "531:\tlearn: 1.7082744\ttotal: 1.44s\tremaining: 1.26s\n",
      "532:\tlearn: 1.7032456\ttotal: 1.44s\tremaining: 1.26s\n",
      "533:\tlearn: 1.6934589\ttotal: 1.44s\tremaining: 1.26s\n",
      "534:\tlearn: 1.6896080\ttotal: 1.45s\tremaining: 1.26s\n",
      "535:\tlearn: 1.6834006\ttotal: 1.45s\tremaining: 1.25s\n",
      "536:\tlearn: 1.6756058\ttotal: 1.45s\tremaining: 1.25s\n",
      "537:\tlearn: 1.6706241\ttotal: 1.45s\tremaining: 1.25s\n",
      "538:\tlearn: 1.6626710\ttotal: 1.46s\tremaining: 1.24s\n",
      "539:\tlearn: 1.6500696\ttotal: 1.46s\tremaining: 1.24s\n",
      "540:\tlearn: 1.6454709\ttotal: 1.46s\tremaining: 1.24s\n",
      "541:\tlearn: 1.6391369\ttotal: 1.46s\tremaining: 1.24s\n",
      "542:\tlearn: 1.6308900\ttotal: 1.47s\tremaining: 1.23s\n",
      "543:\tlearn: 1.6231886\ttotal: 1.47s\tremaining: 1.23s\n",
      "544:\tlearn: 1.6149264\ttotal: 1.47s\tremaining: 1.23s\n",
      "545:\tlearn: 1.6136091\ttotal: 1.47s\tremaining: 1.23s\n",
      "546:\tlearn: 1.6048166\ttotal: 1.48s\tremaining: 1.22s\n",
      "547:\tlearn: 1.5991739\ttotal: 1.48s\tremaining: 1.22s\n",
      "548:\tlearn: 1.5943950\ttotal: 1.48s\tremaining: 1.22s\n",
      "549:\tlearn: 1.5920945\ttotal: 1.48s\tremaining: 1.21s\n",
      "550:\tlearn: 1.5894935\ttotal: 1.49s\tremaining: 1.21s\n",
      "551:\tlearn: 1.5845287\ttotal: 1.49s\tremaining: 1.21s\n",
      "552:\tlearn: 1.5805958\ttotal: 1.49s\tremaining: 1.2s\n",
      "553:\tlearn: 1.5705672\ttotal: 1.49s\tremaining: 1.2s\n",
      "554:\tlearn: 1.5637903\ttotal: 1.49s\tremaining: 1.2s\n",
      "555:\tlearn: 1.5537539\ttotal: 1.5s\tremaining: 1.2s\n",
      "556:\tlearn: 1.5499482\ttotal: 1.5s\tremaining: 1.19s\n",
      "557:\tlearn: 1.5439441\ttotal: 1.5s\tremaining: 1.19s\n",
      "558:\tlearn: 1.5329575\ttotal: 1.5s\tremaining: 1.19s\n",
      "559:\tlearn: 1.5246299\ttotal: 1.5s\tremaining: 1.18s\n",
      "560:\tlearn: 1.5199139\ttotal: 1.51s\tremaining: 1.18s\n",
      "561:\tlearn: 1.5147676\ttotal: 1.51s\tremaining: 1.18s\n",
      "562:\tlearn: 1.5117964\ttotal: 1.51s\tremaining: 1.17s\n",
      "563:\tlearn: 1.5054551\ttotal: 1.52s\tremaining: 1.17s\n",
      "564:\tlearn: 1.5026739\ttotal: 1.52s\tremaining: 1.17s\n",
      "565:\tlearn: 1.4951997\ttotal: 1.52s\tremaining: 1.17s\n",
      "566:\tlearn: 1.4885331\ttotal: 1.53s\tremaining: 1.17s\n",
      "567:\tlearn: 1.4834911\ttotal: 1.53s\tremaining: 1.16s\n",
      "568:\tlearn: 1.4800550\ttotal: 1.53s\tremaining: 1.16s\n",
      "569:\tlearn: 1.4727641\ttotal: 1.54s\tremaining: 1.16s\n",
      "570:\tlearn: 1.4681880\ttotal: 1.54s\tremaining: 1.16s\n",
      "571:\tlearn: 1.4600226\ttotal: 1.54s\tremaining: 1.16s\n",
      "572:\tlearn: 1.4535245\ttotal: 1.55s\tremaining: 1.15s\n",
      "573:\tlearn: 1.4467775\ttotal: 1.55s\tremaining: 1.15s\n",
      "574:\tlearn: 1.4385631\ttotal: 1.55s\tremaining: 1.15s\n",
      "575:\tlearn: 1.4374519\ttotal: 1.56s\tremaining: 1.15s\n",
      "576:\tlearn: 1.4309762\ttotal: 1.56s\tremaining: 1.14s\n",
      "577:\tlearn: 1.4273986\ttotal: 1.56s\tremaining: 1.14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578:\tlearn: 1.4221431\ttotal: 1.57s\tremaining: 1.14s\n",
      "579:\tlearn: 1.4191187\ttotal: 1.57s\tremaining: 1.14s\n",
      "580:\tlearn: 1.4167612\ttotal: 1.57s\tremaining: 1.13s\n",
      "581:\tlearn: 1.4145932\ttotal: 1.57s\tremaining: 1.13s\n",
      "582:\tlearn: 1.4069849\ttotal: 1.58s\tremaining: 1.13s\n",
      "583:\tlearn: 1.4061183\ttotal: 1.58s\tremaining: 1.13s\n",
      "584:\tlearn: 1.3997849\ttotal: 1.58s\tremaining: 1.12s\n",
      "585:\tlearn: 1.3951537\ttotal: 1.59s\tremaining: 1.12s\n",
      "586:\tlearn: 1.3874039\ttotal: 1.59s\tremaining: 1.12s\n",
      "587:\tlearn: 1.3856914\ttotal: 1.59s\tremaining: 1.12s\n",
      "588:\tlearn: 1.3787890\ttotal: 1.6s\tremaining: 1.11s\n",
      "589:\tlearn: 1.3724885\ttotal: 1.6s\tremaining: 1.11s\n",
      "590:\tlearn: 1.3649375\ttotal: 1.6s\tremaining: 1.11s\n",
      "591:\tlearn: 1.3632697\ttotal: 1.61s\tremaining: 1.11s\n",
      "592:\tlearn: 1.3603087\ttotal: 1.61s\tremaining: 1.11s\n",
      "593:\tlearn: 1.3534624\ttotal: 1.61s\tremaining: 1.1s\n",
      "594:\tlearn: 1.3511910\ttotal: 1.62s\tremaining: 1.1s\n",
      "595:\tlearn: 1.3489491\ttotal: 1.62s\tremaining: 1.1s\n",
      "596:\tlearn: 1.3411573\ttotal: 1.62s\tremaining: 1.1s\n",
      "597:\tlearn: 1.3341139\ttotal: 1.63s\tremaining: 1.09s\n",
      "598:\tlearn: 1.3240459\ttotal: 1.63s\tremaining: 1.09s\n",
      "599:\tlearn: 1.3175086\ttotal: 1.63s\tremaining: 1.09s\n",
      "600:\tlearn: 1.3111116\ttotal: 1.64s\tremaining: 1.08s\n",
      "601:\tlearn: 1.3019111\ttotal: 1.64s\tremaining: 1.08s\n",
      "602:\tlearn: 1.2988289\ttotal: 1.64s\tremaining: 1.08s\n",
      "603:\tlearn: 1.2926611\ttotal: 1.65s\tremaining: 1.08s\n",
      "604:\tlearn: 1.2868652\ttotal: 1.65s\tremaining: 1.08s\n",
      "605:\tlearn: 1.2795962\ttotal: 1.65s\tremaining: 1.07s\n",
      "606:\tlearn: 1.2733074\ttotal: 1.65s\tremaining: 1.07s\n",
      "607:\tlearn: 1.2680606\ttotal: 1.66s\tremaining: 1.07s\n",
      "608:\tlearn: 1.2610153\ttotal: 1.66s\tremaining: 1.07s\n",
      "609:\tlearn: 1.2603512\ttotal: 1.66s\tremaining: 1.06s\n",
      "610:\tlearn: 1.2579163\ttotal: 1.67s\tremaining: 1.06s\n",
      "611:\tlearn: 1.2528305\ttotal: 1.67s\tremaining: 1.06s\n",
      "612:\tlearn: 1.2461969\ttotal: 1.67s\tremaining: 1.06s\n",
      "613:\tlearn: 1.2410807\ttotal: 1.68s\tremaining: 1.05s\n",
      "614:\tlearn: 1.2362790\ttotal: 1.68s\tremaining: 1.05s\n",
      "615:\tlearn: 1.2291007\ttotal: 1.68s\tremaining: 1.05s\n",
      "616:\tlearn: 1.2237471\ttotal: 1.68s\tremaining: 1.04s\n",
      "617:\tlearn: 1.2230595\ttotal: 1.69s\tremaining: 1.04s\n",
      "618:\tlearn: 1.2224276\ttotal: 1.69s\tremaining: 1.04s\n",
      "619:\tlearn: 1.2157538\ttotal: 1.69s\tremaining: 1.04s\n",
      "620:\tlearn: 1.2132979\ttotal: 1.7s\tremaining: 1.03s\n",
      "621:\tlearn: 1.2069468\ttotal: 1.7s\tremaining: 1.03s\n",
      "622:\tlearn: 1.2039964\ttotal: 1.7s\tremaining: 1.03s\n",
      "623:\tlearn: 1.1971593\ttotal: 1.71s\tremaining: 1.03s\n",
      "624:\tlearn: 1.1920982\ttotal: 1.71s\tremaining: 1.02s\n",
      "625:\tlearn: 1.1866953\ttotal: 1.71s\tremaining: 1.02s\n",
      "626:\tlearn: 1.1792260\ttotal: 1.71s\tremaining: 1.02s\n",
      "627:\tlearn: 1.1714536\ttotal: 1.72s\tremaining: 1.02s\n",
      "628:\tlearn: 1.1707464\ttotal: 1.72s\tremaining: 1.01s\n",
      "629:\tlearn: 1.1671719\ttotal: 1.72s\tremaining: 1.01s\n",
      "630:\tlearn: 1.1630658\ttotal: 1.73s\tremaining: 1.01s\n",
      "631:\tlearn: 1.1618885\ttotal: 1.73s\tremaining: 1.01s\n",
      "632:\tlearn: 1.1554392\ttotal: 1.73s\tremaining: 1s\n",
      "633:\tlearn: 1.1505492\ttotal: 1.74s\tremaining: 1s\n",
      "634:\tlearn: 1.1479012\ttotal: 1.74s\tremaining: 1000ms\n",
      "635:\tlearn: 1.1422663\ttotal: 1.74s\tremaining: 997ms\n",
      "636:\tlearn: 1.1359854\ttotal: 1.74s\tremaining: 994ms\n",
      "637:\tlearn: 1.1348965\ttotal: 1.75s\tremaining: 991ms\n",
      "638:\tlearn: 1.1337248\ttotal: 1.75s\tremaining: 988ms\n",
      "639:\tlearn: 1.1331074\ttotal: 1.75s\tremaining: 985ms\n",
      "640:\tlearn: 1.1312360\ttotal: 1.75s\tremaining: 982ms\n",
      "641:\tlearn: 1.1278648\ttotal: 1.75s\tremaining: 979ms\n",
      "642:\tlearn: 1.1227683\ttotal: 1.76s\tremaining: 976ms\n",
      "643:\tlearn: 1.1187309\ttotal: 1.76s\tremaining: 974ms\n",
      "644:\tlearn: 1.1156316\ttotal: 1.76s\tremaining: 971ms\n",
      "645:\tlearn: 1.1122553\ttotal: 1.77s\tremaining: 968ms\n",
      "646:\tlearn: 1.1070674\ttotal: 1.77s\tremaining: 965ms\n",
      "647:\tlearn: 1.1007818\ttotal: 1.77s\tremaining: 963ms\n",
      "648:\tlearn: 1.0990161\ttotal: 1.78s\tremaining: 961ms\n",
      "649:\tlearn: 1.0941143\ttotal: 1.78s\tremaining: 958ms\n",
      "650:\tlearn: 1.0887826\ttotal: 1.78s\tremaining: 955ms\n",
      "651:\tlearn: 1.0830912\ttotal: 1.78s\tremaining: 952ms\n",
      "652:\tlearn: 1.0800151\ttotal: 1.78s\tremaining: 949ms\n",
      "653:\tlearn: 1.0780614\ttotal: 1.79s\tremaining: 946ms\n",
      "654:\tlearn: 1.0769448\ttotal: 1.79s\tremaining: 943ms\n",
      "655:\tlearn: 1.0763933\ttotal: 1.79s\tremaining: 940ms\n",
      "656:\tlearn: 1.0712107\ttotal: 1.79s\tremaining: 937ms\n",
      "657:\tlearn: 1.0670915\ttotal: 1.8s\tremaining: 934ms\n",
      "658:\tlearn: 1.0617651\ttotal: 1.8s\tremaining: 931ms\n",
      "659:\tlearn: 1.0594205\ttotal: 1.8s\tremaining: 928ms\n",
      "660:\tlearn: 1.0531753\ttotal: 1.8s\tremaining: 925ms\n",
      "661:\tlearn: 1.0497941\ttotal: 1.81s\tremaining: 922ms\n",
      "662:\tlearn: 1.0449495\ttotal: 1.81s\tremaining: 920ms\n",
      "663:\tlearn: 1.0411156\ttotal: 1.81s\tremaining: 917ms\n",
      "664:\tlearn: 1.0379659\ttotal: 1.81s\tremaining: 914ms\n",
      "665:\tlearn: 1.0371218\ttotal: 1.81s\tremaining: 911ms\n",
      "666:\tlearn: 1.0332775\ttotal: 1.82s\tremaining: 908ms\n",
      "667:\tlearn: 1.0323767\ttotal: 1.82s\tremaining: 905ms\n",
      "668:\tlearn: 1.0307785\ttotal: 1.82s\tremaining: 902ms\n",
      "669:\tlearn: 1.0252335\ttotal: 1.82s\tremaining: 899ms\n",
      "670:\tlearn: 1.0223713\ttotal: 1.83s\tremaining: 896ms\n",
      "671:\tlearn: 1.0171952\ttotal: 1.83s\tremaining: 893ms\n",
      "672:\tlearn: 1.0142122\ttotal: 1.83s\tremaining: 890ms\n",
      "673:\tlearn: 1.0127641\ttotal: 1.83s\tremaining: 887ms\n",
      "674:\tlearn: 1.0075975\ttotal: 1.84s\tremaining: 884ms\n",
      "675:\tlearn: 1.0012146\ttotal: 1.84s\tremaining: 881ms\n",
      "676:\tlearn: 0.9965584\ttotal: 1.84s\tremaining: 879ms\n",
      "677:\tlearn: 0.9960720\ttotal: 1.84s\tremaining: 876ms\n",
      "678:\tlearn: 0.9912661\ttotal: 1.85s\tremaining: 874ms\n",
      "679:\tlearn: 0.9864626\ttotal: 1.85s\tremaining: 871ms\n",
      "680:\tlearn: 0.9819860\ttotal: 1.85s\tremaining: 868ms\n",
      "681:\tlearn: 0.9802042\ttotal: 1.86s\tremaining: 866ms\n",
      "682:\tlearn: 0.9769142\ttotal: 1.86s\tremaining: 864ms\n",
      "683:\tlearn: 0.9764523\ttotal: 1.86s\tremaining: 861ms\n",
      "684:\tlearn: 0.9744518\ttotal: 1.87s\tremaining: 858ms\n",
      "685:\tlearn: 0.9687427\ttotal: 1.87s\tremaining: 856ms\n",
      "686:\tlearn: 0.9631153\ttotal: 1.87s\tremaining: 853ms\n",
      "687:\tlearn: 0.9600475\ttotal: 1.88s\tremaining: 851ms\n",
      "688:\tlearn: 0.9575894\ttotal: 1.88s\tremaining: 848ms\n",
      "689:\tlearn: 0.9565973\ttotal: 1.88s\tremaining: 846ms\n",
      "690:\tlearn: 0.9544249\ttotal: 1.88s\tremaining: 843ms\n",
      "691:\tlearn: 0.9516866\ttotal: 1.89s\tremaining: 840ms\n",
      "692:\tlearn: 0.9476244\ttotal: 1.89s\tremaining: 838ms\n",
      "693:\tlearn: 0.9456063\ttotal: 1.89s\tremaining: 835ms\n",
      "694:\tlearn: 0.9404963\ttotal: 1.9s\tremaining: 833ms\n",
      "695:\tlearn: 0.9378027\ttotal: 1.9s\tremaining: 830ms\n",
      "696:\tlearn: 0.9333181\ttotal: 1.9s\tremaining: 827ms\n",
      "697:\tlearn: 0.9288141\ttotal: 1.91s\tremaining: 825ms\n",
      "698:\tlearn: 0.9269345\ttotal: 1.91s\tremaining: 823ms\n",
      "699:\tlearn: 0.9222946\ttotal: 1.91s\tremaining: 820ms\n",
      "700:\tlearn: 0.9173190\ttotal: 1.92s\tremaining: 817ms\n",
      "701:\tlearn: 0.9108350\ttotal: 1.92s\tremaining: 815ms\n",
      "702:\tlearn: 0.9064189\ttotal: 1.92s\tremaining: 812ms\n",
      "703:\tlearn: 0.9024423\ttotal: 1.93s\tremaining: 809ms\n",
      "704:\tlearn: 0.9000059\ttotal: 1.93s\tremaining: 807ms\n",
      "705:\tlearn: 0.8968954\ttotal: 1.93s\tremaining: 804ms\n",
      "706:\tlearn: 0.8909542\ttotal: 1.93s\tremaining: 801ms\n",
      "707:\tlearn: 0.8895104\ttotal: 1.94s\tremaining: 798ms\n",
      "708:\tlearn: 0.8852617\ttotal: 1.94s\tremaining: 796ms\n",
      "709:\tlearn: 0.8815992\ttotal: 1.94s\tremaining: 793ms\n",
      "710:\tlearn: 0.8775007\ttotal: 1.94s\tremaining: 791ms\n",
      "711:\tlearn: 0.8765260\ttotal: 1.95s\tremaining: 788ms\n",
      "712:\tlearn: 0.8722743\ttotal: 1.95s\tremaining: 785ms\n",
      "713:\tlearn: 0.8719364\ttotal: 1.95s\tremaining: 783ms\n",
      "714:\tlearn: 0.8669811\ttotal: 1.96s\tremaining: 780ms\n",
      "715:\tlearn: 0.8658517\ttotal: 1.96s\tremaining: 777ms\n",
      "716:\tlearn: 0.8614610\ttotal: 1.96s\tremaining: 775ms\n",
      "717:\tlearn: 0.8576220\ttotal: 1.97s\tremaining: 772ms\n",
      "718:\tlearn: 0.8519991\ttotal: 1.97s\tremaining: 769ms\n",
      "719:\tlearn: 0.8468969\ttotal: 1.97s\tremaining: 767ms\n",
      "720:\tlearn: 0.8440295\ttotal: 1.97s\tremaining: 764ms\n",
      "721:\tlearn: 0.8426690\ttotal: 1.98s\tremaining: 761ms\n",
      "722:\tlearn: 0.8415642\ttotal: 1.98s\tremaining: 759ms\n",
      "723:\tlearn: 0.8403701\ttotal: 1.99s\tremaining: 757ms\n",
      "724:\tlearn: 0.8385911\ttotal: 1.99s\tremaining: 754ms\n",
      "725:\tlearn: 0.8364864\ttotal: 1.99s\tremaining: 752ms\n",
      "726:\tlearn: 0.8340884\ttotal: 2s\tremaining: 749ms\n",
      "727:\tlearn: 0.8314533\ttotal: 2s\tremaining: 747ms\n",
      "728:\tlearn: 0.8281578\ttotal: 2s\tremaining: 744ms\n",
      "729:\tlearn: 0.8243222\ttotal: 2s\tremaining: 741ms\n",
      "730:\tlearn: 0.8197356\ttotal: 2.01s\tremaining: 739ms\n",
      "731:\tlearn: 0.8152680\ttotal: 2.01s\tremaining: 736ms\n",
      "732:\tlearn: 0.8106591\ttotal: 2.01s\tremaining: 733ms\n",
      "733:\tlearn: 0.8069108\ttotal: 2.02s\tremaining: 730ms\n",
      "734:\tlearn: 0.8055262\ttotal: 2.02s\tremaining: 728ms\n",
      "735:\tlearn: 0.8029948\ttotal: 2.02s\tremaining: 725ms\n",
      "736:\tlearn: 0.7995817\ttotal: 2.02s\tremaining: 722ms\n",
      "737:\tlearn: 0.7960357\ttotal: 2.03s\tremaining: 720ms\n",
      "738:\tlearn: 0.7938098\ttotal: 2.03s\tremaining: 717ms\n",
      "739:\tlearn: 0.7911017\ttotal: 2.03s\tremaining: 715ms\n",
      "740:\tlearn: 0.7871611\ttotal: 2.04s\tremaining: 712ms\n",
      "741:\tlearn: 0.7823959\ttotal: 2.04s\tremaining: 709ms\n",
      "742:\tlearn: 0.7787252\ttotal: 2.04s\tremaining: 706ms\n",
      "743:\tlearn: 0.7752669\ttotal: 2.04s\tremaining: 704ms\n",
      "744:\tlearn: 0.7748769\ttotal: 2.05s\tremaining: 701ms\n",
      "745:\tlearn: 0.7699784\ttotal: 2.05s\tremaining: 699ms\n",
      "746:\tlearn: 0.7658119\ttotal: 2.05s\tremaining: 696ms\n",
      "747:\tlearn: 0.7611463\ttotal: 2.06s\tremaining: 693ms\n",
      "748:\tlearn: 0.7579403\ttotal: 2.06s\tremaining: 690ms\n",
      "749:\tlearn: 0.7552106\ttotal: 2.06s\tremaining: 688ms\n",
      "750:\tlearn: 0.7510025\ttotal: 2.07s\tremaining: 685ms\n",
      "751:\tlearn: 0.7483939\ttotal: 2.07s\tremaining: 682ms\n",
      "752:\tlearn: 0.7457644\ttotal: 2.07s\tremaining: 679ms\n",
      "753:\tlearn: 0.7452835\ttotal: 2.07s\tremaining: 677ms\n",
      "754:\tlearn: 0.7444030\ttotal: 2.08s\tremaining: 674ms\n",
      "755:\tlearn: 0.7408342\ttotal: 2.08s\tremaining: 671ms\n",
      "756:\tlearn: 0.7369994\ttotal: 2.08s\tremaining: 669ms\n",
      "757:\tlearn: 0.7344100\ttotal: 2.08s\tremaining: 666ms\n",
      "758:\tlearn: 0.7297164\ttotal: 2.09s\tremaining: 663ms\n",
      "759:\tlearn: 0.7269406\ttotal: 2.09s\tremaining: 661ms\n",
      "760:\tlearn: 0.7245299\ttotal: 2.1s\tremaining: 658ms\n",
      "761:\tlearn: 0.7220420\ttotal: 2.1s\tremaining: 655ms\n",
      "762:\tlearn: 0.7165559\ttotal: 2.1s\tremaining: 652ms\n",
      "763:\tlearn: 0.7118432\ttotal: 2.1s\tremaining: 650ms\n",
      "764:\tlearn: 0.7087305\ttotal: 2.11s\tremaining: 648ms\n",
      "765:\tlearn: 0.7040659\ttotal: 2.11s\tremaining: 645ms\n",
      "766:\tlearn: 0.7026281\ttotal: 2.11s\tremaining: 642ms\n",
      "767:\tlearn: 0.6995569\ttotal: 2.12s\tremaining: 640ms\n",
      "768:\tlearn: 0.6947499\ttotal: 2.12s\tremaining: 638ms\n",
      "769:\tlearn: 0.6914969\ttotal: 2.13s\tremaining: 636ms\n",
      "770:\tlearn: 0.6877402\ttotal: 2.13s\tremaining: 633ms\n",
      "771:\tlearn: 0.6854511\ttotal: 2.13s\tremaining: 631ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772:\tlearn: 0.6824423\ttotal: 2.14s\tremaining: 628ms\n",
      "773:\tlearn: 0.6821203\ttotal: 2.14s\tremaining: 626ms\n",
      "774:\tlearn: 0.6795761\ttotal: 2.15s\tremaining: 623ms\n",
      "775:\tlearn: 0.6773828\ttotal: 2.15s\tremaining: 620ms\n",
      "776:\tlearn: 0.6749322\ttotal: 2.15s\tremaining: 617ms\n",
      "777:\tlearn: 0.6746525\ttotal: 2.15s\tremaining: 614ms\n",
      "778:\tlearn: 0.6716648\ttotal: 2.15s\tremaining: 612ms\n",
      "779:\tlearn: 0.6682061\ttotal: 2.16s\tremaining: 609ms\n",
      "780:\tlearn: 0.6648774\ttotal: 2.16s\tremaining: 606ms\n",
      "781:\tlearn: 0.6631692\ttotal: 2.17s\tremaining: 604ms\n",
      "782:\tlearn: 0.6624580\ttotal: 2.17s\tremaining: 601ms\n",
      "783:\tlearn: 0.6617498\ttotal: 2.17s\tremaining: 598ms\n",
      "784:\tlearn: 0.6601461\ttotal: 2.17s\tremaining: 595ms\n",
      "785:\tlearn: 0.6565663\ttotal: 2.17s\tremaining: 592ms\n",
      "786:\tlearn: 0.6553507\ttotal: 2.18s\tremaining: 589ms\n",
      "787:\tlearn: 0.6517920\ttotal: 2.18s\tremaining: 586ms\n",
      "788:\tlearn: 0.6484266\ttotal: 2.18s\tremaining: 584ms\n",
      "789:\tlearn: 0.6464942\ttotal: 2.18s\tremaining: 581ms\n",
      "790:\tlearn: 0.6444375\ttotal: 2.19s\tremaining: 578ms\n",
      "791:\tlearn: 0.6422505\ttotal: 2.19s\tremaining: 575ms\n",
      "792:\tlearn: 0.6394724\ttotal: 2.19s\tremaining: 572ms\n",
      "793:\tlearn: 0.6359836\ttotal: 2.19s\tremaining: 569ms\n",
      "794:\tlearn: 0.6319650\ttotal: 2.19s\tremaining: 566ms\n",
      "795:\tlearn: 0.6276665\ttotal: 2.2s\tremaining: 563ms\n",
      "796:\tlearn: 0.6259765\ttotal: 2.2s\tremaining: 560ms\n",
      "797:\tlearn: 0.6230876\ttotal: 2.2s\tremaining: 558ms\n",
      "798:\tlearn: 0.6218244\ttotal: 2.21s\tremaining: 555ms\n",
      "799:\tlearn: 0.6194371\ttotal: 2.21s\tremaining: 552ms\n",
      "800:\tlearn: 0.6179317\ttotal: 2.21s\tremaining: 549ms\n",
      "801:\tlearn: 0.6173361\ttotal: 2.21s\tremaining: 546ms\n",
      "802:\tlearn: 0.6170013\ttotal: 2.21s\tremaining: 543ms\n",
      "803:\tlearn: 0.6162722\ttotal: 2.22s\tremaining: 541ms\n",
      "804:\tlearn: 0.6129576\ttotal: 2.22s\tremaining: 538ms\n",
      "805:\tlearn: 0.6122355\ttotal: 2.22s\tremaining: 535ms\n",
      "806:\tlearn: 0.6096768\ttotal: 2.22s\tremaining: 532ms\n",
      "807:\tlearn: 0.6067875\ttotal: 2.23s\tremaining: 529ms\n",
      "808:\tlearn: 0.6060769\ttotal: 2.23s\tremaining: 526ms\n",
      "809:\tlearn: 0.6029965\ttotal: 2.23s\tremaining: 524ms\n",
      "810:\tlearn: 0.6008651\ttotal: 2.23s\tremaining: 521ms\n",
      "811:\tlearn: 0.6000285\ttotal: 2.24s\tremaining: 518ms\n",
      "812:\tlearn: 0.5995561\ttotal: 2.24s\tremaining: 515ms\n",
      "813:\tlearn: 0.5969230\ttotal: 2.24s\tremaining: 513ms\n",
      "814:\tlearn: 0.5956235\ttotal: 2.25s\tremaining: 510ms\n",
      "815:\tlearn: 0.5924260\ttotal: 2.25s\tremaining: 508ms\n",
      "816:\tlearn: 0.5901256\ttotal: 2.25s\tremaining: 505ms\n",
      "817:\tlearn: 0.5897801\ttotal: 2.26s\tremaining: 502ms\n",
      "818:\tlearn: 0.5874784\ttotal: 2.26s\tremaining: 499ms\n",
      "819:\tlearn: 0.5871404\ttotal: 2.26s\tremaining: 497ms\n",
      "820:\tlearn: 0.5844734\ttotal: 2.27s\tremaining: 494ms\n",
      "821:\tlearn: 0.5837146\ttotal: 2.27s\tremaining: 492ms\n",
      "822:\tlearn: 0.5822337\ttotal: 2.28s\tremaining: 490ms\n",
      "823:\tlearn: 0.5819929\ttotal: 2.28s\tremaining: 487ms\n",
      "824:\tlearn: 0.5817294\ttotal: 2.28s\tremaining: 484ms\n",
      "825:\tlearn: 0.5785729\ttotal: 2.29s\tremaining: 482ms\n",
      "826:\tlearn: 0.5746691\ttotal: 2.29s\tremaining: 479ms\n",
      "827:\tlearn: 0.5744125\ttotal: 2.29s\tremaining: 476ms\n",
      "828:\tlearn: 0.5717696\ttotal: 2.3s\tremaining: 474ms\n",
      "829:\tlearn: 0.5694422\ttotal: 2.3s\tremaining: 471ms\n",
      "830:\tlearn: 0.5674157\ttotal: 2.3s\tremaining: 468ms\n",
      "831:\tlearn: 0.5643676\ttotal: 2.3s\tremaining: 465ms\n",
      "832:\tlearn: 0.5617334\ttotal: 2.31s\tremaining: 463ms\n",
      "833:\tlearn: 0.5593727\ttotal: 2.31s\tremaining: 460ms\n",
      "834:\tlearn: 0.5565554\ttotal: 2.31s\tremaining: 458ms\n",
      "835:\tlearn: 0.5532029\ttotal: 2.32s\tremaining: 455ms\n",
      "836:\tlearn: 0.5507402\ttotal: 2.32s\tremaining: 452ms\n",
      "837:\tlearn: 0.5502340\ttotal: 2.32s\tremaining: 449ms\n",
      "838:\tlearn: 0.5481531\ttotal: 2.33s\tremaining: 447ms\n",
      "839:\tlearn: 0.5463196\ttotal: 2.33s\tremaining: 444ms\n",
      "840:\tlearn: 0.5436885\ttotal: 2.33s\tremaining: 441ms\n",
      "841:\tlearn: 0.5412078\ttotal: 2.34s\tremaining: 439ms\n",
      "842:\tlearn: 0.5401218\ttotal: 2.34s\tremaining: 436ms\n",
      "843:\tlearn: 0.5397922\ttotal: 2.34s\tremaining: 433ms\n",
      "844:\tlearn: 0.5376344\ttotal: 2.35s\tremaining: 431ms\n",
      "845:\tlearn: 0.5348022\ttotal: 2.35s\tremaining: 428ms\n",
      "846:\tlearn: 0.5345942\ttotal: 2.35s\tremaining: 425ms\n",
      "847:\tlearn: 0.5337065\ttotal: 2.36s\tremaining: 423ms\n",
      "848:\tlearn: 0.5308319\ttotal: 2.36s\tremaining: 420ms\n",
      "849:\tlearn: 0.5299853\ttotal: 2.36s\tremaining: 417ms\n",
      "850:\tlearn: 0.5279239\ttotal: 2.37s\tremaining: 415ms\n",
      "851:\tlearn: 0.5276926\ttotal: 2.37s\tremaining: 412ms\n",
      "852:\tlearn: 0.5248560\ttotal: 2.38s\tremaining: 409ms\n",
      "853:\tlearn: 0.5229627\ttotal: 2.38s\tremaining: 407ms\n",
      "854:\tlearn: 0.5222219\ttotal: 2.38s\tremaining: 404ms\n",
      "855:\tlearn: 0.5193685\ttotal: 2.38s\tremaining: 401ms\n",
      "856:\tlearn: 0.5159184\ttotal: 2.39s\tremaining: 398ms\n",
      "857:\tlearn: 0.5136942\ttotal: 2.39s\tremaining: 396ms\n",
      "858:\tlearn: 0.5116485\ttotal: 2.39s\tremaining: 393ms\n",
      "859:\tlearn: 0.5105621\ttotal: 2.4s\tremaining: 390ms\n",
      "860:\tlearn: 0.5085657\ttotal: 2.4s\tremaining: 387ms\n",
      "861:\tlearn: 0.5071222\ttotal: 2.4s\tremaining: 385ms\n",
      "862:\tlearn: 0.5043268\ttotal: 2.41s\tremaining: 382ms\n",
      "863:\tlearn: 0.5018439\ttotal: 2.41s\tremaining: 379ms\n",
      "864:\tlearn: 0.5015228\ttotal: 2.41s\tremaining: 376ms\n",
      "865:\tlearn: 0.5001181\ttotal: 2.42s\tremaining: 374ms\n",
      "866:\tlearn: 0.4978909\ttotal: 2.42s\tremaining: 371ms\n",
      "867:\tlearn: 0.4965543\ttotal: 2.42s\tremaining: 368ms\n",
      "868:\tlearn: 0.4953363\ttotal: 2.42s\tremaining: 366ms\n",
      "869:\tlearn: 0.4936555\ttotal: 2.43s\tremaining: 363ms\n",
      "870:\tlearn: 0.4924806\ttotal: 2.43s\tremaining: 360ms\n",
      "871:\tlearn: 0.4922502\ttotal: 2.43s\tremaining: 357ms\n",
      "872:\tlearn: 0.4912348\ttotal: 2.44s\tremaining: 354ms\n",
      "873:\tlearn: 0.4897709\ttotal: 2.44s\tremaining: 352ms\n",
      "874:\tlearn: 0.4887895\ttotal: 2.44s\tremaining: 349ms\n",
      "875:\tlearn: 0.4866501\ttotal: 2.44s\tremaining: 346ms\n",
      "876:\tlearn: 0.4852681\ttotal: 2.45s\tremaining: 343ms\n",
      "877:\tlearn: 0.4831876\ttotal: 2.45s\tremaining: 341ms\n",
      "878:\tlearn: 0.4826475\ttotal: 2.45s\tremaining: 338ms\n",
      "879:\tlearn: 0.4824666\ttotal: 2.46s\tremaining: 335ms\n",
      "880:\tlearn: 0.4797460\ttotal: 2.46s\tremaining: 333ms\n",
      "881:\tlearn: 0.4786272\ttotal: 2.47s\tremaining: 330ms\n",
      "882:\tlearn: 0.4770096\ttotal: 2.47s\tremaining: 327ms\n",
      "883:\tlearn: 0.4739594\ttotal: 2.47s\tremaining: 325ms\n",
      "884:\tlearn: 0.4712528\ttotal: 2.48s\tremaining: 322ms\n",
      "885:\tlearn: 0.4709455\ttotal: 2.48s\tremaining: 319ms\n",
      "886:\tlearn: 0.4697345\ttotal: 2.48s\tremaining: 316ms\n",
      "887:\tlearn: 0.4673443\ttotal: 2.48s\tremaining: 313ms\n",
      "888:\tlearn: 0.4671495\ttotal: 2.49s\tremaining: 310ms\n",
      "889:\tlearn: 0.4663652\ttotal: 2.49s\tremaining: 308ms\n",
      "890:\tlearn: 0.4643707\ttotal: 2.49s\tremaining: 305ms\n",
      "891:\tlearn: 0.4625108\ttotal: 2.49s\tremaining: 302ms\n",
      "892:\tlearn: 0.4622912\ttotal: 2.5s\tremaining: 299ms\n",
      "893:\tlearn: 0.4606120\ttotal: 2.5s\tremaining: 296ms\n",
      "894:\tlearn: 0.4604515\ttotal: 2.5s\tremaining: 293ms\n",
      "895:\tlearn: 0.4602520\ttotal: 2.5s\tremaining: 291ms\n",
      "896:\tlearn: 0.4590862\ttotal: 2.5s\tremaining: 288ms\n",
      "897:\tlearn: 0.4586037\ttotal: 2.51s\tremaining: 285ms\n",
      "898:\tlearn: 0.4564699\ttotal: 2.51s\tremaining: 282ms\n",
      "899:\tlearn: 0.4546199\ttotal: 2.52s\tremaining: 280ms\n",
      "900:\tlearn: 0.4533581\ttotal: 2.52s\tremaining: 277ms\n",
      "901:\tlearn: 0.4508865\ttotal: 2.52s\tremaining: 274ms\n",
      "902:\tlearn: 0.4487607\ttotal: 2.52s\tremaining: 271ms\n",
      "903:\tlearn: 0.4478892\ttotal: 2.53s\tremaining: 268ms\n",
      "904:\tlearn: 0.4469461\ttotal: 2.53s\tremaining: 266ms\n",
      "905:\tlearn: 0.4457558\ttotal: 2.53s\tremaining: 263ms\n",
      "906:\tlearn: 0.4431849\ttotal: 2.54s\tremaining: 260ms\n",
      "907:\tlearn: 0.4408296\ttotal: 2.54s\tremaining: 257ms\n",
      "908:\tlearn: 0.4395834\ttotal: 2.54s\tremaining: 255ms\n",
      "909:\tlearn: 0.4380619\ttotal: 2.55s\tremaining: 252ms\n",
      "910:\tlearn: 0.4366149\ttotal: 2.55s\tremaining: 249ms\n",
      "911:\tlearn: 0.4350534\ttotal: 2.56s\tremaining: 247ms\n",
      "912:\tlearn: 0.4326707\ttotal: 2.56s\tremaining: 244ms\n",
      "913:\tlearn: 0.4305869\ttotal: 2.56s\tremaining: 241ms\n",
      "914:\tlearn: 0.4284498\ttotal: 2.56s\tremaining: 238ms\n",
      "915:\tlearn: 0.4270522\ttotal: 2.57s\tremaining: 235ms\n",
      "916:\tlearn: 0.4264280\ttotal: 2.57s\tremaining: 233ms\n",
      "917:\tlearn: 0.4247260\ttotal: 2.57s\tremaining: 230ms\n",
      "918:\tlearn: 0.4227754\ttotal: 2.57s\tremaining: 227ms\n",
      "919:\tlearn: 0.4205804\ttotal: 2.58s\tremaining: 224ms\n",
      "920:\tlearn: 0.4196380\ttotal: 2.58s\tremaining: 221ms\n",
      "921:\tlearn: 0.4169606\ttotal: 2.58s\tremaining: 218ms\n",
      "922:\tlearn: 0.4168094\ttotal: 2.58s\tremaining: 215ms\n",
      "923:\tlearn: 0.4162122\ttotal: 2.59s\tremaining: 213ms\n",
      "924:\tlearn: 0.4159897\ttotal: 2.59s\tremaining: 210ms\n",
      "925:\tlearn: 0.4139577\ttotal: 2.59s\tremaining: 207ms\n",
      "926:\tlearn: 0.4126338\ttotal: 2.6s\tremaining: 204ms\n",
      "927:\tlearn: 0.4118677\ttotal: 2.6s\tremaining: 202ms\n",
      "928:\tlearn: 0.4117087\ttotal: 2.6s\tremaining: 199ms\n",
      "929:\tlearn: 0.4105811\ttotal: 2.6s\tremaining: 196ms\n",
      "930:\tlearn: 0.4087918\ttotal: 2.61s\tremaining: 193ms\n",
      "931:\tlearn: 0.4083226\ttotal: 2.61s\tremaining: 191ms\n",
      "932:\tlearn: 0.4062603\ttotal: 2.61s\tremaining: 188ms\n",
      "933:\tlearn: 0.4042877\ttotal: 2.62s\tremaining: 185ms\n",
      "934:\tlearn: 0.4019499\ttotal: 2.62s\tremaining: 182ms\n",
      "935:\tlearn: 0.4015588\ttotal: 2.63s\tremaining: 180ms\n",
      "936:\tlearn: 0.3992074\ttotal: 2.63s\tremaining: 177ms\n",
      "937:\tlearn: 0.3967703\ttotal: 2.63s\tremaining: 174ms\n",
      "938:\tlearn: 0.3950815\ttotal: 2.63s\tremaining: 171ms\n",
      "939:\tlearn: 0.3937807\ttotal: 2.64s\tremaining: 168ms\n",
      "940:\tlearn: 0.3921317\ttotal: 2.64s\tremaining: 166ms\n",
      "941:\tlearn: 0.3897622\ttotal: 2.64s\tremaining: 163ms\n",
      "942:\tlearn: 0.3889793\ttotal: 2.65s\tremaining: 160ms\n",
      "943:\tlearn: 0.3869109\ttotal: 2.65s\tremaining: 157ms\n",
      "944:\tlearn: 0.3861624\ttotal: 2.65s\tremaining: 154ms\n",
      "945:\tlearn: 0.3851517\ttotal: 2.65s\tremaining: 152ms\n",
      "946:\tlearn: 0.3834001\ttotal: 2.66s\tremaining: 149ms\n",
      "947:\tlearn: 0.3832935\ttotal: 2.66s\tremaining: 146ms\n",
      "948:\tlearn: 0.3829120\ttotal: 2.66s\tremaining: 143ms\n",
      "949:\tlearn: 0.3806580\ttotal: 2.67s\tremaining: 140ms\n",
      "950:\tlearn: 0.3792596\ttotal: 2.68s\tremaining: 138ms\n",
      "951:\tlearn: 0.3775434\ttotal: 2.69s\tremaining: 135ms\n",
      "952:\tlearn: 0.3774221\ttotal: 2.69s\tremaining: 133ms\n",
      "953:\tlearn: 0.3750580\ttotal: 2.69s\tremaining: 130ms\n",
      "954:\tlearn: 0.3748936\ttotal: 2.7s\tremaining: 127ms\n",
      "955:\tlearn: 0.3730002\ttotal: 2.7s\tremaining: 124ms\n",
      "956:\tlearn: 0.3714504\ttotal: 2.7s\tremaining: 121ms\n",
      "957:\tlearn: 0.3699383\ttotal: 2.71s\tremaining: 119ms\n",
      "958:\tlearn: 0.3681363\ttotal: 2.71s\tremaining: 116ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959:\tlearn: 0.3666220\ttotal: 2.71s\tremaining: 113ms\n",
      "960:\tlearn: 0.3664956\ttotal: 2.72s\tremaining: 110ms\n",
      "961:\tlearn: 0.3643172\ttotal: 2.72s\tremaining: 107ms\n",
      "962:\tlearn: 0.3627961\ttotal: 2.72s\tremaining: 105ms\n",
      "963:\tlearn: 0.3609222\ttotal: 2.72s\tremaining: 102ms\n",
      "964:\tlearn: 0.3605757\ttotal: 2.73s\tremaining: 99ms\n",
      "965:\tlearn: 0.3591893\ttotal: 2.73s\tremaining: 96.1ms\n",
      "966:\tlearn: 0.3568837\ttotal: 2.73s\tremaining: 93.3ms\n",
      "967:\tlearn: 0.3544812\ttotal: 2.74s\tremaining: 90.5ms\n",
      "968:\tlearn: 0.3531921\ttotal: 2.74s\tremaining: 87.7ms\n",
      "969:\tlearn: 0.3530502\ttotal: 2.75s\tremaining: 84.9ms\n",
      "970:\tlearn: 0.3509845\ttotal: 2.75s\tremaining: 82.1ms\n",
      "971:\tlearn: 0.3489966\ttotal: 2.75s\tremaining: 79.2ms\n",
      "972:\tlearn: 0.3477187\ttotal: 2.75s\tremaining: 76.4ms\n",
      "973:\tlearn: 0.3461663\ttotal: 2.75s\tremaining: 73.6ms\n",
      "974:\tlearn: 0.3445901\ttotal: 2.76s\tremaining: 70.8ms\n",
      "975:\tlearn: 0.3435627\ttotal: 2.76s\tremaining: 68ms\n",
      "976:\tlearn: 0.3428486\ttotal: 2.77s\tremaining: 65.1ms\n",
      "977:\tlearn: 0.3406775\ttotal: 2.77s\tremaining: 62.3ms\n",
      "978:\tlearn: 0.3392593\ttotal: 2.77s\tremaining: 59.4ms\n",
      "979:\tlearn: 0.3373990\ttotal: 2.78s\tremaining: 56.7ms\n",
      "980:\tlearn: 0.3362528\ttotal: 2.78s\tremaining: 53.8ms\n",
      "981:\tlearn: 0.3342089\ttotal: 2.78s\tremaining: 51ms\n",
      "982:\tlearn: 0.3325671\ttotal: 2.78s\tremaining: 48.2ms\n",
      "983:\tlearn: 0.3314816\ttotal: 2.79s\tremaining: 45.3ms\n",
      "984:\tlearn: 0.3299948\ttotal: 2.79s\tremaining: 42.5ms\n",
      "985:\tlearn: 0.3282838\ttotal: 2.79s\tremaining: 39.7ms\n",
      "986:\tlearn: 0.3265144\ttotal: 2.8s\tremaining: 36.8ms\n",
      "987:\tlearn: 0.3260272\ttotal: 2.8s\tremaining: 34ms\n",
      "988:\tlearn: 0.3248116\ttotal: 2.8s\tremaining: 31.2ms\n",
      "989:\tlearn: 0.3232430\ttotal: 2.81s\tremaining: 28.4ms\n",
      "990:\tlearn: 0.3221518\ttotal: 2.81s\tremaining: 25.5ms\n",
      "991:\tlearn: 0.3200847\ttotal: 2.81s\tremaining: 22.7ms\n",
      "992:\tlearn: 0.3191842\ttotal: 2.81s\tremaining: 19.8ms\n",
      "993:\tlearn: 0.3187234\ttotal: 2.82s\tremaining: 17ms\n",
      "994:\tlearn: 0.3166920\ttotal: 2.82s\tremaining: 14.2ms\n",
      "995:\tlearn: 0.3165157\ttotal: 2.83s\tremaining: 11.3ms\n",
      "996:\tlearn: 0.3155629\ttotal: 2.83s\tremaining: 8.51ms\n",
      "997:\tlearn: 0.3140263\ttotal: 2.83s\tremaining: 5.67ms\n",
      "998:\tlearn: 0.3128715\ttotal: 2.83s\tremaining: 2.83ms\n",
      "999:\tlearn: 0.3113297\ttotal: 2.84s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14.258368323408034, 10.927408297568414)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming train and test datasets are already prepared and loaded\n",
    "# train and test datasets should contain the necessary features and target columns\n",
    "\n",
    "# Importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X = sbp_features.drop(['sbp', 'dbp',\"subject_id\",\"Unnamed: 0\"], axis=1)\n",
    "y = sbp_features['sbp']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MAE and RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "198bb351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.937323259451476, 13.105897187942732)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming train and test datasets are already prepared and loaded\n",
    "# train and test datasets should contain the necessary features and target columns\n",
    "\n",
    "# Importing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sbp_features.drop(['sbp', 'dbp',\"subject_id\",\"Unnamed: 0\"], axis=1)\n",
    "y = sbp_features['sbp']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l1', 'l2'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Creating dataset for LightGBM\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# Training the model with early stopping\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_train, lgb_eval],\n",
    "                num_boost_round=1000)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "# Calculate MAE and RMSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e81da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex=[]\n",
    "Age=[]\n",
    "Height=[]\n",
    "Weight=[]\n",
    "Systolic_Blood_Pressure=[]\n",
    "Diastolic_Blood_Pressure=[]\n",
    "Heart_Rate=[]\n",
    "BMI=[]\n",
    "Ht =[]\n",
    "Diabetics =[]\n",
    "cerebral =[]\n",
    "cerebro =[]\n",
    "\n",
    "\n",
    "for i in dbp_features['subject_id']:\n",
    "    index = df1[df1['Unnamed: 1'] == i].index[0]\n",
    "    sex_value = df1['Unnamed: 2'][index]       \n",
    "    Sex.append(sex_value)  \n",
    "    age_value = df1['Unnamed: 3'][index]       \n",
    "    Age.append(age_value) \n",
    "    height_value = df1['Unnamed: 4'][index]       \n",
    "    Height.append(height_value)\n",
    "    weight_value = df1['Unnamed: 5'][index]       \n",
    "    Weight.append(weight_value)\n",
    "    Systolic_Blood_Pressure_value = df1['Unnamed: 6'][index]       \n",
    "    Systolic_Blood_Pressure.append(Systolic_Blood_Pressure_value)\n",
    "    Diastolic_Blood_Pressure_value = df1['Unnamed: 7'][index]       \n",
    "    Diastolic_Blood_Pressure.append(Diastolic_Blood_Pressure_value)\n",
    "    Heart_Rate_value = df1['Unnamed: 8'][index]       \n",
    "    Heart_Rate.append(Heart_Rate_value)\n",
    "    BMI_value = df1['Unnamed: 9'][index]       \n",
    "    BMI.append(BMI_value)\n",
    "    ht_value = df1['Hospital Electronic Medical Record'][index]       \n",
    "    Ht.append(ht_value)\n",
    "    Diabetics_value = df1['Unnamed: 11'][index]       \n",
    "    Diabetics.append(Diabetics_value)\n",
    "    cerebral_value = df1['Unnamed: 12'][index]       \n",
    "    cerebral.append(cerebral_value)\n",
    "    cerebro_value = df1['Unnamed: 13'][index]       \n",
    "    cerebro.append(cerebro_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36d0d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbp_features['Sex'] = Sex\n",
    "dbp_features['Age'] = Age\n",
    "dbp_features['Height'] = Height\n",
    "dbp_features['Weight'] = Weight\n",
    "# sbp_features['Systolic_Blood_Pressure'] = Systolic_Blood_Pressure\n",
    "# sbp_features['Diastolic_Blood_Pressure'] = Diastolic_Blood_Pressure\n",
    "dbp_features['Heart_Rate'] = Heart_Rate\n",
    "dbp_features['BMI'] = BMI\n",
    "# dbp_features['Hypertension'] = Ht\n",
    "# dbp_features['Diabetics'] = Diabetics\n",
    "# dbp_features['cerebral infarction'] = cerebral\n",
    "# dbp_features['cerebrovascular disease'] = cerebro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6839f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbp_features[\"Sex\"]= dbp_features['Sex'].map({'Male': 0, 'Female': 1})\n",
    "# dbp_features[\"Hypertension\"]= dbp_features['Hypertension'].map({'Normal': 0, 'Prehypertension': 1, \"Stage 1 hypertension\": 2,'Stage 2 hypertension':3})\n",
    "# dbp_features[\"Diabetics\"]= dbp_features['Diabetics'].map({'NaN': 0, 'Type 2 Diabetes': 1,'Diabetes':2})\n",
    "# dbp_features[\"cerebral infarction\"]= dbp_features['cerebral infarction'].map({'NaN': 0, 'cerebral infarction': 1})\n",
    "# dbp_features[\"cerebrovascular disease\"]= dbp_features['cerebrovascular disease'].map({'NaN': 0, 'insufficiency of cerebral blood supply': 1,'insufficiency of cerebral blood supply':2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f93a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>560.121310</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>710.871618</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>593.734741</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>596.576175</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>717.270483</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "182         214  775  185  567          96    349    272    232    160    117   \n",
       "183         215  948  244  646          97    417    333    297    207    123   \n",
       "184         216  719  163  549          98    519    365    313    171    120   \n",
       "185         217  751  255  551          99    444    341    292    187    135   \n",
       "186         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...     div75  sbp  dbp  area_under_curve  Sex  Age  Height  Weight  \\\n",
       "0    ...  0.507576  140   82        673.754706    1   68     150      63   \n",
       "1    ...  1.128440  120   60        671.104643    1   63     153      45   \n",
       "2    ...  1.134831  135   75        571.545583    1   67     155      55   \n",
       "3    ...  2.263889  130   66        821.935730    1   86     161      70   \n",
       "4    ...  1.289855  133   77        649.000588    0   59     171      80   \n",
       "..   ...       ...  ...  ...               ...  ...  ...     ...     ...   \n",
       "182  ...  1.009901  136   71        560.121310    1   76     158      62   \n",
       "183  ...  0.683453  143   65        710.871618    0   76     168      75   \n",
       "184  ...  1.531250  116   65        593.734741    0   68     170      69   \n",
       "185  ...  1.480519  133   71        596.576175    0   78     170      60   \n",
       "186  ...  1.171053  123   73        717.270483    1   46     155      65   \n",
       "\n",
       "     Heart_Rate        BMI  \n",
       "0            73  28.000000  \n",
       "1            76  19.223376  \n",
       "2            72  22.892820  \n",
       "3            69  27.005131  \n",
       "4            66  27.358845  \n",
       "..          ...        ...  \n",
       "182          72  24.835763  \n",
       "183          66  26.573129  \n",
       "184          70  23.875433  \n",
       "185          80  20.761246  \n",
       "186          73  27.055151  \n",
       "\n",
       "[187 rows x 38 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbp_features = dbp_features.fillna(0)\n",
    "dbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7345ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # For scikit-learn <= 0.24\n",
    "# If you're using scikit-learn 0.24 or later, you can use:\n",
    "# from joblib import dump\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_model_size(model):\n",
    "    # Serialize the model and get the size in kilobytes\n",
    "    model_filename = \"temp_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    size_kb = os.path.getsize(model_filename) / 1024\n",
    "    os.remove(model_filename)\n",
    "    return size_kb\n",
    "\n",
    "def evaluate_models(data):\n",
    "    X = data.drop(['sbp', 'dbp',\"subject_id\",\"Unnamed: 0\"], axis=1)\n",
    "    y = data['dbp']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    results_dict = {'Model': [], 'Mean Absolute Error': [], 'Root Mean Square': [], 'Model Size (KB)': []}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "        size_kb = get_model_size(model)\n",
    "\n",
    "        results_dict['Model'].append(model_name)\n",
    "        results_dict['Mean Absolute Error'].append(mae)\n",
    "        results_dict['Root Mean Square'].append(rmse)\n",
    "        results_dict['Model Size (KB)'].append(size_kb)\n",
    "\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "models = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'SVR': SVR(),\n",
    "}\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models.update({\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "    'MLPRegressor': MLPRegressor(),\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efe27c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+02, tolerance: 9.700e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.192e+02, tolerance: 9.700e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Model Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>5.261053</td>\n",
       "      <td>6.685381</td>\n",
       "      <td>1009.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>6.338196</td>\n",
       "      <td>7.941394</td>\n",
       "      <td>1.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>6.031579</td>\n",
       "      <td>7.301190</td>\n",
       "      <td>42.112305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>5.732041</td>\n",
       "      <td>6.873888</td>\n",
       "      <td>44.178711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>7.921053</td>\n",
       "      <td>9.551798</td>\n",
       "      <td>17.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>5.913878</td>\n",
       "      <td>7.295600</td>\n",
       "      <td>1.502930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.514161</td>\n",
       "      <td>6.900121</td>\n",
       "      <td>1.584961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>5.464324</td>\n",
       "      <td>6.921339</td>\n",
       "      <td>1.600586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>6.701032</td>\n",
       "      <td>8.132583</td>\n",
       "      <td>166.809570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>5.363397</td>\n",
       "      <td>6.475082</td>\n",
       "      <td>60.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>7.169331</td>\n",
       "      <td>9.741709</td>\n",
       "      <td>93.233398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>5.822110</td>\n",
       "      <td>7.317375</td>\n",
       "      <td>185.335938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Root Mean Square  \\\n",
       "0       RandomForestRegressor             5.261053          6.685381   \n",
       "1            LinearRegression             6.338196          7.941394   \n",
       "2         KNeighborsRegressor             6.031579          7.301190   \n",
       "3                         SVR             5.732041          6.873888   \n",
       "4       DecisionTreeRegressor             7.921053          9.551798   \n",
       "5                       Ridge             5.913878          7.295600   \n",
       "6                       Lasso             5.514161          6.900121   \n",
       "7                  ElasticNet             5.464324          6.921339   \n",
       "8   GradientBoostingRegressor             6.701032          8.132583   \n",
       "9           AdaBoostRegressor             5.363397          6.475082   \n",
       "10               MLPRegressor             7.169331          9.741709   \n",
       "11               XGBRegressor             5.822110          7.317375   \n",
       "\n",
       "    Model Size (KB)  \n",
       "0       1009.719727  \n",
       "1          1.835938  \n",
       "2         42.112305  \n",
       "3         44.178711  \n",
       "4         17.032227  \n",
       "5          1.502930  \n",
       "6          1.584961  \n",
       "7          1.600586  \n",
       "8        166.809570  \n",
       "9         60.609375  \n",
       "10        93.233398  \n",
       "11       185.335938  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbp_results=evaluate_models(dbp_features)\n",
    "dbp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66bf4a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>div75</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128440</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134831</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>2.263889</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>1.289855</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009901</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>560.121310</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>710.871618</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>593.734741</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480519</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>596.576175</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1.171053</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>717.270483</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "182         214  775  185  567          96    349    272    232    160    117   \n",
       "183         215  948  244  646          97    417    333    297    207    123   \n",
       "184         216  719  163  549          98    519    365    313    171    120   \n",
       "185         217  751  255  551          99    444    341    292    187    135   \n",
       "186         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...     div75  sbp  dbp  area_under_curve  Sex  Age  Height  Weight  \\\n",
       "0    ...  0.507576  140   82        673.754706    1   68     150      63   \n",
       "1    ...  1.128440  120   60        671.104643    1   63     153      45   \n",
       "2    ...  1.134831  135   75        571.545583    1   67     155      55   \n",
       "3    ...  2.263889  130   66        821.935730    1   86     161      70   \n",
       "4    ...  1.289855  133   77        649.000588    0   59     171      80   \n",
       "..   ...       ...  ...  ...               ...  ...  ...     ...     ...   \n",
       "182  ...  1.009901  136   71        560.121310    1   76     158      62   \n",
       "183  ...  0.683453  143   65        710.871618    0   76     168      75   \n",
       "184  ...  1.531250  116   65        593.734741    0   68     170      69   \n",
       "185  ...  1.480519  133   71        596.576175    0   78     170      60   \n",
       "186  ...  1.171053  123   73        717.270483    1   46     155      65   \n",
       "\n",
       "     Heart_Rate        BMI  \n",
       "0            73  28.000000  \n",
       "1            76  19.223376  \n",
       "2            72  22.892820  \n",
       "3            69  27.005131  \n",
       "4            66  27.358845  \n",
       "..          ...        ...  \n",
       "182          72  24.835763  \n",
       "183          66  26.573129  \n",
       "184          70  23.875433  \n",
       "185          80  20.761246  \n",
       "186          73  27.055151  \n",
       "\n",
       "[187 rows x 38 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ff963cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=dbp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e5b95486",
   "metadata": {},
   "outputs": [],
   "source": [
    "org = features[\"dbp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5cb010e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CP</th>\n",
       "      <th>ST</th>\n",
       "      <th>DT</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dw_10</th>\n",
       "      <th>dw_25</th>\n",
       "      <th>dw_33</th>\n",
       "      <th>dw_50</th>\n",
       "      <th>dw_66</th>\n",
       "      <th>...</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>area_under_curve</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>BMI</th>\n",
       "      <th>hypertension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>774</td>\n",
       "      <td>241</td>\n",
       "      <td>609</td>\n",
       "      <td>100</td>\n",
       "      <td>319</td>\n",
       "      <td>263</td>\n",
       "      <td>243</td>\n",
       "      <td>167</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>673.754706</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>73</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>elevated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>976</td>\n",
       "      <td>316</td>\n",
       "      <td>259</td>\n",
       "      <td>103</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>60</td>\n",
       "      <td>671.104643</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>19.223376</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>853</td>\n",
       "      <td>344</td>\n",
       "      <td>162</td>\n",
       "      <td>104</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "      <td>118</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>571.545583</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>155</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>22.892820</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>874</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>105</td>\n",
       "      <td>460</td>\n",
       "      <td>380</td>\n",
       "      <td>332</td>\n",
       "      <td>238</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>66</td>\n",
       "      <td>821.935730</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>27.005131</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>893</td>\n",
       "      <td>187</td>\n",
       "      <td>696</td>\n",
       "      <td>106</td>\n",
       "      <td>380</td>\n",
       "      <td>217</td>\n",
       "      <td>180</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>77</td>\n",
       "      <td>649.000588</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>27.358845</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>214</td>\n",
       "      <td>775</td>\n",
       "      <td>185</td>\n",
       "      <td>567</td>\n",
       "      <td>96</td>\n",
       "      <td>349</td>\n",
       "      <td>272</td>\n",
       "      <td>232</td>\n",
       "      <td>160</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>71</td>\n",
       "      <td>560.121310</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>24.835763</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>215</td>\n",
       "      <td>948</td>\n",
       "      <td>244</td>\n",
       "      <td>646</td>\n",
       "      <td>97</td>\n",
       "      <td>417</td>\n",
       "      <td>333</td>\n",
       "      <td>297</td>\n",
       "      <td>207</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>65</td>\n",
       "      <td>710.871618</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>66</td>\n",
       "      <td>26.573129</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>216</td>\n",
       "      <td>719</td>\n",
       "      <td>163</td>\n",
       "      <td>549</td>\n",
       "      <td>98</td>\n",
       "      <td>519</td>\n",
       "      <td>365</td>\n",
       "      <td>313</td>\n",
       "      <td>171</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>65</td>\n",
       "      <td>593.734741</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>23.875433</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>217</td>\n",
       "      <td>751</td>\n",
       "      <td>255</td>\n",
       "      <td>551</td>\n",
       "      <td>99</td>\n",
       "      <td>444</td>\n",
       "      <td>341</td>\n",
       "      <td>292</td>\n",
       "      <td>187</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>71</td>\n",
       "      <td>596.576175</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>20.761246</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>218</td>\n",
       "      <td>715</td>\n",
       "      <td>170</td>\n",
       "      <td>519</td>\n",
       "      <td>9</td>\n",
       "      <td>489</td>\n",
       "      <td>345</td>\n",
       "      <td>296</td>\n",
       "      <td>186</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>73</td>\n",
       "      <td>717.270483</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>155</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>27.055151</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   CP   ST   DT  subject_id  dw_10  dw_25  dw_33  dw_50  dw_66  \\\n",
       "0             0  774  241  609         100    319    263    243    167     86   \n",
       "1             1  976  316  259         103    258    258    258    258    196   \n",
       "2             2  853  344  162         104    161    161    161    161    118   \n",
       "3             3  874  152  634         105    460    380    332    238    185   \n",
       "4             4  893  187  696         106    380    217    180    140    110   \n",
       "..          ...  ...  ...  ...         ...    ...    ...    ...    ...    ...   \n",
       "182         214  775  185  567          96    349    272    232    160    117   \n",
       "183         215  948  244  646          97    417    333    297    207    123   \n",
       "184         216  719  163  549          98    519    365    313    171    120   \n",
       "185         217  751  255  551          99    444    341    292    187    135   \n",
       "186         218  715  170  519           9    489    345    296    186    100   \n",
       "\n",
       "     ...  sbp  dbp  area_under_curve  Sex  Age  Height  Weight  Heart_Rate  \\\n",
       "0    ...  140   82        673.754706    1   68     150      63          73   \n",
       "1    ...  120   60        671.104643    1   63     153      45          76   \n",
       "2    ...  135   75        571.545583    1   67     155      55          72   \n",
       "3    ...  130   66        821.935730    1   86     161      70          69   \n",
       "4    ...  133   77        649.000588    0   59     171      80          66   \n",
       "..   ...  ...  ...               ...  ...  ...     ...     ...         ...   \n",
       "182  ...  136   71        560.121310    1   76     158      62          72   \n",
       "183  ...  143   65        710.871618    0   76     168      75          66   \n",
       "184  ...  116   65        593.734741    0   68     170      69          70   \n",
       "185  ...  133   71        596.576175    0   78     170      60          80   \n",
       "186  ...  123   73        717.270483    1   46     155      65          73   \n",
       "\n",
       "           BMI  hypertension  \n",
       "0    28.000000      elevated  \n",
       "1    19.223376       unknown  \n",
       "2    22.892820        normal  \n",
       "3    27.005131        normal  \n",
       "4    27.358845        normal  \n",
       "..         ...           ...  \n",
       "182  24.835763        normal  \n",
       "183  26.573129        normal  \n",
       "184  23.875433        normal  \n",
       "185  20.761246        normal  \n",
       "186  27.055151        normal  \n",
       "\n",
       "[187 rows x 39 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c35c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper =[]\n",
    "for i in range(len(features)):\n",
    "    if (features[\"dbp\"][i] < 80) & (features[\"dbp\"][i] > 60) :\n",
    "        hyper.append(\"normal\")\n",
    "    elif (features[\"dbp\"][i] < 89) & (features[\"dbp\"][i] > 80) :\n",
    "        hyper.append(\"elevated\")\n",
    "    elif (features[\"dbp\"][i] < 99) & (features[\"dbp\"][i] > 90) :\n",
    "        hyper.append(\"hypertension_stage1\")\n",
    "    elif (features[\"dbp\"][i] < 120) & (features[\"dbp\"][i] > 100) :\n",
    "        hyper.append(\"hypertension_stage2\")\n",
    "    elif (features[\"dbp\"][i] < 200) & (features[\"dbp\"][i] > 121) :\n",
    "        hyper.append(\"hypertensive_crisis\")\n",
    "    else:\n",
    "        hyper.append(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "809a467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal      144\n",
       "elevated     12\n",
       "Name: hypertension, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"hypertension\"] = hyper\n",
    "features = features[features[\"hypertension\"]!=\"unknown\"]\n",
    "features[\"hypertension\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8644a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "dbp_values = features[\"dbp\"].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 15))\n",
    "scaled_data = scaler.fit_transform(dbp_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f12e0a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\1731316840.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[\"dbp\"] = scaled_data\n"
     ]
    }
   ],
   "source": [
    "features[\"dbp\"] = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7d20cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63deebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # For scikit-learn <= 0.24\n",
    "# If you're using scikit-learn 0.24 or later, you can use:\n",
    "# from joblib import dump\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_model_size(model):\n",
    "    # Serialize the model and get the size in kilobytes\n",
    "    model_filename = \"temp_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    size_kb = os.path.getsize(model_filename) / 1024\n",
    "    os.remove(model_filename)\n",
    "    return size_kb\n",
    "\n",
    "def evaluate_models(data):\n",
    "    X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0','hypertension'], axis=1)\n",
    "    y = features['dbp']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    results_dict = {'Model': [], 'Mean Absolute Error': [], 'Root Mean Square': [], 'Model Size (KB)': []}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "        size_kb = get_model_size(model)\n",
    "\n",
    "        results_dict['Model'].append(model_name)\n",
    "        results_dict['Mean Absolute Error'].append(mae)\n",
    "        results_dict['Root Mean Square'].append(rmse)\n",
    "        results_dict['Model Size (KB)'].append(size_kb)\n",
    "\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "models = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'SVR': SVR(),\n",
    "}\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models.update({\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "    'MLPRegressor': MLPRegressor(),\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f0f9481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+01, tolerance: 1.782e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Model Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>3.659112</td>\n",
       "      <td>4.399869</td>\n",
       "      <td>707.594727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>3.761290</td>\n",
       "      <td>5.117400</td>\n",
       "      <td>1.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>3.799260</td>\n",
       "      <td>4.453069</td>\n",
       "      <td>31.143555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>3.484678</td>\n",
       "      <td>3.994212</td>\n",
       "      <td>31.631836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>5.259019</td>\n",
       "      <td>6.328068</td>\n",
       "      <td>12.157227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>3.755146</td>\n",
       "      <td>5.008997</td>\n",
       "      <td>1.502930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>3.576311</td>\n",
       "      <td>4.346591</td>\n",
       "      <td>1.584961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>3.513730</td>\n",
       "      <td>4.297848</td>\n",
       "      <td>1.600586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>4.063219</td>\n",
       "      <td>5.108393</td>\n",
       "      <td>160.996094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>3.872518</td>\n",
       "      <td>4.682930</td>\n",
       "      <td>61.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>6.264484</td>\n",
       "      <td>7.882219</td>\n",
       "      <td>93.233398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>3.858705</td>\n",
       "      <td>4.552350</td>\n",
       "      <td>149.137695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Root Mean Square  \\\n",
       "0       RandomForestRegressor             3.659112          4.399869   \n",
       "1            LinearRegression             3.761290          5.117400   \n",
       "2         KNeighborsRegressor             3.799260          4.453069   \n",
       "3                         SVR             3.484678          3.994212   \n",
       "4       DecisionTreeRegressor             5.259019          6.328068   \n",
       "5                       Ridge             3.755146          5.008997   \n",
       "6                       Lasso             3.576311          4.346591   \n",
       "7                  ElasticNet             3.513730          4.297848   \n",
       "8   GradientBoostingRegressor             4.063219          5.108393   \n",
       "9           AdaBoostRegressor             3.872518          4.682930   \n",
       "10               MLPRegressor             6.264484          7.882219   \n",
       "11               XGBRegressor             3.858705          4.552350   \n",
       "\n",
       "    Model Size (KB)  \n",
       "0        707.594727  \n",
       "1          1.835938  \n",
       "2         31.143555  \n",
       "3         31.631836  \n",
       "4         12.157227  \n",
       "5          1.502930  \n",
       "6          1.584961  \n",
       "7          1.600586  \n",
       "8        160.996094  \n",
       "9         61.859375  \n",
       "10        93.233398  \n",
       "11       149.137695  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_models(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "870f9c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.994211677991227, 3.4846779708212785)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "rf = SVR()\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0','hypertension'], axis=1)\n",
    "y = features['dbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_1 = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_1)\n",
    "rmse = (mean_squared_error(y_test, y_pred_1))**0.5\n",
    "rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc25d8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.536999982504963, 3.78940795559667)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0','hypertension'], axis=1)\n",
    "y = features['dbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_1 = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_1)\n",
    "rmse = (mean_squared_error(y_test, y_pred_1))**0.5\n",
    "rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e797b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\1826725953.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[\"hypertension\"]= features['hypertension'].map({'normal': 0,'normal1':5,'hypertensive_crisis':6, 'elevated': 1, \"hypertension_stage1\": 2,'hypertension_stage2':3,'unknown':4})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "      ..\n",
       "182    0\n",
       "183    0\n",
       "184    0\n",
       "185    0\n",
       "186    0\n",
       "Name: hypertension, Length: 156, dtype: int64>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"hypertension\"]= features['hypertension'].map({'normal': 0,'normal1':5,'hypertensive_crisis':6, 'elevated': 1, \"hypertension_stage1\": 2,'hypertension_stage2':3,'unknown':4})\n",
    "features[\"hypertension\"].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0da997cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_model_size(model):\n",
    "    # Serialize the model and get the size in kilobytes\n",
    "    model_filename = \"temp_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    size_kb = os.path.getsize(model_filename) / 1024\n",
    "    os.remove(model_filename)\n",
    "    return size_kb\n",
    "\n",
    "def evaluate_models(data):\n",
    "    X = features.drop(['sbp',\"subject_id\",'Unnamed: 0','hypertension'], axis=1)\n",
    "    y = features['hypertension']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_test[\"dbp\"] = y_pred_1\n",
    "\n",
    "    results_dict = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-score': [], 'ROC AUC': [], 'Model Size (KB)': []}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        size_kb = get_model_size(model)\n",
    "\n",
    "        results_dict['Model'].append(model_name)\n",
    "        results_dict['Accuracy'].append(accuracy)\n",
    "        results_dict['Precision'].append(precision)\n",
    "        results_dict['Recall'].append(recall)\n",
    "        results_dict['F1-score'].append(f1)\n",
    "        results_dict['ROC AUC'].append(roc_auc)\n",
    "        results_dict['Model Size (KB)'].append(size_kb)\n",
    "\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8634cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Model Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>128.977539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.811523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>31.745117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.086914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.233398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision  Recall  F1-score   ROC AUC  \\\n",
       "0  RandomForestClassifier  0.957447        0.0     0.0       0.0  0.500000   \n",
       "1      LogisticRegression  0.851064        0.0     0.0       0.0  0.444444   \n",
       "2    KNeighborsClassifier  0.936170        0.0     0.0       0.0  0.488889   \n",
       "3  DecisionTreeClassifier  0.957447        0.0     0.0       0.0  0.500000   \n",
       "4                     SVC  0.957447        0.0     0.0       0.0  0.500000   \n",
       "\n",
       "   Model Size (KB)  \n",
       "0       128.977539  \n",
       "1         1.811523  \n",
       "2        31.745117  \n",
       "3         2.086914  \n",
       "4        11.233398  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_models(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e1fed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9574468085106383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "rf=SVC()\n",
    "X = features.drop(['sbp',\"subject_id\",'Unnamed: 0','hypertension'], axis=1)\n",
    "y = features['hypertension']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "X_test[\"dbp\"] = y_pred_1\n",
    "y_pred_2 = rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_2)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c35c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\1502124082.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[\"dbp\"] = org\n"
     ]
    }
   ],
   "source": [
    "features[\"dbp\"] = org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333b4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2d74462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    144\n",
       "1     12\n",
       "Name: hypertension, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"hypertension\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70f4f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.141887228157504, 5.165957446808512)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "y = features['dbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test[\"hypertension\"]=y_pred_2\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d49a4957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.00076767147194, 8.477446808510637)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "y = features['sbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test[\"hypertension\"]=y_pred_2\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea01f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib # For scikit-learn <= 0.24\n",
    "# If you're using scikit-learn 0.24 or later, you can use:\n",
    "# from joblib import dump\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_model_size(model):\n",
    "    # Serialize the model and get the size in kilobytes\n",
    "    model_filename = \"temp_model.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    size_kb = os.path.getsize(model_filename) / 1024\n",
    "    os.remove(model_filename)\n",
    "    return size_kb\n",
    "\n",
    "def evaluate_models(data):\n",
    "    X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "    y = features['sbp']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_test[\"hypertension\"]=y_pred_2\n",
    "\n",
    "    results_dict = {'Model': [], 'Mean Absolute Error': [], 'Root Mean Square': [], 'Model Size (KB)': []}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "        size_kb = get_model_size(model)\n",
    "\n",
    "        results_dict['Model'].append(model_name)\n",
    "        results_dict['Mean Absolute Error'].append(mae)\n",
    "        results_dict['Root Mean Square'].append(rmse)\n",
    "        results_dict['Model Size (KB)'].append(size_kb)\n",
    "\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "    return results_df\n",
    "\n",
    "models = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'SVR': SVR(),\n",
    "}\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "models.update({\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "    'MLPRegressor': MLPRegressor(),\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7e28a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.117e+01, tolerance: 2.686e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+02, tolerance: 2.686e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Model Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>8.495745</td>\n",
       "      <td>11.287282</td>\n",
       "      <td>794.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>8.948439</td>\n",
       "      <td>11.962871</td>\n",
       "      <td>1.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>10.761702</td>\n",
       "      <td>13.768079</td>\n",
       "      <td>32.041992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>10.291132</td>\n",
       "      <td>12.215050</td>\n",
       "      <td>33.631836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>13.425532</td>\n",
       "      <td>16.197583</td>\n",
       "      <td>12.938477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>8.526040</td>\n",
       "      <td>11.366481</td>\n",
       "      <td>1.526367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>7.977720</td>\n",
       "      <td>10.856242</td>\n",
       "      <td>1.624023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>8.045767</td>\n",
       "      <td>10.945267</td>\n",
       "      <td>1.624023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>8.910865</td>\n",
       "      <td>12.828485</td>\n",
       "      <td>159.856445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>9.744385</td>\n",
       "      <td>12.874556</td>\n",
       "      <td>63.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>9.488597</td>\n",
       "      <td>12.379182</td>\n",
       "      <td>95.592773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>10.092333</td>\n",
       "      <td>13.604806</td>\n",
       "      <td>162.329102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Root Mean Square  \\\n",
       "0       RandomForestRegressor             8.495745         11.287282   \n",
       "1            LinearRegression             8.948439         11.962871   \n",
       "2         KNeighborsRegressor            10.761702         13.768079   \n",
       "3                         SVR            10.291132         12.215050   \n",
       "4       DecisionTreeRegressor            13.425532         16.197583   \n",
       "5                       Ridge             8.526040         11.366481   \n",
       "6                       Lasso             7.977720         10.856242   \n",
       "7                  ElasticNet             8.045767         10.945267   \n",
       "8   GradientBoostingRegressor             8.910865         12.828485   \n",
       "9           AdaBoostRegressor             9.744385         12.874556   \n",
       "10               MLPRegressor             9.488597         12.379182   \n",
       "11               XGBRegressor            10.092333         13.604806   \n",
       "\n",
       "    Model Size (KB)  \n",
       "0        794.610352  \n",
       "1          1.875000  \n",
       "2         32.041992  \n",
       "3         33.631836  \n",
       "4         12.938477  \n",
       "5          1.526367  \n",
       "6          1.624023  \n",
       "7          1.624023  \n",
       "8        159.856445  \n",
       "9         63.375000  \n",
       "10        95.592773  \n",
       "11       162.329102  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_value=evaluate_models(features)\n",
    "sbp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5474f5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.224e+01, tolerance: 4.189e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\varun\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.406e+01, tolerance: 4.189e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Model Size (KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>5.160213</td>\n",
       "      <td>6.127770</td>\n",
       "      <td>654.735352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>6.384507</td>\n",
       "      <td>8.564361</td>\n",
       "      <td>1.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>5.825532</td>\n",
       "      <td>6.828040</td>\n",
       "      <td>32.041992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>5.243138</td>\n",
       "      <td>6.001648</td>\n",
       "      <td>32.764648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>6.021277</td>\n",
       "      <td>7.030329</td>\n",
       "      <td>11.438477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>5.822410</td>\n",
       "      <td>7.625165</td>\n",
       "      <td>1.526367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>5.436591</td>\n",
       "      <td>6.634736</td>\n",
       "      <td>1.624023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>5.346156</td>\n",
       "      <td>6.553125</td>\n",
       "      <td>1.624023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>5.573686</td>\n",
       "      <td>6.810985</td>\n",
       "      <td>165.120117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>5.302371</td>\n",
       "      <td>6.392904</td>\n",
       "      <td>59.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>58.892896</td>\n",
       "      <td>66.685521</td>\n",
       "      <td>92.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>5.313571</td>\n",
       "      <td>6.354826</td>\n",
       "      <td>160.529297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Mean Absolute Error  Root Mean Square  \\\n",
       "0       RandomForestRegressor             5.160213          6.127770   \n",
       "1            LinearRegression             6.384507          8.564361   \n",
       "2         KNeighborsRegressor             5.825532          6.828040   \n",
       "3                         SVR             5.243138          6.001648   \n",
       "4       DecisionTreeRegressor             6.021277          7.030329   \n",
       "5                       Ridge             5.822410          7.625165   \n",
       "6                       Lasso             5.436591          6.634736   \n",
       "7                  ElasticNet             5.346156          6.553125   \n",
       "8   GradientBoostingRegressor             5.573686          6.810985   \n",
       "9           AdaBoostRegressor             5.302371          6.392904   \n",
       "10               MLPRegressor            58.892896         66.685521   \n",
       "11               XGBRegressor             5.313571          6.354826   \n",
       "\n",
       "    Model Size (KB)  \n",
       "0        654.735352  \n",
       "1          1.875000  \n",
       "2         32.041992  \n",
       "3         32.764648  \n",
       "4         11.438477  \n",
       "5          1.526367  \n",
       "6          1.624023  \n",
       "7          1.624023  \n",
       "8        165.120117  \n",
       "9         59.125000  \n",
       "10        92.246094  \n",
       "11       160.529297  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbp_value=evaluate_models(features)\n",
    "dbp_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eef9808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.028846\n",
      "0:\tlearn: 6.1656224\ttotal: 2.53ms\tremaining: 2.53s\n",
      "1:\tlearn: 6.1188956\ttotal: 4.74ms\tremaining: 2.37s\n",
      "2:\tlearn: 6.0736245\ttotal: 6.61ms\tremaining: 2.2s\n",
      "3:\tlearn: 6.0308019\ttotal: 8.27ms\tremaining: 2.06s\n",
      "4:\tlearn: 5.9921229\ttotal: 10.2ms\tremaining: 2.03s\n",
      "5:\tlearn: 5.9550494\ttotal: 12ms\tremaining: 1.98s\n",
      "6:\tlearn: 5.9128185\ttotal: 14ms\tremaining: 1.99s\n",
      "7:\tlearn: 5.8758870\ttotal: 15.9ms\tremaining: 1.97s\n",
      "8:\tlearn: 5.8321874\ttotal: 17.7ms\tremaining: 1.95s\n",
      "9:\tlearn: 5.7931698\ttotal: 19.5ms\tremaining: 1.93s\n",
      "10:\tlearn: 5.7574283\ttotal: 20.2ms\tremaining: 1.82s\n",
      "11:\tlearn: 5.7272406\ttotal: 21.9ms\tremaining: 1.81s\n",
      "12:\tlearn: 5.6989194\ttotal: 23.9ms\tremaining: 1.82s\n",
      "13:\tlearn: 5.6572874\ttotal: 25.5ms\tremaining: 1.8s\n",
      "14:\tlearn: 5.6188868\ttotal: 27.3ms\tremaining: 1.79s\n",
      "15:\tlearn: 5.5821504\ttotal: 29.5ms\tremaining: 1.81s\n",
      "16:\tlearn: 5.5567317\ttotal: 31.2ms\tremaining: 1.8s\n",
      "17:\tlearn: 5.5229820\ttotal: 32.8ms\tremaining: 1.79s\n",
      "18:\tlearn: 5.4954210\ttotal: 34.6ms\tremaining: 1.79s\n",
      "19:\tlearn: 5.4655916\ttotal: 36.4ms\tremaining: 1.78s\n",
      "20:\tlearn: 5.4365042\ttotal: 38.2ms\tremaining: 1.78s\n",
      "21:\tlearn: 5.4105418\ttotal: 39.7ms\tremaining: 1.77s\n",
      "22:\tlearn: 5.3671099\ttotal: 41.5ms\tremaining: 1.76s\n",
      "23:\tlearn: 5.3309593\ttotal: 43.8ms\tremaining: 1.78s\n",
      "24:\tlearn: 5.2992158\ttotal: 45.8ms\tremaining: 1.78s\n",
      "25:\tlearn: 5.2676268\ttotal: 47.6ms\tremaining: 1.78s\n",
      "26:\tlearn: 5.2367003\ttotal: 49.7ms\tremaining: 1.79s\n",
      "27:\tlearn: 5.2127946\ttotal: 52ms\tremaining: 1.8s\n",
      "28:\tlearn: 5.1868562\ttotal: 54ms\tremaining: 1.81s\n",
      "29:\tlearn: 5.1634752\ttotal: 56.8ms\tremaining: 1.84s\n",
      "30:\tlearn: 5.1380310\ttotal: 59.9ms\tremaining: 1.87s\n",
      "31:\tlearn: 5.1068665\ttotal: 62.1ms\tremaining: 1.88s\n",
      "32:\tlearn: 5.0755653\ttotal: 64.7ms\tremaining: 1.9s\n",
      "33:\tlearn: 5.0409709\ttotal: 67.4ms\tremaining: 1.91s\n",
      "34:\tlearn: 5.0144801\ttotal: 69.6ms\tremaining: 1.92s\n",
      "35:\tlearn: 4.9915081\ttotal: 71.3ms\tremaining: 1.91s\n",
      "36:\tlearn: 4.9672081\ttotal: 73ms\tremaining: 1.9s\n",
      "37:\tlearn: 4.9432829\ttotal: 76ms\tremaining: 1.92s\n",
      "38:\tlearn: 4.9202028\ttotal: 78.2ms\tremaining: 1.93s\n",
      "39:\tlearn: 4.8956014\ttotal: 80.4ms\tremaining: 1.93s\n",
      "40:\tlearn: 4.8732358\ttotal: 83.6ms\tremaining: 1.96s\n",
      "41:\tlearn: 4.8398614\ttotal: 85.4ms\tremaining: 1.95s\n",
      "42:\tlearn: 4.8181454\ttotal: 86.9ms\tremaining: 1.93s\n",
      "43:\tlearn: 4.7960083\ttotal: 88.5ms\tremaining: 1.92s\n",
      "44:\tlearn: 4.7605059\ttotal: 91.9ms\tremaining: 1.95s\n",
      "45:\tlearn: 4.7369506\ttotal: 94.1ms\tremaining: 1.95s\n",
      "46:\tlearn: 4.7236866\ttotal: 96.2ms\tremaining: 1.95s\n",
      "47:\tlearn: 4.6931704\ttotal: 99.3ms\tremaining: 1.97s\n",
      "48:\tlearn: 4.6776669\ttotal: 101ms\tremaining: 1.96s\n",
      "49:\tlearn: 4.6608104\ttotal: 103ms\tremaining: 1.95s\n",
      "50:\tlearn: 4.6261209\ttotal: 104ms\tremaining: 1.94s\n",
      "51:\tlearn: 4.5945707\ttotal: 107ms\tremaining: 1.95s\n",
      "52:\tlearn: 4.5736002\ttotal: 109ms\tremaining: 1.95s\n",
      "53:\tlearn: 4.5504673\ttotal: 111ms\tremaining: 1.94s\n",
      "54:\tlearn: 4.5332751\ttotal: 113ms\tremaining: 1.94s\n",
      "55:\tlearn: 4.5057263\ttotal: 115ms\tremaining: 1.94s\n",
      "56:\tlearn: 4.4906015\ttotal: 118ms\tremaining: 1.96s\n",
      "57:\tlearn: 4.4670369\ttotal: 120ms\tremaining: 1.95s\n",
      "58:\tlearn: 4.4404370\ttotal: 123ms\tremaining: 1.96s\n",
      "59:\tlearn: 4.4169294\ttotal: 124ms\tremaining: 1.95s\n",
      "60:\tlearn: 4.4006031\ttotal: 126ms\tremaining: 1.94s\n",
      "61:\tlearn: 4.3813598\ttotal: 128ms\tremaining: 1.93s\n",
      "62:\tlearn: 4.3674532\ttotal: 130ms\tremaining: 1.93s\n",
      "63:\tlearn: 4.3439557\ttotal: 131ms\tremaining: 1.92s\n",
      "64:\tlearn: 4.3252127\ttotal: 133ms\tremaining: 1.91s\n",
      "65:\tlearn: 4.3084886\ttotal: 134ms\tremaining: 1.9s\n",
      "66:\tlearn: 4.2890518\ttotal: 136ms\tremaining: 1.9s\n",
      "67:\tlearn: 4.2660540\ttotal: 138ms\tremaining: 1.89s\n",
      "68:\tlearn: 4.2447879\ttotal: 141ms\tremaining: 1.9s\n",
      "69:\tlearn: 4.2234227\ttotal: 143ms\tremaining: 1.9s\n",
      "70:\tlearn: 4.2067962\ttotal: 145ms\tremaining: 1.9s\n",
      "71:\tlearn: 4.1923397\ttotal: 147ms\tremaining: 1.9s\n",
      "72:\tlearn: 4.1755942\ttotal: 149ms\tremaining: 1.89s\n",
      "73:\tlearn: 4.1506992\ttotal: 151ms\tremaining: 1.88s\n",
      "74:\tlearn: 4.1354095\ttotal: 153ms\tremaining: 1.89s\n",
      "75:\tlearn: 4.1213721\ttotal: 155ms\tremaining: 1.89s\n",
      "76:\tlearn: 4.1088459\ttotal: 158ms\tremaining: 1.89s\n",
      "77:\tlearn: 4.0943582\ttotal: 160ms\tremaining: 1.89s\n",
      "78:\tlearn: 4.0699749\ttotal: 162ms\tremaining: 1.89s\n",
      "79:\tlearn: 4.0486039\ttotal: 164ms\tremaining: 1.88s\n",
      "80:\tlearn: 4.0284417\ttotal: 166ms\tremaining: 1.88s\n",
      "81:\tlearn: 4.0137851\ttotal: 168ms\tremaining: 1.88s\n",
      "82:\tlearn: 3.9937107\ttotal: 170ms\tremaining: 1.88s\n",
      "83:\tlearn: 3.9751939\ttotal: 173ms\tremaining: 1.89s\n",
      "84:\tlearn: 3.9441385\ttotal: 176ms\tremaining: 1.89s\n",
      "85:\tlearn: 3.9248328\ttotal: 178ms\tremaining: 1.89s\n",
      "86:\tlearn: 3.9052270\ttotal: 180ms\tremaining: 1.89s\n",
      "87:\tlearn: 3.8851167\ttotal: 181ms\tremaining: 1.88s\n",
      "88:\tlearn: 3.8678657\ttotal: 184ms\tremaining: 1.89s\n",
      "89:\tlearn: 3.8547191\ttotal: 188ms\tremaining: 1.9s\n",
      "90:\tlearn: 3.8446477\ttotal: 191ms\tremaining: 1.9s\n",
      "91:\tlearn: 3.8280920\ttotal: 193ms\tremaining: 1.91s\n",
      "92:\tlearn: 3.8077430\ttotal: 195ms\tremaining: 1.9s\n",
      "93:\tlearn: 3.7858380\ttotal: 197ms\tremaining: 1.9s\n",
      "94:\tlearn: 3.7623114\ttotal: 200ms\tremaining: 1.91s\n",
      "95:\tlearn: 3.7481519\ttotal: 202ms\tremaining: 1.9s\n",
      "96:\tlearn: 3.7379580\ttotal: 204ms\tremaining: 1.9s\n",
      "97:\tlearn: 3.7295148\ttotal: 206ms\tremaining: 1.89s\n",
      "98:\tlearn: 3.7053632\ttotal: 207ms\tremaining: 1.89s\n",
      "99:\tlearn: 3.6905562\ttotal: 210ms\tremaining: 1.89s\n",
      "100:\tlearn: 3.6740566\ttotal: 212ms\tremaining: 1.89s\n",
      "101:\tlearn: 3.6620426\ttotal: 230ms\tremaining: 2.02s\n",
      "102:\tlearn: 3.6457740\ttotal: 232ms\tremaining: 2.02s\n",
      "103:\tlearn: 3.6316722\ttotal: 235ms\tremaining: 2.02s\n",
      "104:\tlearn: 3.6089100\ttotal: 237ms\tremaining: 2.02s\n",
      "105:\tlearn: 3.5934607\ttotal: 239ms\tremaining: 2.02s\n",
      "106:\tlearn: 3.5787594\ttotal: 241ms\tremaining: 2.01s\n",
      "107:\tlearn: 3.5675655\ttotal: 243ms\tremaining: 2s\n",
      "108:\tlearn: 3.5575278\ttotal: 244ms\tremaining: 2s\n",
      "109:\tlearn: 3.5463064\ttotal: 247ms\tremaining: 2s\n",
      "110:\tlearn: 3.5360915\ttotal: 249ms\tremaining: 1.99s\n",
      "111:\tlearn: 3.5174834\ttotal: 252ms\tremaining: 2s\n",
      "112:\tlearn: 3.5042633\ttotal: 254ms\tremaining: 1.99s\n",
      "113:\tlearn: 3.4874045\ttotal: 256ms\tremaining: 1.99s\n",
      "114:\tlearn: 3.4695255\ttotal: 258ms\tremaining: 1.98s\n",
      "115:\tlearn: 3.4610971\ttotal: 259ms\tremaining: 1.97s\n",
      "116:\tlearn: 3.4454213\ttotal: 261ms\tremaining: 1.97s\n",
      "117:\tlearn: 3.4264699\ttotal: 264ms\tremaining: 1.97s\n",
      "118:\tlearn: 3.4188203\ttotal: 266ms\tremaining: 1.97s\n",
      "119:\tlearn: 3.3994391\ttotal: 269ms\tremaining: 1.97s\n",
      "120:\tlearn: 3.3877228\ttotal: 271ms\tremaining: 1.97s\n",
      "121:\tlearn: 3.3738246\ttotal: 273ms\tremaining: 1.96s\n",
      "122:\tlearn: 3.3560345\ttotal: 275ms\tremaining: 1.96s\n",
      "123:\tlearn: 3.3466356\ttotal: 278ms\tremaining: 1.96s\n",
      "124:\tlearn: 3.3308150\ttotal: 280ms\tremaining: 1.96s\n",
      "125:\tlearn: 3.3176719\ttotal: 283ms\tremaining: 1.97s\n",
      "126:\tlearn: 3.3032489\ttotal: 290ms\tremaining: 1.99s\n",
      "127:\tlearn: 3.2922296\ttotal: 303ms\tremaining: 2.07s\n",
      "128:\tlearn: 3.2754725\ttotal: 322ms\tremaining: 2.17s\n",
      "129:\tlearn: 3.2649062\ttotal: 334ms\tremaining: 2.23s\n",
      "130:\tlearn: 3.2592091\ttotal: 350ms\tremaining: 2.32s\n",
      "131:\tlearn: 3.2514261\ttotal: 368ms\tremaining: 2.42s\n",
      "132:\tlearn: 3.2373302\ttotal: 380ms\tremaining: 2.48s\n",
      "133:\tlearn: 3.2294263\ttotal: 390ms\tremaining: 2.52s\n",
      "134:\tlearn: 3.2103316\ttotal: 412ms\tremaining: 2.64s\n",
      "135:\tlearn: 3.1974637\ttotal: 427ms\tremaining: 2.71s\n",
      "136:\tlearn: 3.1808101\ttotal: 444ms\tremaining: 2.79s\n",
      "137:\tlearn: 3.1625098\ttotal: 449ms\tremaining: 2.8s\n",
      "138:\tlearn: 3.1535447\ttotal: 461ms\tremaining: 2.86s\n",
      "139:\tlearn: 3.1416244\ttotal: 471ms\tremaining: 2.89s\n",
      "140:\tlearn: 3.1314551\ttotal: 478ms\tremaining: 2.91s\n",
      "141:\tlearn: 3.1151720\ttotal: 483ms\tremaining: 2.92s\n",
      "142:\tlearn: 3.1010068\ttotal: 489ms\tremaining: 2.93s\n",
      "143:\tlearn: 3.0949133\ttotal: 494ms\tremaining: 2.94s\n",
      "144:\tlearn: 3.0794108\ttotal: 498ms\tremaining: 2.94s\n",
      "145:\tlearn: 3.0655606\ttotal: 503ms\tremaining: 2.94s\n",
      "146:\tlearn: 3.0542494\ttotal: 507ms\tremaining: 2.94s\n",
      "147:\tlearn: 3.0432160\ttotal: 510ms\tremaining: 2.94s\n",
      "148:\tlearn: 3.0273548\ttotal: 515ms\tremaining: 2.94s\n",
      "149:\tlearn: 3.0086460\ttotal: 518ms\tremaining: 2.94s\n",
      "150:\tlearn: 2.9973906\ttotal: 521ms\tremaining: 2.93s\n",
      "151:\tlearn: 2.9830612\ttotal: 525ms\tremaining: 2.93s\n",
      "152:\tlearn: 2.9698933\ttotal: 528ms\tremaining: 2.92s\n",
      "153:\tlearn: 2.9540601\ttotal: 533ms\tremaining: 2.93s\n",
      "154:\tlearn: 2.9422992\ttotal: 543ms\tremaining: 2.96s\n",
      "155:\tlearn: 2.9291162\ttotal: 547ms\tremaining: 2.96s\n",
      "156:\tlearn: 2.9121992\ttotal: 551ms\tremaining: 2.96s\n",
      "157:\tlearn: 2.9017002\ttotal: 554ms\tremaining: 2.95s\n",
      "158:\tlearn: 2.8816028\ttotal: 557ms\tremaining: 2.94s\n",
      "159:\tlearn: 2.8737468\ttotal: 559ms\tremaining: 2.94s\n",
      "160:\tlearn: 2.8538277\ttotal: 561ms\tremaining: 2.92s\n",
      "161:\tlearn: 2.8386692\ttotal: 564ms\tremaining: 2.92s\n",
      "162:\tlearn: 2.8259531\ttotal: 566ms\tremaining: 2.9s\n",
      "163:\tlearn: 2.8118878\ttotal: 568ms\tremaining: 2.89s\n",
      "164:\tlearn: 2.7997811\ttotal: 569ms\tremaining: 2.88s\n",
      "165:\tlearn: 2.7895661\ttotal: 571ms\tremaining: 2.87s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166:\tlearn: 2.7741171\ttotal: 575ms\tremaining: 2.87s\n",
      "167:\tlearn: 2.7596712\ttotal: 578ms\tremaining: 2.86s\n",
      "168:\tlearn: 2.7502840\ttotal: 580ms\tremaining: 2.85s\n",
      "169:\tlearn: 2.7344261\ttotal: 583ms\tremaining: 2.85s\n",
      "170:\tlearn: 2.7234400\ttotal: 585ms\tremaining: 2.84s\n",
      "171:\tlearn: 2.7078526\ttotal: 588ms\tremaining: 2.83s\n",
      "172:\tlearn: 2.6990983\ttotal: 593ms\tremaining: 2.83s\n",
      "173:\tlearn: 2.6920845\ttotal: 597ms\tremaining: 2.83s\n",
      "174:\tlearn: 2.6807444\ttotal: 599ms\tremaining: 2.82s\n",
      "175:\tlearn: 2.6721076\ttotal: 601ms\tremaining: 2.81s\n",
      "176:\tlearn: 2.6554858\ttotal: 604ms\tremaining: 2.81s\n",
      "177:\tlearn: 2.6437540\ttotal: 606ms\tremaining: 2.8s\n",
      "178:\tlearn: 2.6347626\ttotal: 608ms\tremaining: 2.79s\n",
      "179:\tlearn: 2.6269431\ttotal: 611ms\tremaining: 2.78s\n",
      "180:\tlearn: 2.6106437\ttotal: 613ms\tremaining: 2.77s\n",
      "181:\tlearn: 2.6012365\ttotal: 616ms\tremaining: 2.77s\n",
      "182:\tlearn: 2.5849517\ttotal: 618ms\tremaining: 2.76s\n",
      "183:\tlearn: 2.5754009\ttotal: 620ms\tremaining: 2.75s\n",
      "184:\tlearn: 2.5679551\ttotal: 623ms\tremaining: 2.74s\n",
      "185:\tlearn: 2.5583429\ttotal: 626ms\tremaining: 2.74s\n",
      "186:\tlearn: 2.5519570\ttotal: 628ms\tremaining: 2.73s\n",
      "187:\tlearn: 2.5463962\ttotal: 631ms\tremaining: 2.73s\n",
      "188:\tlearn: 2.5352680\ttotal: 634ms\tremaining: 2.72s\n",
      "189:\tlearn: 2.5273634\ttotal: 638ms\tremaining: 2.72s\n",
      "190:\tlearn: 2.5118195\ttotal: 642ms\tremaining: 2.72s\n",
      "191:\tlearn: 2.4990712\ttotal: 645ms\tremaining: 2.71s\n",
      "192:\tlearn: 2.4939261\ttotal: 648ms\tremaining: 2.71s\n",
      "193:\tlearn: 2.4830789\ttotal: 650ms\tremaining: 2.7s\n",
      "194:\tlearn: 2.4777632\ttotal: 652ms\tremaining: 2.69s\n",
      "195:\tlearn: 2.4689611\ttotal: 654ms\tremaining: 2.68s\n",
      "196:\tlearn: 2.4552235\ttotal: 657ms\tremaining: 2.68s\n",
      "197:\tlearn: 2.4491428\ttotal: 659ms\tremaining: 2.67s\n",
      "198:\tlearn: 2.4364992\ttotal: 661ms\tremaining: 2.66s\n",
      "199:\tlearn: 2.4306273\ttotal: 663ms\tremaining: 2.65s\n",
      "200:\tlearn: 2.4225609\ttotal: 665ms\tremaining: 2.64s\n",
      "201:\tlearn: 2.4064747\ttotal: 667ms\tremaining: 2.63s\n",
      "202:\tlearn: 2.3931130\ttotal: 669ms\tremaining: 2.63s\n",
      "203:\tlearn: 2.3887277\ttotal: 672ms\tremaining: 2.62s\n",
      "204:\tlearn: 2.3809426\ttotal: 676ms\tremaining: 2.62s\n",
      "205:\tlearn: 2.3744423\ttotal: 679ms\tremaining: 2.62s\n",
      "206:\tlearn: 2.3678358\ttotal: 682ms\tremaining: 2.61s\n",
      "207:\tlearn: 2.3596802\ttotal: 684ms\tremaining: 2.6s\n",
      "208:\tlearn: 2.3547942\ttotal: 686ms\tremaining: 2.6s\n",
      "209:\tlearn: 2.3381573\ttotal: 690ms\tremaining: 2.59s\n",
      "210:\tlearn: 2.3263672\ttotal: 694ms\tremaining: 2.59s\n",
      "211:\tlearn: 2.3141962\ttotal: 696ms\tremaining: 2.59s\n",
      "212:\tlearn: 2.2991354\ttotal: 698ms\tremaining: 2.58s\n",
      "213:\tlearn: 2.2939828\ttotal: 701ms\tremaining: 2.57s\n",
      "214:\tlearn: 2.2900515\ttotal: 704ms\tremaining: 2.57s\n",
      "215:\tlearn: 2.2749286\ttotal: 707ms\tremaining: 2.57s\n",
      "216:\tlearn: 2.2681835\ttotal: 710ms\tremaining: 2.56s\n",
      "217:\tlearn: 2.2553013\ttotal: 712ms\tremaining: 2.56s\n",
      "218:\tlearn: 2.2525948\ttotal: 715ms\tremaining: 2.55s\n",
      "219:\tlearn: 2.2362979\ttotal: 716ms\tremaining: 2.54s\n",
      "220:\tlearn: 2.2313104\ttotal: 719ms\tremaining: 2.53s\n",
      "221:\tlearn: 2.2189249\ttotal: 734ms\tremaining: 2.57s\n",
      "222:\tlearn: 2.2083547\ttotal: 736ms\tremaining: 2.56s\n",
      "223:\tlearn: 2.1970456\ttotal: 739ms\tremaining: 2.56s\n",
      "224:\tlearn: 2.1871607\ttotal: 742ms\tremaining: 2.56s\n",
      "225:\tlearn: 2.1759926\ttotal: 744ms\tremaining: 2.55s\n",
      "226:\tlearn: 2.1700833\ttotal: 745ms\tremaining: 2.54s\n",
      "227:\tlearn: 2.1520251\ttotal: 747ms\tremaining: 2.53s\n",
      "228:\tlearn: 2.1417151\ttotal: 749ms\tremaining: 2.52s\n",
      "229:\tlearn: 2.1263945\ttotal: 752ms\tremaining: 2.52s\n",
      "230:\tlearn: 2.1180238\ttotal: 755ms\tremaining: 2.51s\n",
      "231:\tlearn: 2.1064896\ttotal: 758ms\tremaining: 2.51s\n",
      "232:\tlearn: 2.0879672\ttotal: 760ms\tremaining: 2.5s\n",
      "233:\tlearn: 2.0790003\ttotal: 762ms\tremaining: 2.49s\n",
      "234:\tlearn: 2.0688927\ttotal: 766ms\tremaining: 2.49s\n",
      "235:\tlearn: 2.0550475\ttotal: 769ms\tremaining: 2.49s\n",
      "236:\tlearn: 2.0509931\ttotal: 772ms\tremaining: 2.48s\n",
      "237:\tlearn: 2.0420392\ttotal: 774ms\tremaining: 2.48s\n",
      "238:\tlearn: 2.0369761\ttotal: 776ms\tremaining: 2.47s\n",
      "239:\tlearn: 2.0264773\ttotal: 777ms\tremaining: 2.46s\n",
      "240:\tlearn: 2.0193489\ttotal: 779ms\tremaining: 2.45s\n",
      "241:\tlearn: 2.0050120\ttotal: 782ms\tremaining: 2.45s\n",
      "242:\tlearn: 1.9909882\ttotal: 785ms\tremaining: 2.45s\n",
      "243:\tlearn: 1.9800597\ttotal: 788ms\tremaining: 2.44s\n",
      "244:\tlearn: 1.9697763\ttotal: 790ms\tremaining: 2.43s\n",
      "245:\tlearn: 1.9559908\ttotal: 792ms\tremaining: 2.43s\n",
      "246:\tlearn: 1.9433883\ttotal: 794ms\tremaining: 2.42s\n",
      "247:\tlearn: 1.9363834\ttotal: 797ms\tremaining: 2.42s\n",
      "248:\tlearn: 1.9227220\ttotal: 802ms\tremaining: 2.42s\n",
      "249:\tlearn: 1.9177003\ttotal: 804ms\tremaining: 2.41s\n",
      "250:\tlearn: 1.9144240\ttotal: 805ms\tremaining: 2.4s\n",
      "251:\tlearn: 1.9002575\ttotal: 807ms\tremaining: 2.4s\n",
      "252:\tlearn: 1.8977132\ttotal: 809ms\tremaining: 2.39s\n",
      "253:\tlearn: 1.8892847\ttotal: 810ms\tremaining: 2.38s\n",
      "254:\tlearn: 1.8779881\ttotal: 815ms\tremaining: 2.38s\n",
      "255:\tlearn: 1.8644024\ttotal: 819ms\tremaining: 2.38s\n",
      "256:\tlearn: 1.8505189\ttotal: 820ms\tremaining: 2.37s\n",
      "257:\tlearn: 1.8446778\ttotal: 822ms\tremaining: 2.37s\n",
      "258:\tlearn: 1.8378817\ttotal: 824ms\tremaining: 2.36s\n",
      "259:\tlearn: 1.8244078\ttotal: 826ms\tremaining: 2.35s\n",
      "260:\tlearn: 1.8122152\ttotal: 830ms\tremaining: 2.35s\n",
      "261:\tlearn: 1.8048921\ttotal: 833ms\tremaining: 2.35s\n",
      "262:\tlearn: 1.7943605\ttotal: 836ms\tremaining: 2.34s\n",
      "263:\tlearn: 1.7868145\ttotal: 837ms\tremaining: 2.33s\n",
      "264:\tlearn: 1.7800177\ttotal: 839ms\tremaining: 2.33s\n",
      "265:\tlearn: 1.7768548\ttotal: 841ms\tremaining: 2.32s\n",
      "266:\tlearn: 1.7659756\ttotal: 845ms\tremaining: 2.32s\n",
      "267:\tlearn: 1.7556970\ttotal: 848ms\tremaining: 2.32s\n",
      "268:\tlearn: 1.7471592\ttotal: 851ms\tremaining: 2.31s\n",
      "269:\tlearn: 1.7417530\ttotal: 852ms\tremaining: 2.3s\n",
      "270:\tlearn: 1.7314880\ttotal: 854ms\tremaining: 2.3s\n",
      "271:\tlearn: 1.7169886\ttotal: 856ms\tremaining: 2.29s\n",
      "272:\tlearn: 1.7037486\ttotal: 858ms\tremaining: 2.29s\n",
      "273:\tlearn: 1.6904874\ttotal: 862ms\tremaining: 2.28s\n",
      "274:\tlearn: 1.6727843\ttotal: 865ms\tremaining: 2.28s\n",
      "275:\tlearn: 1.6624972\ttotal: 868ms\tremaining: 2.27s\n",
      "276:\tlearn: 1.6509636\ttotal: 869ms\tremaining: 2.27s\n",
      "277:\tlearn: 1.6482349\ttotal: 873ms\tremaining: 2.27s\n",
      "278:\tlearn: 1.6407121\ttotal: 876ms\tremaining: 2.26s\n",
      "279:\tlearn: 1.6345483\ttotal: 878ms\tremaining: 2.26s\n",
      "280:\tlearn: 1.6244130\ttotal: 880ms\tremaining: 2.25s\n",
      "281:\tlearn: 1.6132529\ttotal: 882ms\tremaining: 2.24s\n",
      "282:\tlearn: 1.6042281\ttotal: 883ms\tremaining: 2.24s\n",
      "283:\tlearn: 1.6010101\ttotal: 885ms\tremaining: 2.23s\n",
      "284:\tlearn: 1.5896348\ttotal: 888ms\tremaining: 2.23s\n",
      "285:\tlearn: 1.5782896\ttotal: 890ms\tremaining: 2.22s\n",
      "286:\tlearn: 1.5660083\ttotal: 891ms\tremaining: 2.21s\n",
      "287:\tlearn: 1.5550024\ttotal: 893ms\tremaining: 2.21s\n",
      "288:\tlearn: 1.5496021\ttotal: 895ms\tremaining: 2.2s\n",
      "289:\tlearn: 1.5401098\ttotal: 897ms\tremaining: 2.19s\n",
      "290:\tlearn: 1.5290715\ttotal: 899ms\tremaining: 2.19s\n",
      "291:\tlearn: 1.5144442\ttotal: 900ms\tremaining: 2.18s\n",
      "292:\tlearn: 1.5046430\ttotal: 902ms\tremaining: 2.18s\n",
      "293:\tlearn: 1.4949781\ttotal: 904ms\tremaining: 2.17s\n",
      "294:\tlearn: 1.4852648\ttotal: 906ms\tremaining: 2.16s\n",
      "295:\tlearn: 1.4741251\ttotal: 908ms\tremaining: 2.16s\n",
      "296:\tlearn: 1.4662160\ttotal: 909ms\tremaining: 2.15s\n",
      "297:\tlearn: 1.4554269\ttotal: 911ms\tremaining: 2.15s\n",
      "298:\tlearn: 1.4496715\ttotal: 913ms\tremaining: 2.14s\n",
      "299:\tlearn: 1.4473952\ttotal: 915ms\tremaining: 2.13s\n",
      "300:\tlearn: 1.4356702\ttotal: 916ms\tremaining: 2.13s\n",
      "301:\tlearn: 1.4305354\ttotal: 918ms\tremaining: 2.12s\n",
      "302:\tlearn: 1.4232658\ttotal: 920ms\tremaining: 2.12s\n",
      "303:\tlearn: 1.4163876\ttotal: 922ms\tremaining: 2.11s\n",
      "304:\tlearn: 1.4085987\ttotal: 925ms\tremaining: 2.11s\n",
      "305:\tlearn: 1.4000800\ttotal: 927ms\tremaining: 2.1s\n",
      "306:\tlearn: 1.3949514\ttotal: 930ms\tremaining: 2.1s\n",
      "307:\tlearn: 1.3847051\ttotal: 931ms\tremaining: 2.09s\n",
      "308:\tlearn: 1.3773463\ttotal: 933ms\tremaining: 2.09s\n",
      "309:\tlearn: 1.3669941\ttotal: 935ms\tremaining: 2.08s\n",
      "310:\tlearn: 1.3624500\ttotal: 937ms\tremaining: 2.08s\n",
      "311:\tlearn: 1.3534325\ttotal: 939ms\tremaining: 2.07s\n",
      "312:\tlearn: 1.3463252\ttotal: 941ms\tremaining: 2.06s\n",
      "313:\tlearn: 1.3428946\ttotal: 943ms\tremaining: 2.06s\n",
      "314:\tlearn: 1.3325242\ttotal: 944ms\tremaining: 2.05s\n",
      "315:\tlearn: 1.3230872\ttotal: 946ms\tremaining: 2.05s\n",
      "316:\tlearn: 1.3124277\ttotal: 948ms\tremaining: 2.04s\n",
      "317:\tlearn: 1.3025122\ttotal: 950ms\tremaining: 2.04s\n",
      "318:\tlearn: 1.2966050\ttotal: 952ms\tremaining: 2.03s\n",
      "319:\tlearn: 1.2883231\ttotal: 955ms\tremaining: 2.03s\n",
      "320:\tlearn: 1.2814779\ttotal: 957ms\tremaining: 2.02s\n",
      "321:\tlearn: 1.2764094\ttotal: 959ms\tremaining: 2.02s\n",
      "322:\tlearn: 1.2690052\ttotal: 962ms\tremaining: 2.02s\n",
      "323:\tlearn: 1.2654491\ttotal: 964ms\tremaining: 2.01s\n",
      "324:\tlearn: 1.2581385\ttotal: 967ms\tremaining: 2.01s\n",
      "325:\tlearn: 1.2515866\ttotal: 970ms\tremaining: 2s\n",
      "326:\tlearn: 1.2443197\ttotal: 972ms\tremaining: 2s\n",
      "327:\tlearn: 1.2416099\ttotal: 974ms\tremaining: 1.99s\n",
      "328:\tlearn: 1.2332475\ttotal: 975ms\tremaining: 1.99s\n",
      "329:\tlearn: 1.2278880\ttotal: 977ms\tremaining: 1.98s\n",
      "330:\tlearn: 1.2200701\ttotal: 980ms\tremaining: 1.98s\n",
      "331:\tlearn: 1.2126776\ttotal: 983ms\tremaining: 1.98s\n",
      "332:\tlearn: 1.2053445\ttotal: 985ms\tremaining: 1.97s\n",
      "333:\tlearn: 1.1985400\ttotal: 988ms\tremaining: 1.97s\n",
      "334:\tlearn: 1.1896862\ttotal: 990ms\tremaining: 1.96s\n",
      "335:\tlearn: 1.1864628\ttotal: 992ms\tremaining: 1.96s\n",
      "336:\tlearn: 1.1782912\ttotal: 994ms\tremaining: 1.95s\n",
      "337:\tlearn: 1.1738474\ttotal: 996ms\tremaining: 1.95s\n",
      "338:\tlearn: 1.1699836\ttotal: 998ms\tremaining: 1.95s\n",
      "339:\tlearn: 1.1659238\ttotal: 999ms\tremaining: 1.94s\n",
      "340:\tlearn: 1.1581736\ttotal: 1s\tremaining: 1.93s\n",
      "341:\tlearn: 1.1530581\ttotal: 1s\tremaining: 1.93s\n",
      "342:\tlearn: 1.1447820\ttotal: 1s\tremaining: 1.92s\n",
      "343:\tlearn: 1.1417798\ttotal: 1.01s\tremaining: 1.92s\n",
      "344:\tlearn: 1.1363871\ttotal: 1.01s\tremaining: 1.91s\n",
      "345:\tlearn: 1.1334390\ttotal: 1.01s\tremaining: 1.91s\n",
      "346:\tlearn: 1.1311211\ttotal: 1.01s\tremaining: 1.91s\n",
      "347:\tlearn: 1.1265338\ttotal: 1.01s\tremaining: 1.9s\n",
      "348:\tlearn: 1.1204322\ttotal: 1.02s\tremaining: 1.9s\n",
      "349:\tlearn: 1.1123647\ttotal: 1.02s\tremaining: 1.89s\n",
      "350:\tlearn: 1.1059139\ttotal: 1.02s\tremaining: 1.89s\n",
      "351:\tlearn: 1.0971618\ttotal: 1.02s\tremaining: 1.88s\n",
      "352:\tlearn: 1.0903806\ttotal: 1.02s\tremaining: 1.88s\n",
      "353:\tlearn: 1.0888512\ttotal: 1.02s\tremaining: 1.87s\n",
      "354:\tlearn: 1.0851308\ttotal: 1.03s\tremaining: 1.86s\n",
      "355:\tlearn: 1.0820320\ttotal: 1.03s\tremaining: 1.86s\n",
      "356:\tlearn: 1.0763247\ttotal: 1.03s\tremaining: 1.86s\n",
      "357:\tlearn: 1.0749356\ttotal: 1.03s\tremaining: 1.85s\n",
      "358:\tlearn: 1.0670624\ttotal: 1.03s\tremaining: 1.85s\n",
      "359:\tlearn: 1.0599240\ttotal: 1.04s\tremaining: 1.84s\n",
      "360:\tlearn: 1.0582881\ttotal: 1.04s\tremaining: 1.84s\n",
      "361:\tlearn: 1.0508340\ttotal: 1.04s\tremaining: 1.83s\n",
      "362:\tlearn: 1.0456899\ttotal: 1.04s\tremaining: 1.83s\n",
      "363:\tlearn: 1.0422349\ttotal: 1.04s\tremaining: 1.82s\n",
      "364:\tlearn: 1.0360015\ttotal: 1.05s\tremaining: 1.82s\n",
      "365:\tlearn: 1.0348440\ttotal: 1.05s\tremaining: 1.81s\n",
      "366:\tlearn: 1.0293325\ttotal: 1.05s\tremaining: 1.81s\n",
      "367:\tlearn: 1.0234144\ttotal: 1.05s\tremaining: 1.8s\n",
      "368:\tlearn: 1.0167337\ttotal: 1.05s\tremaining: 1.8s\n",
      "369:\tlearn: 1.0094203\ttotal: 1.05s\tremaining: 1.79s\n",
      "370:\tlearn: 1.0032503\ttotal: 1.05s\tremaining: 1.79s\n",
      "371:\tlearn: 0.9969310\ttotal: 1.06s\tremaining: 1.78s\n",
      "372:\tlearn: 0.9886860\ttotal: 1.06s\tremaining: 1.78s\n",
      "373:\tlearn: 0.9832907\ttotal: 1.06s\tremaining: 1.77s\n",
      "374:\tlearn: 0.9766825\ttotal: 1.06s\tremaining: 1.77s\n",
      "375:\tlearn: 0.9702588\ttotal: 1.06s\tremaining: 1.76s\n",
      "376:\tlearn: 0.9642642\ttotal: 1.06s\tremaining: 1.76s\n",
      "377:\tlearn: 0.9583964\ttotal: 1.07s\tremaining: 1.75s\n",
      "378:\tlearn: 0.9572287\ttotal: 1.07s\tremaining: 1.75s\n",
      "379:\tlearn: 0.9550674\ttotal: 1.07s\tremaining: 1.75s\n",
      "380:\tlearn: 0.9534251\ttotal: 1.07s\tremaining: 1.74s\n",
      "381:\tlearn: 0.9517017\ttotal: 1.07s\tremaining: 1.74s\n",
      "382:\tlearn: 0.9469622\ttotal: 1.07s\tremaining: 1.73s\n",
      "383:\tlearn: 0.9406297\ttotal: 1.08s\tremaining: 1.73s\n",
      "384:\tlearn: 0.9386698\ttotal: 1.08s\tremaining: 1.72s\n",
      "385:\tlearn: 0.9332305\ttotal: 1.08s\tremaining: 1.72s\n",
      "386:\tlearn: 0.9288478\ttotal: 1.08s\tremaining: 1.71s\n",
      "387:\tlearn: 0.9209124\ttotal: 1.08s\tremaining: 1.71s\n",
      "388:\tlearn: 0.9151796\ttotal: 1.08s\tremaining: 1.7s\n",
      "389:\tlearn: 0.9090068\ttotal: 1.08s\tremaining: 1.7s\n",
      "390:\tlearn: 0.9054948\ttotal: 1.09s\tremaining: 1.69s\n",
      "391:\tlearn: 0.8986832\ttotal: 1.09s\tremaining: 1.69s\n",
      "392:\tlearn: 0.8955925\ttotal: 1.09s\tremaining: 1.69s\n",
      "393:\tlearn: 0.8893309\ttotal: 1.09s\tremaining: 1.68s\n",
      "394:\tlearn: 0.8831214\ttotal: 1.09s\tremaining: 1.68s\n",
      "395:\tlearn: 0.8823758\ttotal: 1.09s\tremaining: 1.67s\n",
      "396:\tlearn: 0.8786904\ttotal: 1.1s\tremaining: 1.67s\n",
      "397:\tlearn: 0.8776632\ttotal: 1.1s\tremaining: 1.66s\n",
      "398:\tlearn: 0.8743115\ttotal: 1.1s\tremaining: 1.66s\n",
      "399:\tlearn: 0.8690410\ttotal: 1.1s\tremaining: 1.65s\n",
      "400:\tlearn: 0.8627013\ttotal: 1.1s\tremaining: 1.65s\n",
      "401:\tlearn: 0.8617599\ttotal: 1.1s\tremaining: 1.64s\n",
      "402:\tlearn: 0.8555622\ttotal: 1.11s\tremaining: 1.64s\n",
      "403:\tlearn: 0.8492286\ttotal: 1.11s\tremaining: 1.64s\n",
      "404:\tlearn: 0.8436552\ttotal: 1.11s\tremaining: 1.63s\n",
      "405:\tlearn: 0.8378709\ttotal: 1.11s\tremaining: 1.63s\n",
      "406:\tlearn: 0.8318388\ttotal: 1.11s\tremaining: 1.62s\n",
      "407:\tlearn: 0.8252308\ttotal: 1.13s\tremaining: 1.64s\n",
      "408:\tlearn: 0.8204327\ttotal: 1.13s\tremaining: 1.64s\n",
      "409:\tlearn: 0.8167061\ttotal: 1.14s\tremaining: 1.63s\n",
      "410:\tlearn: 0.8129112\ttotal: 1.14s\tremaining: 1.63s\n",
      "411:\tlearn: 0.8086638\ttotal: 1.14s\tremaining: 1.63s\n",
      "412:\tlearn: 0.8024722\ttotal: 1.14s\tremaining: 1.62s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413:\tlearn: 0.7973058\ttotal: 1.15s\tremaining: 1.62s\n",
      "414:\tlearn: 0.7929099\ttotal: 1.15s\tremaining: 1.62s\n",
      "415:\tlearn: 0.7891504\ttotal: 1.15s\tremaining: 1.62s\n",
      "416:\tlearn: 0.7826943\ttotal: 1.15s\tremaining: 1.61s\n",
      "417:\tlearn: 0.7817592\ttotal: 1.16s\tremaining: 1.61s\n",
      "418:\tlearn: 0.7793910\ttotal: 1.16s\tremaining: 1.61s\n",
      "419:\tlearn: 0.7744081\ttotal: 1.16s\tremaining: 1.6s\n",
      "420:\tlearn: 0.7702356\ttotal: 1.16s\tremaining: 1.6s\n",
      "421:\tlearn: 0.7674810\ttotal: 1.16s\tremaining: 1.59s\n",
      "422:\tlearn: 0.7666695\ttotal: 1.17s\tremaining: 1.59s\n",
      "423:\tlearn: 0.7630044\ttotal: 1.17s\tremaining: 1.59s\n",
      "424:\tlearn: 0.7590595\ttotal: 1.17s\tremaining: 1.59s\n",
      "425:\tlearn: 0.7542739\ttotal: 1.18s\tremaining: 1.59s\n",
      "426:\tlearn: 0.7486428\ttotal: 1.18s\tremaining: 1.58s\n",
      "427:\tlearn: 0.7475665\ttotal: 1.18s\tremaining: 1.58s\n",
      "428:\tlearn: 0.7435048\ttotal: 1.19s\tremaining: 1.58s\n",
      "429:\tlearn: 0.7378308\ttotal: 1.19s\tremaining: 1.57s\n",
      "430:\tlearn: 0.7372625\ttotal: 1.19s\tremaining: 1.57s\n",
      "431:\tlearn: 0.7328815\ttotal: 1.19s\tremaining: 1.57s\n",
      "432:\tlearn: 0.7292744\ttotal: 1.19s\tremaining: 1.56s\n",
      "433:\tlearn: 0.7276576\ttotal: 1.2s\tremaining: 1.56s\n",
      "434:\tlearn: 0.7268634\ttotal: 1.2s\tremaining: 1.55s\n",
      "435:\tlearn: 0.7223773\ttotal: 1.2s\tremaining: 1.55s\n",
      "436:\tlearn: 0.7215458\ttotal: 1.2s\tremaining: 1.55s\n",
      "437:\tlearn: 0.7207909\ttotal: 1.2s\tremaining: 1.54s\n",
      "438:\tlearn: 0.7148143\ttotal: 1.21s\tremaining: 1.54s\n",
      "439:\tlearn: 0.7124760\ttotal: 1.21s\tremaining: 1.54s\n",
      "440:\tlearn: 0.7118383\ttotal: 1.21s\tremaining: 1.53s\n",
      "441:\tlearn: 0.7096127\ttotal: 1.21s\tremaining: 1.53s\n",
      "442:\tlearn: 0.7043376\ttotal: 1.21s\tremaining: 1.52s\n",
      "443:\tlearn: 0.6999235\ttotal: 1.22s\tremaining: 1.52s\n",
      "444:\tlearn: 0.6992122\ttotal: 1.22s\tremaining: 1.52s\n",
      "445:\tlearn: 0.6940501\ttotal: 1.22s\tremaining: 1.51s\n",
      "446:\tlearn: 0.6889042\ttotal: 1.22s\tremaining: 1.51s\n",
      "447:\tlearn: 0.6841993\ttotal: 1.23s\tremaining: 1.51s\n",
      "448:\tlearn: 0.6790112\ttotal: 1.23s\tremaining: 1.51s\n",
      "449:\tlearn: 0.6783708\ttotal: 1.23s\tremaining: 1.5s\n",
      "450:\tlearn: 0.6776791\ttotal: 1.23s\tremaining: 1.5s\n",
      "451:\tlearn: 0.6758842\ttotal: 1.23s\tremaining: 1.49s\n",
      "452:\tlearn: 0.6709090\ttotal: 1.24s\tremaining: 1.49s\n",
      "453:\tlearn: 0.6679259\ttotal: 1.24s\tremaining: 1.49s\n",
      "454:\tlearn: 0.6657079\ttotal: 1.24s\tremaining: 1.49s\n",
      "455:\tlearn: 0.6629314\ttotal: 1.24s\tremaining: 1.48s\n",
      "456:\tlearn: 0.6622829\ttotal: 1.24s\tremaining: 1.48s\n",
      "457:\tlearn: 0.6590150\ttotal: 1.25s\tremaining: 1.47s\n",
      "458:\tlearn: 0.6583606\ttotal: 1.25s\tremaining: 1.47s\n",
      "459:\tlearn: 0.6542972\ttotal: 1.25s\tremaining: 1.47s\n",
      "460:\tlearn: 0.6526872\ttotal: 1.25s\tremaining: 1.47s\n",
      "461:\tlearn: 0.6494497\ttotal: 1.26s\tremaining: 1.46s\n",
      "462:\tlearn: 0.6482383\ttotal: 1.26s\tremaining: 1.46s\n",
      "463:\tlearn: 0.6436265\ttotal: 1.26s\tremaining: 1.46s\n",
      "464:\tlearn: 0.6406297\ttotal: 1.26s\tremaining: 1.45s\n",
      "465:\tlearn: 0.6382332\ttotal: 1.26s\tremaining: 1.45s\n",
      "466:\tlearn: 0.6372733\ttotal: 1.27s\tremaining: 1.45s\n",
      "467:\tlearn: 0.6364355\ttotal: 1.27s\tremaining: 1.44s\n",
      "468:\tlearn: 0.6323808\ttotal: 1.27s\tremaining: 1.44s\n",
      "469:\tlearn: 0.6295211\ttotal: 1.27s\tremaining: 1.44s\n",
      "470:\tlearn: 0.6252218\ttotal: 1.28s\tremaining: 1.43s\n",
      "471:\tlearn: 0.6205164\ttotal: 1.28s\tremaining: 1.43s\n",
      "472:\tlearn: 0.6199632\ttotal: 1.28s\tremaining: 1.43s\n",
      "473:\tlearn: 0.6149387\ttotal: 1.28s\tremaining: 1.42s\n",
      "474:\tlearn: 0.6143659\ttotal: 1.29s\tremaining: 1.42s\n",
      "475:\tlearn: 0.6107737\ttotal: 1.29s\tremaining: 1.42s\n",
      "476:\tlearn: 0.6055981\ttotal: 1.29s\tremaining: 1.41s\n",
      "477:\tlearn: 0.6015804\ttotal: 1.29s\tremaining: 1.41s\n",
      "478:\tlearn: 0.5984959\ttotal: 1.29s\tremaining: 1.41s\n",
      "479:\tlearn: 0.5933694\ttotal: 1.3s\tremaining: 1.4s\n",
      "480:\tlearn: 0.5916009\ttotal: 1.3s\tremaining: 1.4s\n",
      "481:\tlearn: 0.5888388\ttotal: 1.3s\tremaining: 1.4s\n",
      "482:\tlearn: 0.5844423\ttotal: 1.31s\tremaining: 1.4s\n",
      "483:\tlearn: 0.5822628\ttotal: 1.32s\tremaining: 1.41s\n",
      "484:\tlearn: 0.5778358\ttotal: 1.33s\tremaining: 1.42s\n",
      "485:\tlearn: 0.5774275\ttotal: 1.34s\tremaining: 1.41s\n",
      "486:\tlearn: 0.5750824\ttotal: 1.34s\tremaining: 1.41s\n",
      "487:\tlearn: 0.5729710\ttotal: 1.34s\tremaining: 1.41s\n",
      "488:\tlearn: 0.5689618\ttotal: 1.35s\tremaining: 1.41s\n",
      "489:\tlearn: 0.5680552\ttotal: 1.35s\tremaining: 1.41s\n",
      "490:\tlearn: 0.5654905\ttotal: 1.35s\tremaining: 1.4s\n",
      "491:\tlearn: 0.5625997\ttotal: 1.35s\tremaining: 1.4s\n",
      "492:\tlearn: 0.5609098\ttotal: 1.36s\tremaining: 1.4s\n",
      "493:\tlearn: 0.5572358\ttotal: 1.36s\tremaining: 1.39s\n",
      "494:\tlearn: 0.5538958\ttotal: 1.36s\tremaining: 1.39s\n",
      "495:\tlearn: 0.5499180\ttotal: 1.37s\tremaining: 1.39s\n",
      "496:\tlearn: 0.5459179\ttotal: 1.37s\tremaining: 1.39s\n",
      "497:\tlearn: 0.5430017\ttotal: 1.38s\tremaining: 1.39s\n",
      "498:\tlearn: 0.5386001\ttotal: 1.38s\tremaining: 1.39s\n",
      "499:\tlearn: 0.5367964\ttotal: 1.39s\tremaining: 1.39s\n",
      "500:\tlearn: 0.5362440\ttotal: 1.4s\tremaining: 1.39s\n",
      "501:\tlearn: 0.5342335\ttotal: 1.4s\tremaining: 1.39s\n",
      "502:\tlearn: 0.5322439\ttotal: 1.4s\tremaining: 1.39s\n",
      "503:\tlearn: 0.5304350\ttotal: 1.41s\tremaining: 1.38s\n",
      "504:\tlearn: 0.5298665\ttotal: 1.41s\tremaining: 1.38s\n",
      "505:\tlearn: 0.5285299\ttotal: 1.41s\tremaining: 1.38s\n",
      "506:\tlearn: 0.5258838\ttotal: 1.41s\tremaining: 1.38s\n",
      "507:\tlearn: 0.5234076\ttotal: 1.42s\tremaining: 1.37s\n",
      "508:\tlearn: 0.5230227\ttotal: 1.42s\tremaining: 1.37s\n",
      "509:\tlearn: 0.5225119\ttotal: 1.42s\tremaining: 1.36s\n",
      "510:\tlearn: 0.5203206\ttotal: 1.42s\tremaining: 1.36s\n",
      "511:\tlearn: 0.5172945\ttotal: 1.42s\tremaining: 1.36s\n",
      "512:\tlearn: 0.5149452\ttotal: 1.42s\tremaining: 1.35s\n",
      "513:\tlearn: 0.5116950\ttotal: 1.43s\tremaining: 1.35s\n",
      "514:\tlearn: 0.5112314\ttotal: 1.43s\tremaining: 1.34s\n",
      "515:\tlearn: 0.5089249\ttotal: 1.43s\tremaining: 1.34s\n",
      "516:\tlearn: 0.5052687\ttotal: 1.43s\tremaining: 1.34s\n",
      "517:\tlearn: 0.5032408\ttotal: 1.43s\tremaining: 1.33s\n",
      "518:\tlearn: 0.5008885\ttotal: 1.43s\tremaining: 1.33s\n",
      "519:\tlearn: 0.4973183\ttotal: 1.44s\tremaining: 1.32s\n",
      "520:\tlearn: 0.4939690\ttotal: 1.44s\tremaining: 1.32s\n",
      "521:\tlearn: 0.4935623\ttotal: 1.44s\tremaining: 1.32s\n",
      "522:\tlearn: 0.4931059\ttotal: 1.44s\tremaining: 1.31s\n",
      "523:\tlearn: 0.4909979\ttotal: 1.44s\tremaining: 1.31s\n",
      "524:\tlearn: 0.4906236\ttotal: 1.44s\tremaining: 1.31s\n",
      "525:\tlearn: 0.4875035\ttotal: 1.45s\tremaining: 1.3s\n",
      "526:\tlearn: 0.4868422\ttotal: 1.45s\tremaining: 1.3s\n",
      "527:\tlearn: 0.4864326\ttotal: 1.45s\tremaining: 1.29s\n",
      "528:\tlearn: 0.4825010\ttotal: 1.45s\tremaining: 1.29s\n",
      "529:\tlearn: 0.4808076\ttotal: 1.45s\tremaining: 1.29s\n",
      "530:\tlearn: 0.4792846\ttotal: 1.45s\tremaining: 1.28s\n",
      "531:\tlearn: 0.4765558\ttotal: 1.46s\tremaining: 1.28s\n",
      "532:\tlearn: 0.4743168\ttotal: 1.46s\tremaining: 1.28s\n",
      "533:\tlearn: 0.4707056\ttotal: 1.46s\tremaining: 1.27s\n",
      "534:\tlearn: 0.4672950\ttotal: 1.46s\tremaining: 1.27s\n",
      "535:\tlearn: 0.4663702\ttotal: 1.46s\tremaining: 1.26s\n",
      "536:\tlearn: 0.4636760\ttotal: 1.46s\tremaining: 1.26s\n",
      "537:\tlearn: 0.4626646\ttotal: 1.47s\tremaining: 1.26s\n",
      "538:\tlearn: 0.4598481\ttotal: 1.47s\tremaining: 1.25s\n",
      "539:\tlearn: 0.4580852\ttotal: 1.47s\tremaining: 1.25s\n",
      "540:\tlearn: 0.4565826\ttotal: 1.47s\tremaining: 1.25s\n",
      "541:\tlearn: 0.4531420\ttotal: 1.47s\tremaining: 1.24s\n",
      "542:\tlearn: 0.4495529\ttotal: 1.47s\tremaining: 1.24s\n",
      "543:\tlearn: 0.4462697\ttotal: 1.48s\tremaining: 1.24s\n",
      "544:\tlearn: 0.4451252\ttotal: 1.48s\tremaining: 1.24s\n",
      "545:\tlearn: 0.4431467\ttotal: 1.48s\tremaining: 1.23s\n",
      "546:\tlearn: 0.4411985\ttotal: 1.48s\tremaining: 1.23s\n",
      "547:\tlearn: 0.4407813\ttotal: 1.49s\tremaining: 1.23s\n",
      "548:\tlearn: 0.4372961\ttotal: 1.49s\tremaining: 1.22s\n",
      "549:\tlearn: 0.4349262\ttotal: 1.49s\tremaining: 1.22s\n",
      "550:\tlearn: 0.4327376\ttotal: 1.49s\tremaining: 1.22s\n",
      "551:\tlearn: 0.4302171\ttotal: 1.49s\tremaining: 1.21s\n",
      "552:\tlearn: 0.4290628\ttotal: 1.5s\tremaining: 1.21s\n",
      "553:\tlearn: 0.4277525\ttotal: 1.5s\tremaining: 1.21s\n",
      "554:\tlearn: 0.4256738\ttotal: 1.5s\tremaining: 1.2s\n",
      "555:\tlearn: 0.4226999\ttotal: 1.5s\tremaining: 1.2s\n",
      "556:\tlearn: 0.4223323\ttotal: 1.5s\tremaining: 1.19s\n",
      "557:\tlearn: 0.4202611\ttotal: 1.5s\tremaining: 1.19s\n",
      "558:\tlearn: 0.4179274\ttotal: 1.5s\tremaining: 1.19s\n",
      "559:\tlearn: 0.4154221\ttotal: 1.51s\tremaining: 1.18s\n",
      "560:\tlearn: 0.4136829\ttotal: 1.51s\tremaining: 1.18s\n",
      "561:\tlearn: 0.4118104\ttotal: 1.51s\tremaining: 1.18s\n",
      "562:\tlearn: 0.4084644\ttotal: 1.51s\tremaining: 1.17s\n",
      "563:\tlearn: 0.4062960\ttotal: 1.51s\tremaining: 1.17s\n",
      "564:\tlearn: 0.4045002\ttotal: 1.51s\tremaining: 1.17s\n",
      "565:\tlearn: 0.4042574\ttotal: 1.52s\tremaining: 1.16s\n",
      "566:\tlearn: 0.4027811\ttotal: 1.52s\tremaining: 1.16s\n",
      "567:\tlearn: 0.4000692\ttotal: 1.52s\tremaining: 1.16s\n",
      "568:\tlearn: 0.3991611\ttotal: 1.52s\tremaining: 1.15s\n",
      "569:\tlearn: 0.3972253\ttotal: 1.52s\tremaining: 1.15s\n",
      "570:\tlearn: 0.3951131\ttotal: 1.52s\tremaining: 1.15s\n",
      "571:\tlearn: 0.3928754\ttotal: 1.53s\tremaining: 1.14s\n",
      "572:\tlearn: 0.3897628\ttotal: 1.53s\tremaining: 1.14s\n",
      "573:\tlearn: 0.3894225\ttotal: 1.53s\tremaining: 1.14s\n",
      "574:\tlearn: 0.3866341\ttotal: 1.53s\tremaining: 1.13s\n",
      "575:\tlearn: 0.3860354\ttotal: 1.53s\tremaining: 1.13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576:\tlearn: 0.3845370\ttotal: 1.53s\tremaining: 1.13s\n",
      "577:\tlearn: 0.3824518\ttotal: 1.54s\tremaining: 1.12s\n",
      "578:\tlearn: 0.3814254\ttotal: 1.54s\tremaining: 1.12s\n",
      "579:\tlearn: 0.3788225\ttotal: 1.54s\tremaining: 1.12s\n",
      "580:\tlearn: 0.3762958\ttotal: 1.54s\tremaining: 1.11s\n",
      "581:\tlearn: 0.3747912\ttotal: 1.54s\tremaining: 1.11s\n",
      "582:\tlearn: 0.3732891\ttotal: 1.55s\tremaining: 1.11s\n",
      "583:\tlearn: 0.3704381\ttotal: 1.55s\tremaining: 1.1s\n",
      "584:\tlearn: 0.3679932\ttotal: 1.55s\tremaining: 1.1s\n",
      "585:\tlearn: 0.3667872\ttotal: 1.55s\tremaining: 1.1s\n",
      "586:\tlearn: 0.3643906\ttotal: 1.55s\tremaining: 1.09s\n",
      "587:\tlearn: 0.3625502\ttotal: 1.56s\tremaining: 1.09s\n",
      "588:\tlearn: 0.3596266\ttotal: 1.56s\tremaining: 1.09s\n",
      "589:\tlearn: 0.3582693\ttotal: 1.56s\tremaining: 1.08s\n",
      "590:\tlearn: 0.3556570\ttotal: 1.56s\tremaining: 1.08s\n",
      "591:\tlearn: 0.3539051\ttotal: 1.56s\tremaining: 1.08s\n",
      "592:\tlearn: 0.3532115\ttotal: 1.56s\tremaining: 1.07s\n",
      "593:\tlearn: 0.3523506\ttotal: 1.57s\tremaining: 1.07s\n",
      "594:\tlearn: 0.3500942\ttotal: 1.57s\tremaining: 1.07s\n",
      "595:\tlearn: 0.3490821\ttotal: 1.57s\tremaining: 1.06s\n",
      "596:\tlearn: 0.3471659\ttotal: 1.57s\tremaining: 1.06s\n",
      "597:\tlearn: 0.3462769\ttotal: 1.57s\tremaining: 1.06s\n",
      "598:\tlearn: 0.3435353\ttotal: 1.58s\tremaining: 1.05s\n",
      "599:\tlearn: 0.3411584\ttotal: 1.58s\tremaining: 1.05s\n",
      "600:\tlearn: 0.3405489\ttotal: 1.58s\tremaining: 1.05s\n",
      "601:\tlearn: 0.3384069\ttotal: 1.58s\tremaining: 1.04s\n",
      "602:\tlearn: 0.3363746\ttotal: 1.58s\tremaining: 1.04s\n",
      "603:\tlearn: 0.3341833\ttotal: 1.58s\tremaining: 1.04s\n",
      "604:\tlearn: 0.3318144\ttotal: 1.59s\tremaining: 1.03s\n",
      "605:\tlearn: 0.3315764\ttotal: 1.59s\tremaining: 1.03s\n",
      "606:\tlearn: 0.3292393\ttotal: 1.59s\tremaining: 1.03s\n",
      "607:\tlearn: 0.3270066\ttotal: 1.59s\tremaining: 1.02s\n",
      "608:\tlearn: 0.3256892\ttotal: 1.59s\tremaining: 1.02s\n",
      "609:\tlearn: 0.3244532\ttotal: 1.59s\tremaining: 1.02s\n",
      "610:\tlearn: 0.3230231\ttotal: 1.6s\tremaining: 1.02s\n",
      "611:\tlearn: 0.3215755\ttotal: 1.6s\tremaining: 1.01s\n",
      "612:\tlearn: 0.3201751\ttotal: 1.6s\tremaining: 1.01s\n",
      "613:\tlearn: 0.3193799\ttotal: 1.6s\tremaining: 1.01s\n",
      "614:\tlearn: 0.3181271\ttotal: 1.6s\tremaining: 1s\n",
      "615:\tlearn: 0.3169424\ttotal: 1.61s\tremaining: 1s\n",
      "616:\tlearn: 0.3139826\ttotal: 1.61s\tremaining: 1s\n",
      "617:\tlearn: 0.3123129\ttotal: 1.61s\tremaining: 998ms\n",
      "618:\tlearn: 0.3114460\ttotal: 1.62s\tremaining: 995ms\n",
      "619:\tlearn: 0.3091796\ttotal: 1.62s\tremaining: 992ms\n",
      "620:\tlearn: 0.3087788\ttotal: 1.62s\tremaining: 989ms\n",
      "621:\tlearn: 0.3071682\ttotal: 1.62s\tremaining: 986ms\n",
      "622:\tlearn: 0.3050813\ttotal: 1.62s\tremaining: 983ms\n",
      "623:\tlearn: 0.3040146\ttotal: 1.63s\tremaining: 981ms\n",
      "624:\tlearn: 0.3017803\ttotal: 1.63s\tremaining: 978ms\n",
      "625:\tlearn: 0.3005506\ttotal: 1.63s\tremaining: 975ms\n",
      "626:\tlearn: 0.2987096\ttotal: 1.63s\tremaining: 972ms\n",
      "627:\tlearn: 0.2973207\ttotal: 1.64s\tremaining: 969ms\n",
      "628:\tlearn: 0.2950866\ttotal: 1.64s\tremaining: 966ms\n",
      "629:\tlearn: 0.2946006\ttotal: 1.64s\tremaining: 963ms\n",
      "630:\tlearn: 0.2927494\ttotal: 1.64s\tremaining: 960ms\n",
      "631:\tlearn: 0.2904417\ttotal: 1.64s\tremaining: 957ms\n",
      "632:\tlearn: 0.2889032\ttotal: 1.65s\tremaining: 954ms\n",
      "633:\tlearn: 0.2878176\ttotal: 1.65s\tremaining: 951ms\n",
      "634:\tlearn: 0.2865864\ttotal: 1.65s\tremaining: 948ms\n",
      "635:\tlearn: 0.2847542\ttotal: 1.65s\tremaining: 944ms\n",
      "636:\tlearn: 0.2827627\ttotal: 1.65s\tremaining: 941ms\n",
      "637:\tlearn: 0.2814734\ttotal: 1.65s\tremaining: 938ms\n",
      "638:\tlearn: 0.2794955\ttotal: 1.66s\tremaining: 940ms\n",
      "639:\tlearn: 0.2779112\ttotal: 1.67s\tremaining: 937ms\n",
      "640:\tlearn: 0.2765436\ttotal: 1.67s\tremaining: 934ms\n",
      "641:\tlearn: 0.2753272\ttotal: 1.67s\tremaining: 932ms\n",
      "642:\tlearn: 0.2735518\ttotal: 1.67s\tremaining: 928ms\n",
      "643:\tlearn: 0.2728954\ttotal: 1.67s\tremaining: 925ms\n",
      "644:\tlearn: 0.2714444\ttotal: 1.68s\tremaining: 922ms\n",
      "645:\tlearn: 0.2694636\ttotal: 1.68s\tremaining: 919ms\n",
      "646:\tlearn: 0.2678962\ttotal: 1.68s\tremaining: 916ms\n",
      "647:\tlearn: 0.2673713\ttotal: 1.68s\tremaining: 913ms\n",
      "648:\tlearn: 0.2658188\ttotal: 1.68s\tremaining: 910ms\n",
      "649:\tlearn: 0.2654307\ttotal: 1.68s\tremaining: 907ms\n",
      "650:\tlearn: 0.2632778\ttotal: 1.69s\tremaining: 904ms\n",
      "651:\tlearn: 0.2614896\ttotal: 1.69s\tremaining: 901ms\n",
      "652:\tlearn: 0.2598058\ttotal: 1.69s\tremaining: 899ms\n",
      "653:\tlearn: 0.2577395\ttotal: 1.69s\tremaining: 896ms\n",
      "654:\tlearn: 0.2557766\ttotal: 1.7s\tremaining: 893ms\n",
      "655:\tlearn: 0.2538683\ttotal: 1.7s\tremaining: 890ms\n",
      "656:\tlearn: 0.2522879\ttotal: 1.7s\tremaining: 887ms\n",
      "657:\tlearn: 0.2508801\ttotal: 1.7s\tremaining: 884ms\n",
      "658:\tlearn: 0.2499095\ttotal: 1.7s\tremaining: 881ms\n",
      "659:\tlearn: 0.2486078\ttotal: 1.7s\tremaining: 878ms\n",
      "660:\tlearn: 0.2475212\ttotal: 1.71s\tremaining: 875ms\n",
      "661:\tlearn: 0.2461037\ttotal: 1.71s\tremaining: 872ms\n",
      "662:\tlearn: 0.2441827\ttotal: 1.71s\tremaining: 869ms\n",
      "663:\tlearn: 0.2427219\ttotal: 1.71s\tremaining: 866ms\n",
      "664:\tlearn: 0.2412725\ttotal: 1.71s\tremaining: 863ms\n",
      "665:\tlearn: 0.2393727\ttotal: 1.71s\tremaining: 860ms\n",
      "666:\tlearn: 0.2386933\ttotal: 1.72s\tremaining: 857ms\n",
      "667:\tlearn: 0.2373265\ttotal: 1.72s\tremaining: 854ms\n",
      "668:\tlearn: 0.2364593\ttotal: 1.72s\tremaining: 851ms\n",
      "669:\tlearn: 0.2362654\ttotal: 1.72s\tremaining: 847ms\n",
      "670:\tlearn: 0.2346269\ttotal: 1.72s\tremaining: 844ms\n",
      "671:\tlearn: 0.2330795\ttotal: 1.72s\tremaining: 842ms\n",
      "672:\tlearn: 0.2318014\ttotal: 1.73s\tremaining: 839ms\n",
      "673:\tlearn: 0.2299574\ttotal: 1.73s\tremaining: 836ms\n",
      "674:\tlearn: 0.2292698\ttotal: 1.73s\tremaining: 833ms\n",
      "675:\tlearn: 0.2283422\ttotal: 1.73s\tremaining: 830ms\n",
      "676:\tlearn: 0.2269686\ttotal: 1.73s\tremaining: 827ms\n",
      "677:\tlearn: 0.2254542\ttotal: 1.74s\tremaining: 825ms\n",
      "678:\tlearn: 0.2243737\ttotal: 1.74s\tremaining: 822ms\n",
      "679:\tlearn: 0.2224002\ttotal: 1.74s\tremaining: 819ms\n",
      "680:\tlearn: 0.2221230\ttotal: 1.74s\tremaining: 816ms\n",
      "681:\tlearn: 0.2211220\ttotal: 1.75s\tremaining: 814ms\n",
      "682:\tlearn: 0.2208473\ttotal: 1.75s\tremaining: 812ms\n",
      "683:\tlearn: 0.2201000\ttotal: 1.75s\tremaining: 809ms\n",
      "684:\tlearn: 0.2189574\ttotal: 1.75s\tremaining: 806ms\n",
      "685:\tlearn: 0.2178815\ttotal: 1.75s\tremaining: 803ms\n",
      "686:\tlearn: 0.2169988\ttotal: 1.75s\tremaining: 800ms\n",
      "687:\tlearn: 0.2156578\ttotal: 1.76s\tremaining: 797ms\n",
      "688:\tlearn: 0.2142826\ttotal: 1.76s\tremaining: 794ms\n",
      "689:\tlearn: 0.2133522\ttotal: 1.76s\tremaining: 791ms\n",
      "690:\tlearn: 0.2125732\ttotal: 1.76s\tremaining: 788ms\n",
      "691:\tlearn: 0.2111612\ttotal: 1.76s\tremaining: 785ms\n",
      "692:\tlearn: 0.2103571\ttotal: 1.76s\tremaining: 782ms\n",
      "693:\tlearn: 0.2087247\ttotal: 1.77s\tremaining: 779ms\n",
      "694:\tlearn: 0.2082351\ttotal: 1.77s\tremaining: 777ms\n",
      "695:\tlearn: 0.2070496\ttotal: 1.77s\tremaining: 774ms\n",
      "696:\tlearn: 0.2056913\ttotal: 1.77s\tremaining: 771ms\n",
      "697:\tlearn: 0.2046794\ttotal: 1.77s\tremaining: 768ms\n",
      "698:\tlearn: 0.2027320\ttotal: 1.77s\tremaining: 765ms\n",
      "699:\tlearn: 0.2018242\ttotal: 1.78s\tremaining: 762ms\n",
      "700:\tlearn: 0.2010502\ttotal: 1.78s\tremaining: 759ms\n",
      "701:\tlearn: 0.1999103\ttotal: 1.78s\tremaining: 756ms\n",
      "702:\tlearn: 0.1990823\ttotal: 1.78s\tremaining: 753ms\n",
      "703:\tlearn: 0.1978621\ttotal: 1.78s\tremaining: 751ms\n",
      "704:\tlearn: 0.1974250\ttotal: 1.79s\tremaining: 748ms\n",
      "705:\tlearn: 0.1967780\ttotal: 1.79s\tremaining: 746ms\n",
      "706:\tlearn: 0.1955577\ttotal: 1.79s\tremaining: 744ms\n",
      "707:\tlearn: 0.1945608\ttotal: 1.8s\tremaining: 742ms\n",
      "708:\tlearn: 0.1933025\ttotal: 1.8s\tremaining: 740ms\n",
      "709:\tlearn: 0.1915923\ttotal: 1.81s\tremaining: 739ms\n",
      "710:\tlearn: 0.1906141\ttotal: 1.81s\tremaining: 738ms\n",
      "711:\tlearn: 0.1899248\ttotal: 1.82s\tremaining: 735ms\n",
      "712:\tlearn: 0.1887216\ttotal: 1.82s\tremaining: 733ms\n",
      "713:\tlearn: 0.1875991\ttotal: 1.82s\tremaining: 731ms\n",
      "714:\tlearn: 0.1863833\ttotal: 1.83s\tremaining: 729ms\n",
      "715:\tlearn: 0.1855046\ttotal: 1.83s\tremaining: 727ms\n",
      "716:\tlearn: 0.1853958\ttotal: 1.83s\tremaining: 724ms\n",
      "717:\tlearn: 0.1852411\ttotal: 1.84s\tremaining: 722ms\n",
      "718:\tlearn: 0.1840142\ttotal: 1.84s\tremaining: 720ms\n",
      "719:\tlearn: 0.1834550\ttotal: 1.84s\tremaining: 718ms\n",
      "720:\tlearn: 0.1823062\ttotal: 1.85s\tremaining: 716ms\n",
      "721:\tlearn: 0.1809262\ttotal: 1.87s\tremaining: 719ms\n",
      "722:\tlearn: 0.1801130\ttotal: 1.87s\tremaining: 717ms\n",
      "723:\tlearn: 0.1786276\ttotal: 1.88s\tremaining: 715ms\n",
      "724:\tlearn: 0.1783213\ttotal: 1.88s\tremaining: 714ms\n",
      "725:\tlearn: 0.1774135\ttotal: 1.89s\tremaining: 712ms\n",
      "726:\tlearn: 0.1772682\ttotal: 1.89s\tremaining: 710ms\n",
      "727:\tlearn: 0.1761239\ttotal: 1.89s\tremaining: 708ms\n",
      "728:\tlearn: 0.1751400\ttotal: 1.9s\tremaining: 705ms\n",
      "729:\tlearn: 0.1745101\ttotal: 1.9s\tremaining: 703ms\n",
      "730:\tlearn: 0.1738744\ttotal: 1.91s\tremaining: 701ms\n",
      "731:\tlearn: 0.1736130\ttotal: 1.91s\tremaining: 699ms\n",
      "732:\tlearn: 0.1732499\ttotal: 1.91s\tremaining: 697ms\n",
      "733:\tlearn: 0.1723906\ttotal: 1.92s\tremaining: 694ms\n",
      "734:\tlearn: 0.1722591\ttotal: 1.92s\tremaining: 693ms\n",
      "735:\tlearn: 0.1718791\ttotal: 1.93s\tremaining: 692ms\n",
      "736:\tlearn: 0.1710839\ttotal: 1.93s\tremaining: 690ms\n",
      "737:\tlearn: 0.1698085\ttotal: 1.94s\tremaining: 688ms\n",
      "738:\tlearn: 0.1689783\ttotal: 1.94s\tremaining: 686ms\n",
      "739:\tlearn: 0.1682564\ttotal: 1.94s\tremaining: 683ms\n",
      "740:\tlearn: 0.1670818\ttotal: 1.95s\tremaining: 681ms\n",
      "741:\tlearn: 0.1668622\ttotal: 1.95s\tremaining: 678ms\n",
      "742:\tlearn: 0.1655127\ttotal: 1.95s\tremaining: 676ms\n",
      "743:\tlearn: 0.1646401\ttotal: 1.96s\tremaining: 674ms\n",
      "744:\tlearn: 0.1639197\ttotal: 1.96s\tremaining: 671ms\n",
      "745:\tlearn: 0.1632848\ttotal: 1.96s\tremaining: 668ms\n",
      "746:\tlearn: 0.1627226\ttotal: 1.97s\tremaining: 666ms\n",
      "747:\tlearn: 0.1625212\ttotal: 1.97s\tremaining: 663ms\n",
      "748:\tlearn: 0.1618141\ttotal: 1.97s\tremaining: 661ms\n",
      "749:\tlearn: 0.1611557\ttotal: 1.98s\tremaining: 658ms\n",
      "750:\tlearn: 0.1601552\ttotal: 1.98s\tremaining: 656ms\n",
      "751:\tlearn: 0.1593272\ttotal: 1.98s\tremaining: 654ms\n",
      "752:\tlearn: 0.1586384\ttotal: 1.99s\tremaining: 651ms\n",
      "753:\tlearn: 0.1575974\ttotal: 1.99s\tremaining: 649ms\n",
      "754:\tlearn: 0.1569920\ttotal: 1.99s\tremaining: 646ms\n",
      "755:\tlearn: 0.1566130\ttotal: 1.99s\tremaining: 644ms\n",
      "756:\tlearn: 0.1561293\ttotal: 2s\tremaining: 641ms\n",
      "757:\tlearn: 0.1559144\ttotal: 2s\tremaining: 639ms\n",
      "758:\tlearn: 0.1548195\ttotal: 2s\tremaining: 636ms\n",
      "759:\tlearn: 0.1537482\ttotal: 2.01s\tremaining: 634ms\n",
      "760:\tlearn: 0.1529229\ttotal: 2.01s\tremaining: 631ms\n",
      "761:\tlearn: 0.1519165\ttotal: 2.01s\tremaining: 628ms\n",
      "762:\tlearn: 0.1510447\ttotal: 2.02s\tremaining: 626ms\n",
      "763:\tlearn: 0.1505387\ttotal: 2.02s\tremaining: 623ms\n",
      "764:\tlearn: 0.1496263\ttotal: 2.02s\tremaining: 621ms\n",
      "765:\tlearn: 0.1488561\ttotal: 2.02s\tremaining: 618ms\n",
      "766:\tlearn: 0.1487072\ttotal: 2.03s\tremaining: 616ms\n",
      "767:\tlearn: 0.1480300\ttotal: 2.03s\tremaining: 613ms\n",
      "768:\tlearn: 0.1469077\ttotal: 2.03s\tremaining: 610ms\n",
      "769:\tlearn: 0.1464375\ttotal: 2.03s\tremaining: 608ms\n",
      "770:\tlearn: 0.1462014\ttotal: 2.04s\tremaining: 605ms\n",
      "771:\tlearn: 0.1454457\ttotal: 2.04s\tremaining: 603ms\n",
      "772:\tlearn: 0.1453263\ttotal: 2.04s\tremaining: 600ms\n",
      "773:\tlearn: 0.1447653\ttotal: 2.04s\tremaining: 597ms\n",
      "774:\tlearn: 0.1441179\ttotal: 2.05s\tremaining: 595ms\n",
      "775:\tlearn: 0.1432460\ttotal: 2.05s\tremaining: 592ms\n",
      "776:\tlearn: 0.1424002\ttotal: 2.05s\tremaining: 589ms\n",
      "777:\tlearn: 0.1416071\ttotal: 2.06s\tremaining: 586ms\n",
      "778:\tlearn: 0.1414972\ttotal: 2.06s\tremaining: 584ms\n",
      "779:\tlearn: 0.1409877\ttotal: 2.06s\tremaining: 582ms\n",
      "780:\tlearn: 0.1408317\ttotal: 2.06s\tremaining: 579ms\n",
      "781:\tlearn: 0.1398569\ttotal: 2.07s\tremaining: 577ms\n",
      "782:\tlearn: 0.1389069\ttotal: 2.07s\tremaining: 574ms\n",
      "783:\tlearn: 0.1384359\ttotal: 2.08s\tremaining: 572ms\n",
      "784:\tlearn: 0.1377106\ttotal: 2.08s\tremaining: 569ms\n",
      "785:\tlearn: 0.1373049\ttotal: 2.08s\tremaining: 567ms\n",
      "786:\tlearn: 0.1366632\ttotal: 2.08s\tremaining: 565ms\n",
      "787:\tlearn: 0.1363811\ttotal: 2.09s\tremaining: 562ms\n",
      "788:\tlearn: 0.1361749\ttotal: 2.09s\tremaining: 560ms\n",
      "789:\tlearn: 0.1353872\ttotal: 2.1s\tremaining: 557ms\n",
      "790:\tlearn: 0.1347029\ttotal: 2.1s\tremaining: 555ms\n",
      "791:\tlearn: 0.1336300\ttotal: 2.1s\tremaining: 552ms\n",
      "792:\tlearn: 0.1328596\ttotal: 2.1s\tremaining: 549ms\n",
      "793:\tlearn: 0.1323608\ttotal: 2.11s\tremaining: 547ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794:\tlearn: 0.1317098\ttotal: 2.11s\tremaining: 545ms\n",
      "795:\tlearn: 0.1307868\ttotal: 2.12s\tremaining: 542ms\n",
      "796:\tlearn: 0.1303499\ttotal: 2.12s\tremaining: 540ms\n",
      "797:\tlearn: 0.1295368\ttotal: 2.12s\tremaining: 538ms\n",
      "798:\tlearn: 0.1289663\ttotal: 2.13s\tremaining: 536ms\n",
      "799:\tlearn: 0.1282640\ttotal: 2.13s\tremaining: 533ms\n",
      "800:\tlearn: 0.1273783\ttotal: 2.13s\tremaining: 531ms\n",
      "801:\tlearn: 0.1268507\ttotal: 2.14s\tremaining: 528ms\n",
      "802:\tlearn: 0.1267574\ttotal: 2.14s\tremaining: 526ms\n",
      "803:\tlearn: 0.1259603\ttotal: 2.15s\tremaining: 523ms\n",
      "804:\tlearn: 0.1252873\ttotal: 2.15s\tremaining: 520ms\n",
      "805:\tlearn: 0.1248227\ttotal: 2.15s\tremaining: 518ms\n",
      "806:\tlearn: 0.1245811\ttotal: 2.15s\tremaining: 515ms\n",
      "807:\tlearn: 0.1235396\ttotal: 2.16s\tremaining: 513ms\n",
      "808:\tlearn: 0.1230195\ttotal: 2.16s\tremaining: 511ms\n",
      "809:\tlearn: 0.1225241\ttotal: 2.17s\tremaining: 509ms\n",
      "810:\tlearn: 0.1218562\ttotal: 2.17s\tremaining: 507ms\n",
      "811:\tlearn: 0.1217940\ttotal: 2.18s\tremaining: 504ms\n",
      "812:\tlearn: 0.1208381\ttotal: 2.18s\tremaining: 502ms\n",
      "813:\tlearn: 0.1199731\ttotal: 2.18s\tremaining: 499ms\n",
      "814:\tlearn: 0.1195464\ttotal: 2.19s\tremaining: 497ms\n",
      "815:\tlearn: 0.1192526\ttotal: 2.19s\tremaining: 494ms\n",
      "816:\tlearn: 0.1184506\ttotal: 2.19s\tremaining: 491ms\n",
      "817:\tlearn: 0.1182690\ttotal: 2.2s\tremaining: 489ms\n",
      "818:\tlearn: 0.1175197\ttotal: 2.2s\tremaining: 486ms\n",
      "819:\tlearn: 0.1171445\ttotal: 2.2s\tremaining: 483ms\n",
      "820:\tlearn: 0.1165982\ttotal: 2.21s\tremaining: 481ms\n",
      "821:\tlearn: 0.1159909\ttotal: 2.21s\tremaining: 478ms\n",
      "822:\tlearn: 0.1158117\ttotal: 2.21s\tremaining: 476ms\n",
      "823:\tlearn: 0.1150574\ttotal: 2.21s\tremaining: 473ms\n",
      "824:\tlearn: 0.1145783\ttotal: 2.22s\tremaining: 470ms\n",
      "825:\tlearn: 0.1143786\ttotal: 2.22s\tremaining: 468ms\n",
      "826:\tlearn: 0.1137517\ttotal: 2.22s\tremaining: 465ms\n",
      "827:\tlearn: 0.1129822\ttotal: 2.23s\tremaining: 463ms\n",
      "828:\tlearn: 0.1124538\ttotal: 2.23s\tremaining: 460ms\n",
      "829:\tlearn: 0.1117349\ttotal: 2.23s\tremaining: 458ms\n",
      "830:\tlearn: 0.1112311\ttotal: 2.24s\tremaining: 455ms\n",
      "831:\tlearn: 0.1104090\ttotal: 2.24s\tremaining: 453ms\n",
      "832:\tlearn: 0.1103341\ttotal: 2.24s\tremaining: 450ms\n",
      "833:\tlearn: 0.1094282\ttotal: 2.25s\tremaining: 448ms\n",
      "834:\tlearn: 0.1093057\ttotal: 2.25s\tremaining: 445ms\n",
      "835:\tlearn: 0.1085627\ttotal: 2.26s\tremaining: 443ms\n",
      "836:\tlearn: 0.1079965\ttotal: 2.26s\tremaining: 440ms\n",
      "837:\tlearn: 0.1071018\ttotal: 2.26s\tremaining: 437ms\n",
      "838:\tlearn: 0.1067677\ttotal: 2.27s\tremaining: 435ms\n",
      "839:\tlearn: 0.1063004\ttotal: 2.27s\tremaining: 432ms\n",
      "840:\tlearn: 0.1055212\ttotal: 2.27s\tremaining: 430ms\n",
      "841:\tlearn: 0.1050121\ttotal: 2.28s\tremaining: 427ms\n",
      "842:\tlearn: 0.1044665\ttotal: 2.28s\tremaining: 425ms\n",
      "843:\tlearn: 0.1038712\ttotal: 2.29s\tremaining: 423ms\n",
      "844:\tlearn: 0.1032753\ttotal: 2.29s\tremaining: 420ms\n",
      "845:\tlearn: 0.1026530\ttotal: 2.29s\tremaining: 418ms\n",
      "846:\tlearn: 0.1020281\ttotal: 2.3s\tremaining: 415ms\n",
      "847:\tlearn: 0.1012134\ttotal: 2.3s\tremaining: 413ms\n",
      "848:\tlearn: 0.1010258\ttotal: 2.31s\tremaining: 410ms\n",
      "849:\tlearn: 0.1006353\ttotal: 2.31s\tremaining: 408ms\n",
      "850:\tlearn: 0.0999669\ttotal: 2.31s\tremaining: 405ms\n",
      "851:\tlearn: 0.0995612\ttotal: 2.32s\tremaining: 403ms\n",
      "852:\tlearn: 0.0989573\ttotal: 2.32s\tremaining: 400ms\n",
      "853:\tlearn: 0.0982917\ttotal: 2.33s\tremaining: 398ms\n",
      "854:\tlearn: 0.0976376\ttotal: 2.33s\tremaining: 395ms\n",
      "855:\tlearn: 0.0969627\ttotal: 2.33s\tremaining: 393ms\n",
      "856:\tlearn: 0.0964932\ttotal: 2.34s\tremaining: 391ms\n",
      "857:\tlearn: 0.0960874\ttotal: 2.35s\tremaining: 388ms\n",
      "858:\tlearn: 0.0954855\ttotal: 2.35s\tremaining: 386ms\n",
      "859:\tlearn: 0.0954204\ttotal: 2.35s\tremaining: 383ms\n",
      "860:\tlearn: 0.0951339\ttotal: 2.36s\tremaining: 381ms\n",
      "861:\tlearn: 0.0950547\ttotal: 2.36s\tremaining: 378ms\n",
      "862:\tlearn: 0.0946880\ttotal: 2.37s\tremaining: 376ms\n",
      "863:\tlearn: 0.0944838\ttotal: 2.37s\tremaining: 373ms\n",
      "864:\tlearn: 0.0943027\ttotal: 2.38s\tremaining: 371ms\n",
      "865:\tlearn: 0.0938946\ttotal: 2.38s\tremaining: 368ms\n",
      "866:\tlearn: 0.0936548\ttotal: 2.38s\tremaining: 365ms\n",
      "867:\tlearn: 0.0933246\ttotal: 2.38s\tremaining: 363ms\n",
      "868:\tlearn: 0.0929151\ttotal: 2.39s\tremaining: 360ms\n",
      "869:\tlearn: 0.0921265\ttotal: 2.39s\tremaining: 358ms\n",
      "870:\tlearn: 0.0920061\ttotal: 2.4s\tremaining: 355ms\n",
      "871:\tlearn: 0.0915230\ttotal: 2.4s\tremaining: 352ms\n",
      "872:\tlearn: 0.0911797\ttotal: 2.4s\tremaining: 350ms\n",
      "873:\tlearn: 0.0904736\ttotal: 2.41s\tremaining: 347ms\n",
      "874:\tlearn: 0.0903332\ttotal: 2.41s\tremaining: 344ms\n",
      "875:\tlearn: 0.0897093\ttotal: 2.41s\tremaining: 341ms\n",
      "876:\tlearn: 0.0891180\ttotal: 2.41s\tremaining: 339ms\n",
      "877:\tlearn: 0.0887622\ttotal: 2.42s\tremaining: 336ms\n",
      "878:\tlearn: 0.0884933\ttotal: 2.42s\tremaining: 333ms\n",
      "879:\tlearn: 0.0881397\ttotal: 2.42s\tremaining: 330ms\n",
      "880:\tlearn: 0.0877607\ttotal: 2.42s\tremaining: 328ms\n",
      "881:\tlearn: 0.0876046\ttotal: 2.43s\tremaining: 325ms\n",
      "882:\tlearn: 0.0873402\ttotal: 2.43s\tremaining: 322ms\n",
      "883:\tlearn: 0.0870390\ttotal: 2.43s\tremaining: 319ms\n",
      "884:\tlearn: 0.0867400\ttotal: 2.44s\tremaining: 317ms\n",
      "885:\tlearn: 0.0864546\ttotal: 2.44s\tremaining: 314ms\n",
      "886:\tlearn: 0.0858292\ttotal: 2.44s\tremaining: 311ms\n",
      "887:\tlearn: 0.0852578\ttotal: 2.44s\tremaining: 308ms\n",
      "888:\tlearn: 0.0851766\ttotal: 2.45s\tremaining: 306ms\n",
      "889:\tlearn: 0.0845499\ttotal: 2.45s\tremaining: 303ms\n",
      "890:\tlearn: 0.0841232\ttotal: 2.45s\tremaining: 300ms\n",
      "891:\tlearn: 0.0838989\ttotal: 2.46s\tremaining: 297ms\n",
      "892:\tlearn: 0.0833230\ttotal: 2.46s\tremaining: 295ms\n",
      "893:\tlearn: 0.0829249\ttotal: 2.46s\tremaining: 292ms\n",
      "894:\tlearn: 0.0822710\ttotal: 2.46s\tremaining: 289ms\n",
      "895:\tlearn: 0.0819908\ttotal: 2.47s\tremaining: 286ms\n",
      "896:\tlearn: 0.0817343\ttotal: 2.47s\tremaining: 284ms\n",
      "897:\tlearn: 0.0811799\ttotal: 2.47s\tremaining: 281ms\n",
      "898:\tlearn: 0.0807119\ttotal: 2.47s\tremaining: 278ms\n",
      "899:\tlearn: 0.0804014\ttotal: 2.48s\tremaining: 275ms\n",
      "900:\tlearn: 0.0803358\ttotal: 2.48s\tremaining: 273ms\n",
      "901:\tlearn: 0.0798048\ttotal: 2.48s\tremaining: 270ms\n",
      "902:\tlearn: 0.0794693\ttotal: 2.49s\tremaining: 267ms\n",
      "903:\tlearn: 0.0792624\ttotal: 2.49s\tremaining: 264ms\n",
      "904:\tlearn: 0.0790281\ttotal: 2.49s\tremaining: 262ms\n",
      "905:\tlearn: 0.0785109\ttotal: 2.49s\tremaining: 259ms\n",
      "906:\tlearn: 0.0782443\ttotal: 2.5s\tremaining: 256ms\n",
      "907:\tlearn: 0.0777093\ttotal: 2.5s\tremaining: 253ms\n",
      "908:\tlearn: 0.0770792\ttotal: 2.5s\tremaining: 251ms\n",
      "909:\tlearn: 0.0767749\ttotal: 2.5s\tremaining: 248ms\n",
      "910:\tlearn: 0.0765117\ttotal: 2.51s\tremaining: 245ms\n",
      "911:\tlearn: 0.0762459\ttotal: 2.51s\tremaining: 242ms\n",
      "912:\tlearn: 0.0760818\ttotal: 2.52s\tremaining: 240ms\n",
      "913:\tlearn: 0.0756823\ttotal: 2.52s\tremaining: 237ms\n",
      "914:\tlearn: 0.0752155\ttotal: 2.52s\tremaining: 234ms\n",
      "915:\tlearn: 0.0746916\ttotal: 2.52s\tremaining: 231ms\n",
      "916:\tlearn: 0.0742820\ttotal: 2.53s\tremaining: 229ms\n",
      "917:\tlearn: 0.0739974\ttotal: 2.53s\tremaining: 226ms\n",
      "918:\tlearn: 0.0737351\ttotal: 2.53s\tremaining: 223ms\n",
      "919:\tlearn: 0.0734273\ttotal: 2.53s\tremaining: 220ms\n",
      "920:\tlearn: 0.0731105\ttotal: 2.54s\tremaining: 218ms\n",
      "921:\tlearn: 0.0726208\ttotal: 2.54s\tremaining: 215ms\n",
      "922:\tlearn: 0.0721151\ttotal: 2.54s\tremaining: 212ms\n",
      "923:\tlearn: 0.0716762\ttotal: 2.55s\tremaining: 209ms\n",
      "924:\tlearn: 0.0715157\ttotal: 2.55s\tremaining: 207ms\n",
      "925:\tlearn: 0.0710849\ttotal: 2.55s\tremaining: 204ms\n",
      "926:\tlearn: 0.0710343\ttotal: 2.56s\tremaining: 201ms\n",
      "927:\tlearn: 0.0709266\ttotal: 2.56s\tremaining: 199ms\n",
      "928:\tlearn: 0.0706319\ttotal: 2.56s\tremaining: 196ms\n",
      "929:\tlearn: 0.0702059\ttotal: 2.56s\tremaining: 193ms\n",
      "930:\tlearn: 0.0699031\ttotal: 2.57s\tremaining: 190ms\n",
      "931:\tlearn: 0.0694864\ttotal: 2.57s\tremaining: 188ms\n",
      "932:\tlearn: 0.0689932\ttotal: 2.58s\tremaining: 185ms\n",
      "933:\tlearn: 0.0689406\ttotal: 2.58s\tremaining: 182ms\n",
      "934:\tlearn: 0.0685036\ttotal: 2.58s\tremaining: 180ms\n",
      "935:\tlearn: 0.0679510\ttotal: 2.58s\tremaining: 177ms\n",
      "936:\tlearn: 0.0677380\ttotal: 2.59s\tremaining: 174ms\n",
      "937:\tlearn: 0.0672894\ttotal: 2.59s\tremaining: 171ms\n",
      "938:\tlearn: 0.0668797\ttotal: 2.59s\tremaining: 169ms\n",
      "939:\tlearn: 0.0666365\ttotal: 2.6s\tremaining: 166ms\n",
      "940:\tlearn: 0.0663884\ttotal: 2.6s\tremaining: 163ms\n",
      "941:\tlearn: 0.0663174\ttotal: 2.6s\tremaining: 160ms\n",
      "942:\tlearn: 0.0658226\ttotal: 2.6s\tremaining: 157ms\n",
      "943:\tlearn: 0.0656259\ttotal: 2.61s\tremaining: 155ms\n",
      "944:\tlearn: 0.0651971\ttotal: 2.61s\tremaining: 152ms\n",
      "945:\tlearn: 0.0647399\ttotal: 2.61s\tremaining: 149ms\n",
      "946:\tlearn: 0.0644511\ttotal: 2.61s\tremaining: 146ms\n",
      "947:\tlearn: 0.0640840\ttotal: 2.62s\tremaining: 143ms\n",
      "948:\tlearn: 0.0639524\ttotal: 2.62s\tremaining: 141ms\n",
      "949:\tlearn: 0.0635777\ttotal: 2.62s\tremaining: 138ms\n",
      "950:\tlearn: 0.0632538\ttotal: 2.62s\tremaining: 135ms\n",
      "951:\tlearn: 0.0627793\ttotal: 2.63s\tremaining: 132ms\n",
      "952:\tlearn: 0.0625884\ttotal: 2.63s\tremaining: 130ms\n",
      "953:\tlearn: 0.0625166\ttotal: 2.63s\tremaining: 127ms\n",
      "954:\tlearn: 0.0622981\ttotal: 2.63s\tremaining: 124ms\n",
      "955:\tlearn: 0.0619410\ttotal: 2.63s\tremaining: 121ms\n",
      "956:\tlearn: 0.0617803\ttotal: 2.64s\tremaining: 118ms\n",
      "957:\tlearn: 0.0615252\ttotal: 2.64s\tremaining: 116ms\n",
      "958:\tlearn: 0.0611748\ttotal: 2.64s\tremaining: 113ms\n",
      "959:\tlearn: 0.0609485\ttotal: 2.64s\tremaining: 110ms\n",
      "960:\tlearn: 0.0607588\ttotal: 2.65s\tremaining: 107ms\n",
      "961:\tlearn: 0.0603579\ttotal: 2.65s\tremaining: 105ms\n",
      "962:\tlearn: 0.0601414\ttotal: 2.65s\tremaining: 102ms\n",
      "963:\tlearn: 0.0596859\ttotal: 2.65s\tremaining: 99ms\n",
      "964:\tlearn: 0.0594421\ttotal: 2.65s\tremaining: 96.2ms\n",
      "965:\tlearn: 0.0589322\ttotal: 2.65s\tremaining: 93.5ms\n",
      "966:\tlearn: 0.0588466\ttotal: 2.66s\tremaining: 90.7ms\n",
      "967:\tlearn: 0.0585493\ttotal: 2.66s\tremaining: 87.9ms\n",
      "968:\tlearn: 0.0582410\ttotal: 2.66s\tremaining: 85.2ms\n",
      "969:\tlearn: 0.0580225\ttotal: 2.66s\tremaining: 82.4ms\n",
      "970:\tlearn: 0.0579531\ttotal: 2.67s\tremaining: 79.6ms\n",
      "971:\tlearn: 0.0576790\ttotal: 2.67s\tremaining: 76.9ms\n",
      "972:\tlearn: 0.0573842\ttotal: 2.67s\tremaining: 74.1ms\n",
      "973:\tlearn: 0.0570307\ttotal: 2.67s\tremaining: 71.4ms\n",
      "974:\tlearn: 0.0567819\ttotal: 2.67s\tremaining: 68.6ms\n",
      "975:\tlearn: 0.0566093\ttotal: 2.68s\tremaining: 65.8ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976:\tlearn: 0.0564202\ttotal: 2.68s\tremaining: 63.1ms\n",
      "977:\tlearn: 0.0561427\ttotal: 2.68s\tremaining: 60.4ms\n",
      "978:\tlearn: 0.0558418\ttotal: 2.69s\tremaining: 57.6ms\n",
      "979:\tlearn: 0.0555518\ttotal: 2.69s\tremaining: 54.9ms\n",
      "980:\tlearn: 0.0552421\ttotal: 2.69s\tremaining: 52.1ms\n",
      "981:\tlearn: 0.0549244\ttotal: 2.69s\tremaining: 49.4ms\n",
      "982:\tlearn: 0.0546137\ttotal: 2.7s\tremaining: 46.7ms\n",
      "983:\tlearn: 0.0544555\ttotal: 2.7s\tremaining: 43.9ms\n",
      "984:\tlearn: 0.0541219\ttotal: 2.7s\tremaining: 41.2ms\n",
      "985:\tlearn: 0.0540327\ttotal: 2.71s\tremaining: 38.4ms\n",
      "986:\tlearn: 0.0537821\ttotal: 2.71s\tremaining: 35.7ms\n",
      "987:\tlearn: 0.0534715\ttotal: 2.71s\tremaining: 32.9ms\n",
      "988:\tlearn: 0.0531800\ttotal: 2.71s\tremaining: 30.2ms\n",
      "989:\tlearn: 0.0528925\ttotal: 2.71s\tremaining: 27.4ms\n",
      "990:\tlearn: 0.0526444\ttotal: 2.72s\tremaining: 24.7ms\n",
      "991:\tlearn: 0.0526036\ttotal: 2.72s\tremaining: 21.9ms\n",
      "992:\tlearn: 0.0523023\ttotal: 2.72s\tremaining: 19.2ms\n",
      "993:\tlearn: 0.0521292\ttotal: 2.73s\tremaining: 16.5ms\n",
      "994:\tlearn: 0.0518356\ttotal: 2.73s\tremaining: 13.7ms\n",
      "995:\tlearn: 0.0515531\ttotal: 2.73s\tremaining: 11ms\n",
      "996:\tlearn: 0.0514178\ttotal: 2.73s\tremaining: 8.22ms\n",
      "997:\tlearn: 0.0513500\ttotal: 2.73s\tremaining: 5.48ms\n",
      "998:\tlearn: 0.0509461\ttotal: 2.74s\tremaining: 2.74ms\n",
      "999:\tlearn: 0.0509066\ttotal: 2.74s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.346428491461625, 5.36781246534628)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "rf = CatBoostRegressor()\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "y = features['dbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test[\"hypertension\"]=y_pred_2\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "rmse,mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86ccd428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:05,275] A new study created in memory with name: no-name-3b2bc1cf-d8ba-4e86-91fe-c3f28c3724b1\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:06,473] Trial 0 finished with value: 21.824677444016658 and parameters: {'hidden_units': 103, 'activation': 'tanh', 'learning_rate': 0.07952806921054174}. Best is trial 0 with value: 21.824677444016658.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:07,654] Trial 1 finished with value: 19.002025636521545 and parameters: {'hidden_units': 107, 'activation': 'tanh', 'learning_rate': 0.02186017799364664}. Best is trial 1 with value: 19.002025636521545.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:08,826] Trial 2 finished with value: 36.77157505524573 and parameters: {'hidden_units': 47, 'activation': 'relu', 'learning_rate': 0.003288702515124621}. Best is trial 1 with value: 19.002025636521545.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:10,012] Trial 3 finished with value: 16.528599773090107 and parameters: {'hidden_units': 113, 'activation': 'tanh', 'learning_rate': 0.01833484959117621}. Best is trial 3 with value: 16.528599773090107.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:11,247] Trial 4 finished with value: 16.613648184685328 and parameters: {'hidden_units': 92, 'activation': 'tanh', 'learning_rate': 0.0006832251116876484}. Best is trial 3 with value: 16.528599773090107.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:12,412] Trial 5 finished with value: 106.94688890327677 and parameters: {'hidden_units': 52, 'activation': 'tanh', 'learning_rate': 0.00011952304918450434}. Best is trial 3 with value: 16.528599773090107.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:13,553] Trial 6 finished with value: 15.150467038644793 and parameters: {'hidden_units': 100, 'activation': 'tanh', 'learning_rate': 0.0016087875057351096}. Best is trial 6 with value: 15.150467038644793.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:14,726] Trial 7 finished with value: 44.13246521634353 and parameters: {'hidden_units': 122, 'activation': 'relu', 'learning_rate': 0.0012537533421186874}. Best is trial 6 with value: 15.150467038644793.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:15,866] Trial 8 finished with value: 17.948275098943984 and parameters: {'hidden_units': 76, 'activation': 'tanh', 'learning_rate': 0.00039203480289917573}. Best is trial 6 with value: 15.150467038644793.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:17,023] Trial 9 finished with value: 63.27755256804862 and parameters: {'hidden_units': 119, 'activation': 'relu', 'learning_rate': 0.07024217158734541}. Best is trial 6 with value: 15.150467038644793.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:18,226] Trial 10 finished with value: 38.68010242518494 and parameters: {'hidden_units': 74, 'activation': 'relu', 'learning_rate': 0.00368153589417941}. Best is trial 6 with value: 15.150467038644793.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:19,382] Trial 11 finished with value: 14.31271748547096 and parameters: {'hidden_units': 96, 'activation': 'tanh', 'learning_rate': 0.0129454110962007}. Best is trial 11 with value: 14.31271748547096.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:20,586] Trial 12 finished with value: 13.60648235683624 and parameters: {'hidden_units': 94, 'activation': 'tanh', 'learning_rate': 0.00928232055113058}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:21,790] Trial 13 finished with value: 14.276645475832057 and parameters: {'hidden_units': 87, 'activation': 'tanh', 'learning_rate': 0.009765273256921904}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:22,978] Trial 14 finished with value: 14.242370062375866 and parameters: {'hidden_units': 69, 'activation': 'tanh', 'learning_rate': 0.00775568420619552}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:24,181] Trial 15 finished with value: 13.858806809416672 and parameters: {'hidden_units': 63, 'activation': 'tanh', 'learning_rate': 0.00647890850200024}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:25,369] Trial 16 finished with value: 23.06938071228303 and parameters: {'hidden_units': 62, 'activation': 'tanh', 'learning_rate': 0.03027636581726178}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:26,965] Trial 17 finished with value: 15.2867951994755 and parameters: {'hidden_units': 39, 'activation': 'tanh', 'learning_rate': 0.005354953964214071}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:28,231] Trial 18 finished with value: 46.32062733193802 and parameters: {'hidden_units': 61, 'activation': 'relu', 'learning_rate': 0.04488303336397907}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:29,671] Trial 19 finished with value: 14.407867079834729 and parameters: {'hidden_units': 83, 'activation': 'tanh', 'learning_rate': 0.0017339625426456345}. Best is trial 12 with value: 13.60648235683624.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:30,965] Trial 20 finished with value: 13.204506531909688 and parameters: {'hidden_units': 35, 'activation': 'tanh', 'learning_rate': 0.0064232210065620346}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:32,211] Trial 21 finished with value: 15.106651259543305 and parameters: {'hidden_units': 37, 'activation': 'tanh', 'learning_rate': 0.006683806925518982}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:33,336] Trial 22 finished with value: 16.77576551617331 and parameters: {'hidden_units': 49, 'activation': 'tanh', 'learning_rate': 0.0028797407261458158}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:34,603] Trial 23 finished with value: 16.754053094360653 and parameters: {'hidden_units': 33, 'activation': 'tanh', 'learning_rate': 0.013043577978269306}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:35,775] Trial 24 finished with value: 14.83467690570174 and parameters: {'hidden_units': 58, 'activation': 'tanh', 'learning_rate': 0.004483937843918788}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:36,917] Trial 25 finished with value: 16.496919690138743 and parameters: {'hidden_units': 71, 'activation': 'tanh', 'learning_rate': 0.0339149453252654}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:38,071] Trial 26 finished with value: 43.544937889066425 and parameters: {'hidden_units': 42, 'activation': 'relu', 'learning_rate': 0.0026362976373297997}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:39,261] Trial 27 finished with value: 15.596742077832468 and parameters: {'hidden_units': 128, 'activation': 'tanh', 'learning_rate': 0.0008550235273232629}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:40,528] Trial 28 finished with value: 16.5713472607782 and parameters: {'hidden_units': 85, 'activation': 'tanh', 'learning_rate': 0.01117206071822966}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:41,711] Trial 29 finished with value: 71.59766385153593 and parameters: {'hidden_units': 106, 'activation': 'tanh', 'learning_rate': 0.09675583373870257}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:42,901] Trial 30 finished with value: 14.879437788337455 and parameters: {'hidden_units': 67, 'activation': 'tanh', 'learning_rate': 0.018570366409490193}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:44,302] Trial 31 finished with value: 17.243473509371114 and parameters: {'hidden_units': 79, 'activation': 'tanh', 'learning_rate': 0.0071976651012139944}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:45,552] Trial 32 finished with value: 14.786614285699885 and parameters: {'hidden_units': 56, 'activation': 'tanh', 'learning_rate': 0.008782272549733147}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:46,839] Trial 33 finished with value: 15.68413286173013 and parameters: {'hidden_units': 69, 'activation': 'tanh', 'learning_rate': 0.005900158310187378}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:48,325] Trial 34 finished with value: 14.583184919244776 and parameters: {'hidden_units': 92, 'activation': 'tanh', 'learning_rate': 0.018608402280278484}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:49,707] Trial 35 finished with value: 15.903240007742097 and parameters: {'hidden_units': 43, 'activation': 'tanh', 'learning_rate': 0.00218369918560607}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:51,082] Trial 36 finished with value: 14.316206344053725 and parameters: {'hidden_units': 52, 'activation': 'tanh', 'learning_rate': 0.003987533387896315}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:52,519] Trial 37 finished with value: 43.48774007389903 and parameters: {'hidden_units': 64, 'activation': 'relu', 'learning_rate': 0.02698288826852767}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:53,894] Trial 38 finished with value: 15.902431771683844 and parameters: {'hidden_units': 111, 'activation': 'tanh', 'learning_rate': 0.012709519792647552}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:55,241] Trial 39 finished with value: 18.433609374302698 and parameters: {'hidden_units': 101, 'activation': 'tanh', 'learning_rate': 0.00031936788497108175}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:57,054] Trial 40 finished with value: 35.031535964689596 and parameters: {'hidden_units': 92, 'activation': 'tanh', 'learning_rate': 0.050966941306415714}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:28:59,464] Trial 41 finished with value: 13.94049798485799 and parameters: {'hidden_units': 87, 'activation': 'tanh', 'learning_rate': 0.008210466989052258}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:00,825] Trial 42 finished with value: 15.468518144471087 and parameters: {'hidden_units': 78, 'activation': 'tanh', 'learning_rate': 0.006885045358841693}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:02,284] Trial 43 finished with value: 15.999762271948018 and parameters: {'hidden_units': 90, 'activation': 'tanh', 'learning_rate': 0.004717586103359423}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:03,787] Trial 44 finished with value: 37.088064672682975 and parameters: {'hidden_units': 98, 'activation': 'relu', 'learning_rate': 0.008587632531811124}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:04,993] Trial 45 finished with value: 18.151325258942986 and parameters: {'hidden_units': 72, 'activation': 'tanh', 'learning_rate': 0.016038533000420883}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:06,181] Trial 46 finished with value: 15.89500902851267 and parameters: {'hidden_units': 95, 'activation': 'tanh', 'learning_rate': 0.003194039789126008}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:07,383] Trial 47 finished with value: 18.20465102557698 and parameters: {'hidden_units': 83, 'activation': 'tanh', 'learning_rate': 0.02402809351682161}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:08,571] Trial 48 finished with value: 51.92520376395982 and parameters: {'hidden_units': 88, 'activation': 'relu', 'learning_rate': 0.0001128959560080905}. Best is trial 20 with value: 13.204506531909688.\n",
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_4704\\38995349.py:33: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:29:09,837] Trial 49 finished with value: 15.337086034897506 and parameters: {'hidden_units': 106, 'activation': 'tanh', 'learning_rate': 0.008719099751039563}. Best is trial 20 with value: 13.204506531909688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n",
      "Optuna-tuned Neural Network RMSE: 72.77862012499169, MAE: 71.75415160808157\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have a DataFrame 'features' with the necessary columns\n",
    "\n",
    "# Preprocess the data\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "y = features['sbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test[\"hypertension\"]=y_pred_2\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(trial.suggest_int('hidden_units', 32, 128), activation=trial.suggest_categorical('activation', ['relu', 'tanh']), input_shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.Dense(128),\n",
    "        keras.layers.Dense(128),\n",
    "        keras.layers.Dense(1)  # Output layer\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=trial.suggest_loguniform('learning_rate', 1e-4, 1e-1))\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_nn = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse_nn = (mean_squared_error(y_test, y_pred_nn))**0.5\n",
    "\n",
    "    return rmse_nn\n",
    "\n",
    "# Perform hyperparameter optimization with Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = keras.Sequential([\n",
    "    keras.layers.Dense(best_params['hidden_units'], activation=best_params['activation'], input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n",
    "final_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "final_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_nn = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the neural network\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "rmse_nn = (mean_squared_error(y_test, y_pred_nn))**0.5\n",
    "\n",
    "print(f'Optuna-tuned Neural Network RMSE: {rmse_nn}, MAE: {mae_nn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2e6fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "RMSE: 11.157955718916622\n",
      "MAE: 8.322817729310493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Assuming 'features' is your DataFrame\n",
    "\n",
    "# Define your RandomForestRegressor with default hyperparameters\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Define the parameter grid to search through\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Split your data\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "y = features['sbp']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test[\"hypertension\"]=y_pred_2\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model with the best hyperparameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52f8e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-16 19:35:22,768] A new study created in memory with name: no-name-8dae52a3-6783-45f2-8965-b21c3a2387e3\n",
      "[I 2024-02-16 19:35:22,886] Trial 0 finished with value: -30.300244680851055 and parameters: {}. Best is trial 0 with value: -30.300244680851055.\n",
      "[I 2024-02-16 19:35:23,026] Trial 1 finished with value: -30.220385106382977 and parameters: {}. Best is trial 0 with value: -30.300244680851055.\n",
      "[I 2024-02-16 19:35:23,151] Trial 2 finished with value: -29.23373404255319 and parameters: {}. Best is trial 0 with value: -30.300244680851055.\n",
      "[I 2024-02-16 19:35:23,276] Trial 3 finished with value: -30.33726808510638 and parameters: {}. Best is trial 3 with value: -30.33726808510638.\n",
      "[I 2024-02-16 19:35:23,401] Trial 4 finished with value: -31.38461914893617 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:23,526] Trial 5 finished with value: -29.651093617021278 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:23,641] Trial 6 finished with value: -28.945557446808525 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:23,766] Trial 7 finished with value: -31.063570212765963 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:23,906] Trial 8 finished with value: -28.913129787234045 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,047] Trial 9 finished with value: -30.011451063829785 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,203] Trial 10 finished with value: -29.69093617021277 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,328] Trial 11 finished with value: -30.279927659574472 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,453] Trial 12 finished with value: -30.304504255319152 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,578] Trial 13 finished with value: -29.813844680851066 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,703] Trial 14 finished with value: -31.085289361702124 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,828] Trial 15 finished with value: -29.159940425531914 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:24,953] Trial 16 finished with value: -30.364534042553203 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:25,078] Trial 17 finished with value: -30.227497872340432 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:25,204] Trial 18 finished with value: -28.80823404255319 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:25,329] Trial 19 finished with value: -30.112465957446812 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:25,449] Trial 20 finished with value: -29.185963829787234 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:25,574] Trial 21 finished with value: -30.658889361702133 and parameters: {}. Best is trial 4 with value: -31.38461914893617.\n",
      "[I 2024-02-16 19:35:25,699] Trial 22 finished with value: -31.39666382978724 and parameters: {}. Best is trial 22 with value: -31.39666382978724.\n",
      "[I 2024-02-16 19:35:25,824] Trial 23 finished with value: -30.557455319148946 and parameters: {}. Best is trial 22 with value: -31.39666382978724.\n",
      "[I 2024-02-16 19:35:25,949] Trial 24 finished with value: -31.536563829787227 and parameters: {}. Best is trial 24 with value: -31.536563829787227.\n",
      "[I 2024-02-16 19:35:26,074] Trial 25 finished with value: -31.262570212765958 and parameters: {}. Best is trial 24 with value: -31.536563829787227.\n",
      "[I 2024-02-16 19:35:26,214] Trial 26 finished with value: -31.659691489361705 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:26,339] Trial 27 finished with value: -30.560342553191486 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:26,464] Trial 28 finished with value: -29.694655319148925 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:26,589] Trial 29 finished with value: -30.908421276595742 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:26,714] Trial 30 finished with value: -31.231670212765952 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:26,839] Trial 31 finished with value: -30.02140425531915 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:26,964] Trial 32 finished with value: -29.985278723404264 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:27,089] Trial 33 finished with value: -29.23522340425532 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:27,214] Trial 34 finished with value: -31.03570851063828 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:27,339] Trial 35 finished with value: -30.322729787234028 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:27,464] Trial 36 finished with value: -28.662465957446823 and parameters: {}. Best is trial 26 with value: -31.659691489361705.\n",
      "[I 2024-02-16 19:35:27,605] Trial 37 finished with value: -32.33671489361702 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:27,730] Trial 38 finished with value: -29.108561702127655 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:27,854] Trial 39 finished with value: -29.508674468085108 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:27,964] Trial 40 finished with value: -30.534844680851062 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,089] Trial 41 finished with value: -30.659361702127665 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,214] Trial 42 finished with value: -29.962057446808508 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,339] Trial 43 finished with value: -30.477787234042566 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,464] Trial 44 finished with value: -31.520236170212762 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,589] Trial 45 finished with value: -31.698382978723394 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,714] Trial 46 finished with value: -30.86059148936171 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,854] Trial 47 finished with value: -31.669848936170208 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:28,979] Trial 48 finished with value: -30.889855319148943 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n",
      "[I 2024-02-16 19:35:29,104] Trial 49 finished with value: -30.47589148936171 and parameters: {}. Best is trial 37 with value: -32.33671489361702.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {}\n",
      "RMSE: 11.32683154134277\n",
      "MAE: 8.540212765957447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define your RandomForestRegressor with hyperparameters to be tuned\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # Split your data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the trained model\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate and return the negative mean squared error as Optuna tries to minimize the objective\n",
    "    return -mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Assuming 'features' is your DataFrame\n",
    "X = features.drop(['sbp', 'dbp',\"subject_id\",'Unnamed: 0'], axis=1)\n",
    "y = features['dbp']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test[\"hypertension\"]=y_pred_2\n",
    "\n",
    "# Optimize hyperparameters using Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_rf = RandomForestRegressor(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = (mean_squared_error(y_test, y_pred))**0.5\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcbdfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8d80a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741377ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc5d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eed391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
